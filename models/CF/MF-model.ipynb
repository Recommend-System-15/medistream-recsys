{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1758f1b3",
   "metadata": {},
   "source": [
    "# MF 모델 기반 학습 및 평가 진행\n",
    "- 메디스트림의 order 데이터 기반으로 아이템 추천을 진행합니다.\n",
    "- 5개월치 데이터 중 도서 카테고리 아이템 추천을 진행합니다.\n",
    "- train: 2022.04.13 ~ 08.22(약 5개월), test: 2022.08.23 ~ 09.13(약 3주)\n",
    "- 메디마켓 메인 페이지 노출 상품 수가 15개였으며 때문에 NDCG@15 score 와 entropy diversity@15 통해 평가합니다.\n",
    "- base 모델로 메디스트림 메디마켓에서 실제 진행 중인 연관추천 (인기순,최신순,오래된순,높은가격순,낮은가격순,이름순 총 6가지)를   \n",
    "재현하여 추천 학습 모델(MF,LMF,MP,앙상블)과 성능을 비교합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dbe592",
   "metadata": {},
   "source": [
    "# 추천 학습 모델\n",
    "- ALS MF, LMF, MP, 앙상블 (총 4개)\n",
    "- 학습 모델로는 총 3개의 추천을 진행하며 각 모델을 비교하며 최종적으로 모델을 선별\n",
    "- 선별된 모델은 다른 모델과 앙상블을 통해서 성능을 비교해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "053cf1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "import random\n",
    "import implicit\n",
    "from implicit.als import AlternatingLeastSquares as ALS\n",
    "\n",
    "from utils import *\n",
    "\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5943a3d",
   "metadata": {},
   "source": [
    "# 1.Dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "1bfc0ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5141/5141 [00:00<00:00, 639223.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# products name 확인 용\n",
    "products_df = pd.read_json(\"/fastcampus-data/products/products.json\")\n",
    "products_df = key_to_element(['_id'],products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "392f7771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('/fastcampus-data/select_column_version_4.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "a727bca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-04-13 08:59:21.151000+0000', tz='UTC')"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "\n",
    "df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
    "# 5개월 전 날짜 확인\n",
    "df['date_paid'].max()-relativedelta(months=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "29b34a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_name_fill(product_name_preprocess_df):\n",
    "    # 각 마지막 product_ids, name으로 채우기\n",
    "    product_ids_to_name = {}\n",
    "    for idx, row in product_name_preprocess_df.iterrows():\n",
    "        product_ids_to_name[row.product_ids] = row.name_x\n",
    "    product_name_preprocess_df['name_x'] = product_name_preprocess_df['product_ids'].apply(lambda x: product_ids_to_name[x])\n",
    "\n",
    "    name_to_product_ids = {}\n",
    "    for idx, row in product_name_preprocess_df.iterrows():\n",
    "        name_to_product_ids[row.name_x] = row.product_ids\n",
    "    product_name_preprocess_df['product_ids'] = product_name_preprocess_df['name_x'].apply(lambda x: name_to_product_ids[x])\n",
    "    return product_name_preprocess_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "92247728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# medirecommend 만들기\n",
    "df = df.dropna(subset=['product_ids','name_x'])\n",
    "\n",
    "# 나오는 개월 수 적기\n",
    "date_state = \"2022-04-13\"\n",
    "# paid orders만 가져오기\n",
    "df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
    "df_only_paid = df[~df['date_paid'].isna()]\n",
    "# 취소 안된 것만 가져오기\n",
    "complete_df = df_only_paid[(df_only_paid['paid'] == True) & (df_only_paid['cancelled']==False)]\n",
    "# 도서 카테고리만 가져오기\n",
    "only_book = complete_df[complete_df['name'] == '도서']\n",
    "\n",
    "# 유저가 중복으로 아이템 구매 삭제\n",
    "df_duplicated_book = only_book.drop_duplicates(subset=['customer_id','product_ids'])\n",
    "\n",
    "df_sort = df_duplicated_book.sort_values(by='date_paid').reset_index(drop=True)\n",
    "df_sort = product_name_fill(df_sort)\n",
    "df_sort = df_sort.drop_duplicates(subset=['customer_id','product_ids']).reset_index(drop=True)\n",
    "\n",
    "# 3개월치 데이터만 가져오기\n",
    "df_book = df_sort[df_sort['date_paid'] >= date_state].reset_index(drop=True)\n",
    "\n",
    "# 마지막 3주 제외한 medirecommend 만들기\n",
    "mediprediction_all_df = df_sort[df_sort['date_paid'] < '2022-08-23'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "05871ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id                 0\n",
       "date_created        0\n",
       "regular_price       0\n",
       "sale_price          0\n",
       "three_months        0\n",
       "date_paid           0\n",
       "customer_id         0\n",
       "paid                0\n",
       "name_x              0\n",
       "category_id_y       0\n",
       "product_ids         0\n",
       "quantity            0\n",
       "price               0\n",
       "price_total         0\n",
       "age_group        1078\n",
       "한의사 여부              2\n",
       "사업자 여부              2\n",
       "cancelled           0\n",
       "name                0\n",
       "slug                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# none 값 확인하기\n",
    "df_book.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdf817c",
   "metadata": {},
   "source": [
    "- age_group, 한의사, 사업자 여부는 사용하지 않는 컬럼이므로 전처리를 진행하지 않았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1485275",
   "metadata": {},
   "source": [
    "## 전체 데이터 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "ee8c91fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 전: 38395 중복 제거 후: 6957\n"
     ]
    }
   ],
   "source": [
    "print('중복 제거 전:',len(only_book), '중복 제거 후:',len(df_book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "c882d891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 수: 6957\n"
     ]
    }
   ],
   "source": [
    "print('전체 데이터 수:',len(df_book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "80095379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아이템 수: 267 유저 수: 2902\n"
     ]
    }
   ],
   "source": [
    "print('아이템 수:',len(df_book.product_ids.unique()),'유저 수:',len(df_book.customer_id.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c21921e",
   "metadata": {},
   "source": [
    "# promotion 전처리 함수\n",
    "- train 만 프로모션 전처리하여 학습 진행\n",
    "- test 는 real world 평가하기 위해서 프로모션 전처리르 진행하지 않았습니다.\n",
    "- 프로모션은 메디스트림 마케팅 팀에서 제공해준 정보를 바탕으로 전처리하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "0c14a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promotion_proprof(df):\n",
    "    from datetime import datetime\n",
    "\n",
    "    preprocessed_book_df_date = df.copy()\n",
    "\n",
    "    promotion_book_df = preprocessed_book_df_date[preprocessed_book_df_date['date_paid'] >= '2022-01-01']\n",
    "    promotion_book_df['date_paid_date'] = promotion_book_df['date_paid'].dt.date\n",
    "    promotion_book_df['date_paid_week'] = promotion_book_df['date_paid_date'].apply(lambda x: x.isocalendar()[1])\n",
    "\n",
    "    promotion_dict = {\n",
    "        2:['트리거포인트 침치료'],\n",
    "        3:['藥徵, 약의 징표','파킨슨병 한의진료','침의 과학적 접근의 이해','길익동동','Medical acupuncture 침의 과학적 접근과 임상활용',\\\n",
    "          '동의보감 약선','수화론(水火論)'],\n",
    "        4:['실전한약가이드','음양승강으로 해석하는 사상의학: 생리병리'],\n",
    "        5:['음양승강으로 해석하는 사상의학: 생리병리'],\n",
    "        6:['윤상훈·권병조의 알짜 근육학','임상 한의사를 위한 기본 한약처방 강의 2판','트리거포인트 침치료','KCD 한방내과 진찰진단 가이드라인',\\\n",
    "          '실전한약가이드','음양승강으로 해석하는 사상의학: 생리병리','藥徵, 약의 징표','증보운곡본초학','통증치료를 위한 근육 초음파와 주사 테크닉'],\n",
    "        7:['오국통 온병명방'],\n",
    "        9:['병태생리 Visual map','NEO 인턴 핸드북','보험한약 브런치 the # 2판 개정판','Kendall 자세와 통증치료에 있어서 근육의 기능과 검사 5판',\\\n",
    "          '사상방 사용설명서','실전한약가이드','일차진료 한의사를 위한 보험한약입문 - 둘째 판','증보운곡본초학'],\n",
    "        10:['한눈에 보는 스트레칭 해부학'],\n",
    "        11:['임산부에게 사용할 수 있는 한방처방'],\n",
    "        12:['임산부에게 사용할 수 있는 한방처방'],\n",
    "        13:['MRI 자신감 키우기_족부편'],\n",
    "        14:['장골의 PI 변위는 없다'],\n",
    "        15:['윤상훈·권병조의 알짜 근육학','임상 한의사를 위한 기본 한약처방 강의 2판','KCD 한방내과 진찰진단 가이드라인','트리거포인트 침치료',\\\n",
    "           '음양승강으로 해석하는 사상의학: 생리병리','침의 과학적 접근의 이해','실전한약가이드','임산부에게 사용할 수 있는 한방처방','한눈에 보는 스트레칭 해부학',\\\n",
    "           'MRI 자신감 키우기_족부편'],\n",
    "        16:['환자상담의 달인','병의원 경영과 자산 관리 클리닉','우리 병원의 문제? 현장에서 답을 찾다!','근육학','스파이랄 및 키네지오 테이핑',\\\n",
    "           '요양병원 주치의 진료핵심'],\n",
    "        17:['오당 본초강론','운동기능장애 치료 매뉴얼','K. 한의학 임상총론','한방 활용 가이드','최강통증매선','암 치료에 이용되는 천연약물',\\\n",
    "           '왕문원 임상 평형침법','중국 왕문원 평형침구학'],\n",
    "        18:['초음파 가이드 근골격계 통증 치료의 정석'],\n",
    "        19:['초음파 가이드 근골격계 통증 치료의 정석','섭혜민 명의경방험안'],\n",
    "        20:['카이로프랙틱 기본테크닉론'],\n",
    "        21:['흔히보는 정형외과 외래진료 가이드북'],\n",
    "        22:['趙紹琴(조소금) 내과학','한의학 상담','숨찬 세상, 호흡기를 편하게',\\\n",
    "         '의학심오(醫學心悟)','안면마비 침구치료','중경서 독법 강해(상,하) /개정판'],\n",
    "        23:['선생님, 이제 그만 저 좀 포기해 주세요','한의학 상담','숨찬 세상, 호흡기를 편하게',\\\n",
    "        '의학심오(醫學心悟)','중경서 독법 강해(상,하) /개정판','안면마비 침구치료'],\n",
    "     24:['황황교수의 임상의를 위한 근거기반 상한금궤 처방 매뉴얼','황황교수의 개원 한의사를 위한 상한금궤 처방 강의록',\\\n",
    "        '선생님, 이제 그만 저 좀 포기해 주세요'],\\\n",
    "     25:['황황교수의 임상의를 위한 근거기반 상한금궤 처방 매뉴얼',\\\n",
    "       '황황교수의 개원 한의사를 위한 상한금궤 처방 강의록','약침의 정석 –통증편','갑상선 진료 완전정복',\\\n",
    "       '신경학 증상의 감별법','이것이 알고싶다! 당뇨병진료','어지럼질환의 진단과 치료','증례와 함께 하는 한약처방',\\\n",
    "       '뇌의학의 첫걸음','HAPPY 소아청소년 진료'],\\\n",
    "     26:['약침의 정석 –통증편','갑상선 진료 완전정복','신경학 증상의 감별법',\\\n",
    "       '증례와 함께 하는 한약처방','이것이 알고싶다! 당뇨병진료','HAPPY 소아청소년 진료','어지럼질환의 진단과 치료',\\\n",
    "       '뇌의학의 첫걸음','실전, 임상한의학 내과질환을 중심으로','실전, 임상한의학 알레르기질환','침구대성','평주온열경위'],\n",
    "     27:['침구과 진료매뉴얼','실전, 임상한의학 내과질환을 중심으로','실전, 임상한의학 알레르기질환','내과학 5권세트','한방순환 신경내과학',\\\n",
    "        '침구대성'],\n",
    "     28:['감별진단의 정석','기본통증진료학','약처방의 정석 (1, 2권 세트)','QBook: Case based Review',\\\n",
    "         'SMART 내과 1권 : 바이탈, 감염, 종양, 류마티스','일차진료아카데미 처방가이드'],\n",
    "     29:['비만문답','사암침의 해석과 임상'],\n",
    "     30:['플로차트 정형외과 진단','침구과 진료매뉴얼','내과학 5권세트','한방순환 신경내과학'],\n",
    "     31:['외래에서 꼭 알아야 할 통증증후군 137가지'],\n",
    "     32:['SMART 기본 일차진료매뉴얼 3판(세트)','SMART 소아진료매뉴얼 3판','SMART 응급진료매뉴얼(세트)'],\n",
    "     33:['SMART 기본 일차진료매뉴얼 3판(세트)','SMART 소아진료매뉴얼 3판','SMART 응급진료매뉴얼(세트)'],\n",
    "     34:['초음파 유도하 침 시술 가이드북'],\n",
    "     35:['영어 진료 가이드북','초음파 유도하 침 시술 가이드북'],\n",
    "     36:['영어 진료 가이드북','소아피부질환해설'],\n",
    "     37:['소아피부질환해설','醫學心悟(의학심오) 톺아보기'],}\n",
    "\n",
    "    promotion_item_list = []\n",
    "    for promotion_items in promotion_dict.values():\n",
    "        for item in promotion_items:\n",
    "            promotion_item_list.append(item)\n",
    "\n",
    "    # set(promotion_item_list), len(set(promotion_item_list))\n",
    "\n",
    "    preprocess_promotion_df = promotion_book_df[~((promotion_book_df['name_x'].str.contains('침의 과학적 접근과 임상활용')) & \\\n",
    "                            (promotion_book_df['date_paid_week']==3))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('의학심오')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==22))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('의학심오')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==23))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('약처방의 정석')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==28))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('초음파 유도하 침')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==34))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('초음파 유도하 침')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==34))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('영어 진료 가이드북')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==35))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('영어 진료 가이드북')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==36))]\n",
    "    all_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('의학심오')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==37))]\n",
    "\n",
    "    for key,value in promotion_dict.items():\n",
    "        all_promotion_df = all_promotion_df[~((all_promotion_df['name_x'].isin(value)) & (all_promotion_df['date_paid_week']==key))]\n",
    "    \n",
    "    return all_promotion_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbebd6a1",
   "metadata": {},
   "source": [
    "# 2.train test split\n",
    "- 마지막 3주 분량(2022.08.23 ~ 09.13)을 test로 선정합니다.\n",
    "- train 없는 test 아이템 또한 모두 반영하여 학습을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "054c8f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-09-13 08:51:40+0000', tz='UTC')"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "df_book['date_paid'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "57fcec3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 8, 23, 0, 0)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime(2022,9,13)-timedelta(days=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "a0aad083",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2022-08-23'\n",
    "train_before = df_book[df_book['date_paid'] < date]\n",
    "train_before_preprocess = promotion_proprof(train_before)\n",
    "test_before_preprocess = df_book[df_book['date_paid'] >= date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "598fe6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5983"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "3931742d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2555, 256)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_before.customer_id)), len(set(train_before.product_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "49bc928c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2887"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_before_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "b4e77b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482, 251)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_before_preprocess.customer_id)), len(set(train_before_preprocess.product_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30999e38",
   "metadata": {},
   "source": [
    "## 전체 아이템 중복 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "cc90f9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(267, 267)"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# product_ids, name_x 수는 일치\n",
    "len(df_book.product_ids.unique()), len(df_book.name_x.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "cea01f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복 제거 후 수 비교 확인\n",
    "len(df_book.drop_duplicates(subset=['product_ids','name_x']).name_x.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e2a66",
   "metadata": {},
   "source": [
    "- 전체 아이템 일치하는 것을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae44431e",
   "metadata": {},
   "source": [
    "## train test 아이템 중복 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "137c94be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251, 131)"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_before_preprocess.product_ids.unique()),len(test_before_preprocess.product_ids.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "e70aeedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_before_preprocess.product_ids.unique())-set(test_before_preprocess.product_ids.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "cdf1afc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 아이템에 train 없는 아이템 확인\n",
    "len(set(test_before_preprocess.product_ids.unique())-set(train_before_preprocess.product_ids.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7291f41e",
   "metadata": {},
   "source": [
    "- train 에서 학습할 수 없는 아이템은 11개 입니다.\n",
    "- 11개 아이템이 중요한 아이템일 수 있지만, real test evaluation   \n",
    "위해서 전처리를 진행하지 않았습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "acd3352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 만 있는 item 제거\n",
    "only_test_items = set(test_before_preprocess.product_ids.unique())-set(train_before_preprocess.product_ids.unique())\n",
    "if_prepro_test = test_before_preprocess[~test_before_preprocess['product_ids'].isin(only_test_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "e2a94995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 변수 명 변경\n",
    "train = train_before_preprocess.copy()\n",
    "# test 변수 명 변경\n",
    "test = test_before_preprocess.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "e35c9ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 test 수: 974\n",
      "전처리 진행했을 경우 test 수: 384\n"
     ]
    }
   ],
   "source": [
    "# test 전처리 진행했을 경우\n",
    "print('원본 test 수:', len(test))\n",
    "print('전처리 진행했을 경우 test 수:', len(if_prepro_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24a4b77",
   "metadata": {},
   "source": [
    "# train test eda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952ba9d0",
   "metadata": {},
   "source": [
    "### 전처리 전후 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "25e9863f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 전처리 전: 5983 train 전처리 후: 2887\n"
     ]
    }
   ],
   "source": [
    "print('train 전처리 전:',len(train_before), 'train 전처리 후:',len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "8bacd384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 전처리 전: 974 test 전처리 후: 974\n"
     ]
    }
   ],
   "source": [
    "print('test 전처리 전:',len(test_before_preprocess), 'test 전처리 후:',len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9797c9d0",
   "metadata": {},
   "source": [
    "### user 수 비교 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "2e702d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 전 train 유저수 :  2555 전처리 후 train 유저 수: 1482\n"
     ]
    }
   ],
   "source": [
    "print('전처리 전 train 유저수 : ',len(train_before.customer_id.unique()), '전처리 후 train 유저 수:',len(train.customer_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "b2d4c5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 유저 수: 744\n"
     ]
    }
   ],
   "source": [
    "print('test 유저 수:',len(test.customer_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "18e1b5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 만 있는 신규 유저 : 514\n"
     ]
    }
   ],
   "source": [
    "# 신규 유저는 MP 같은 다른 방법으로 추천 진행해야 함\n",
    "print('test 만 있는 신규 유저 :',len(set(test['customer_id'].unique())- set(train['customer_id'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197dd8fb",
   "metadata": {},
   "source": [
    "### item 개수 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "3aba7272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 전 train 아이템 수: 256 전처리 후 train 아이템 수 : 251\n"
     ]
    }
   ],
   "source": [
    "print('전처리 전 train 아이템 수:',len(set(train_before.product_ids)), '전처리 후 train 아이템 수 :',len(set(train.product_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "3812f139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 아이템 수 : 131\n"
     ]
    }
   ],
   "source": [
    "print('test 아이템 수 :',len(set(test.product_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "102316b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 만 있는 아이템 수: 131\n"
     ]
    }
   ],
   "source": [
    "print('train 만 있는 아이템 수:',  len(set(train.product_ids)-set(test.product_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "41589650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 만 있는 아이템 수: 11\n"
     ]
    }
   ],
   "source": [
    "print('test 만 있는 아이템 수:', len(set(test.product_ids) - set(train.product_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19564e8",
   "metadata": {},
   "source": [
    "# 3. sparse matrix 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf19f8d",
   "metadata": {},
   "source": [
    "## ALS MF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "dbfcb32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PdIds = train.product_ids.unique()\n",
    "\n",
    "PdIdToIndex = {}\n",
    "indexToPdId = {}\n",
    "\n",
    "colIdx = 0\n",
    "\n",
    "for PdId in PdIds:\n",
    "    PdIdToIndex[PdId] = colIdx\n",
    "    indexToPdId[colIdx] = PdId\n",
    "    colIdx += 1\n",
    "    \n",
    "userIds = train.customer_id.unique()\n",
    "\n",
    "userIdToIndex = {}\n",
    "indexToUserId = {}\n",
    "\n",
    "rowIdx = 0\n",
    "\n",
    "for userId in userIds:\n",
    "    userIdToIndex[userId] = rowIdx\n",
    "    indexToUserId[rowIdx] = userId\n",
    "    rowIdx += 1\n",
    "\n",
    "import scipy.sparse as sp\n",
    "\n",
    "rows = []\n",
    "cols = []\n",
    "vals = []\n",
    "\n",
    "for row in train.itertuples():\n",
    "    rows.append(userIdToIndex[row.customer_id])\n",
    "    cols.append(PdIdToIndex[row.product_ids])\n",
    "    vals.append(1)\n",
    "\n",
    "purchase_sparse = sp.csr_matrix((vals, (rows, cols)), shape=(rowIdx,colIdx))\n",
    "\n",
    "matrix = purchase_sparse.todense()\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f283e658",
   "metadata": {},
   "source": [
    "### Most_popular_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "8a75fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular = mediprediction_all_df.groupby(['product_ids']).count()['customer_id'].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd27dbca",
   "metadata": {},
   "source": [
    "- 5주치 데이터를 통해 most popular 만들어 평가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88fa623",
   "metadata": {},
   "source": [
    "### Medistream_prediction_matrix\n",
    "- 메디스트림 메디마켓에서 제공하는 정렬 추천 성능 비교를 위한 df 구현\n",
    "- 인기도순, 최신순, 과거순, 높은 가격순, 낮은 가격순, 이름순 (총 6 가지)\n",
    "- 각각 구현해보고 학습 모델 대비 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "70704fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-397-274709b685cd>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n"
     ]
    }
   ],
   "source": [
    "medistream_prediction_df = mediprediction_all_df[['date_created','regular_price','sale_price','three_months','product_ids','name_x']]\n",
    "medistream_prediction_preprop_df = medistream_prediction_df.drop_duplicates(subset=['product_ids'], ignore_index=True)\n",
    "medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
    "# sale_prices가 0이면 regular_price 값으로 채워넣어야하는데 0이 없음(전처리 필요 무)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca1abb4",
   "metadata": {},
   "source": [
    "# Sparsity 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "47f55717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.22388717733654"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sparsity: 얼마나 비어있나?\n",
    "matrix_size = purchase_sparse.shape[0]* purchase_sparse.shape[1]\n",
    "num_purchases = len(purchase_sparse.nonzero()[0])\n",
    "sparsity = 100 * (1 - (num_purchases / matrix_size))\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbe9ba0",
   "metadata": {},
   "source": [
    "# 4. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641764ad",
   "metadata": {},
   "source": [
    "## Model 학습 진행\n",
    "- real test 만들기\n",
    "- implict 라이브러리 사용(MF,LMF)\n",
    "- MF 구현 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "b8adfc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real test \n",
    "ground_trues = []\n",
    "for user_id in test['customer_id'].unique():\n",
    "    ground_trues.append({'id': user_id,\\\n",
    "    'items':list(test[test['customer_id']==user_id].product_ids)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b4b0d1",
   "metadata": {},
   "source": [
    "## ALS fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "71f6003c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbaa0e82842e4bf4a99c3ba97a90fb13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "als_model = ALS(factors=20, regularization=0.01, iterations = 50, random_state=42)\n",
    "als_model.fit(purchase_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9085617c",
   "metadata": {},
   "source": [
    "## LMF fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "515f2663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.lmf import LogisticMatrixFactorization as LMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "aea5ab56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b763f9a6524841dd84f5b6d77c71584c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lmf_model = LMF(factors=20, regularization=0.001, iterations = 20, random_state=42)\n",
    "lmf_model.fit(purchase_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd609a",
   "metadata": {},
   "source": [
    "# 5. prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814fddf3",
   "metadata": {},
   "source": [
    "# ALS mf prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "c88db67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신규 유저인 경우 mp로 넣기\n",
    "# 전체 도서에 대한 판매 만큼 정렬 후 넣기\n",
    "most_popular_list = most_popular.sort_values(by='customer_id',ascending=False).index\n",
    "\n",
    "# test 예측값, 이미 구매 했을 경우 제외\n",
    "als_predict_list = []\n",
    "for user_id in test['customer_id'].unique():\n",
    "    try:\n",
    "        result = als_model.recommend(userIdToIndex[user_id], purchase_sparse[userIdToIndex[user_id]], N=15)\n",
    "        als_predict_list.append({'id':user_id ,'items':[indexToPdId[num] for num in result[0]]})\n",
    "    except:\n",
    "        train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "        als_predict_list.append({'id':user_id ,'items':[most_popular.product_ids.loc[num] for num in most_popular_list \\\n",
    "                                                            if most_popular.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                            ]})\n",
    "        \n",
    "# 15 개만 예측하기\n",
    "for idx, pred_list in enumerate(als_predict_list):\n",
    "    als_predict_list[idx]['items'] = pred_list['items'][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee59f90",
   "metadata": {},
   "source": [
    "# LMF prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "7551f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신규 유저 mp로 넣기\n",
    "most_popular_list = most_popular.sort_values(by='customer_id',ascending=False).index\n",
    "\n",
    "# test 예측값\n",
    "lmf_predict_list = []\n",
    "for user_id in test['customer_id'].unique():\n",
    "    try:\n",
    "        result = lmf_model.recommend(userIdToIndex[user_id], purchase_sparse[userIdToIndex[user_id]], N=15)\n",
    "        lmf_predict_list.append({'id':user_id ,'items':[indexToPdId[num] for num in result[0]]})\n",
    "    except:\n",
    "        train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "        lmf_predict_list.append({'id':user_id ,'items':[most_popular.product_ids.loc[num] for num in most_popular_list \\\n",
    "                                                            if most_popular.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                            ]})\n",
    "        \n",
    "# 15 개만 예측하기\n",
    "for idx, pred_list in enumerate(lmf_predict_list):\n",
    "    lmf_predict_list[idx]['items'] = pred_list['items'][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65633ab7",
   "metadata": {},
   "source": [
    "# most popular prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "c1f592ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 도서에 대한 판매 만큼 정렬 후 넣기\n",
    "most_popular_list = most_popular.sort_values(by='customer_id',ascending=False).index\n",
    "\n",
    "# test 예측값, 이미 구매 했을 경우 제외\n",
    "predict_popular_list = []\n",
    "for user_id in test['customer_id'].unique():\n",
    "    train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "    predict_popular_list.append({'id':user_id ,'items':[most_popular.product_ids.loc[num] for num in most_popular_list \\\n",
    "                                                            if most_popular.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                            ]})\n",
    "\n",
    "# 15 개만 예측하기\n",
    "for idx, pred_list in enumerate(predict_popular_list):\n",
    "    predict_popular_list[idx]['items'] = pred_list['items'][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90829334",
   "metadata": {},
   "source": [
    "# medistream base model prediction\n",
    "- 메디스트림 메디마켓에서 제공하는 정렬 추천 성능 비교\n",
    "- 인기도순, 최신순, 과거순, 높은 가격순, 낮은 가격순, 이름순 (총 6 가지)\n",
    "- 각각 구현해보고 학습 모델 대비 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "6284210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인기도순\n",
    "medistream_popular_list = medistream_prediction_preprop_df.sort_values(by='three_months', ascending=False).index\n",
    "# 최신순\n",
    "medistream_latest_list = medistream_prediction_preprop_df.sort_values(by='date_created', ascending=False).index\n",
    "# 오랜된 순\n",
    "medistream_oldest_list = medistream_prediction_preprop_df.sort_values(by='date_created', ascending=True).index\n",
    "# 높은 가격 순\n",
    "medistream_high_price_list = medistream_prediction_preprop_df.sort_values(by='sale_price', ascending=False).index\n",
    "# 낮은 가격 순\n",
    "medistream_low_price_list = medistream_prediction_preprop_df.sort_values(by='sale_price', ascending=True).index\n",
    "# 이름 순\n",
    "medistream_name_sort_list = medistream_prediction_preprop_df.sort_values(by='name_x',ascending=True).index\n",
    "\n",
    "def medistream_prediction_method(predict_num:int ,medi_predict_list:list)->list:\n",
    "    medistream_predict_list = []\n",
    "    for user_id in test['customer_id'].unique():\n",
    "        medistream_predict_list.append({'id':user_id ,'items':[medistream_prediction_preprop_df.product_ids.loc[num] \\\n",
    "                                                                       for num in medi_predict_list]})\n",
    "\n",
    "    # 15 개만 예측하기\n",
    "    for idx, pred_list in enumerate(medistream_predict_list):\n",
    "        medistream_predict_list[idx]['items'] = pred_list['items'][:predict_num]\n",
    "        \n",
    "    return medistream_predict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "ea82c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "medistream_predict_popular_list = medistream_prediction_method(15, medistream_popular_list)\n",
    "medistream_predict_latest_list = medistream_prediction_method(15, medistream_latest_list)\n",
    "medistream_predict_oldest_list = medistream_prediction_method(15, medistream_oldest_list)\n",
    "medistream_predict_high_price_list = medistream_prediction_method(15, medistream_high_price_list)\n",
    "medistream_predict_low_price_list = medistream_prediction_method(15, medistream_low_price_list)\n",
    "medistream_predict_name_sort_list = medistream_prediction_method(15, medistream_name_sort_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b5a451",
   "metadata": {},
   "source": [
    "# 6. evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0f739b",
   "metadata": {},
   "source": [
    "## NDCG & Entropy Diversity 평가지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d31af98",
   "metadata": {},
   "source": [
    "- NDCG score 와 Entropy Diversity score 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "2124a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEvaluator:\n",
    "    # relavence 모두 1로 동일하게 봄\n",
    "    def _idcg(self, l):\n",
    "        return sum((1.0 / np.log(i + 2) for i in range(l)))\n",
    "    \n",
    "\n",
    "    def __init__(self):\n",
    "        self._idcgs = [self._idcg(i) for i in range(1000)]\n",
    "\n",
    "    def _ndcg(self, gt, rec):\n",
    "        dcg = 0.0\n",
    "        for i, r in enumerate(rec):\n",
    "            if r in gt:\n",
    "                dcg += 1.0 / np.log(i + 2)\n",
    "\n",
    "        return dcg / self._idcgs[len(gt)]\n",
    "    \n",
    "    def _entropy_diversity(self,rec_list):\n",
    "        import six\n",
    "        import math\n",
    "        \n",
    "        topn = len(rec_list[0]['items'])\n",
    "        users = [i.get('id',None) for i in rec_list]\n",
    "        sz = float(len(users)) * topn\n",
    "        freq = {}\n",
    "        for rec in rec_list:\n",
    "            for r in rec['items']:\n",
    "                freq[r] = freq.get(r, 0) + 1\n",
    "        ent = -sum([v / sz * math.log(v / sz) for v in six.itervalues(freq)])\n",
    "        return ent\n",
    "\n",
    "    def _eval(self, gt_list, rec_list):\n",
    "        gt_dict = {g[\"id\"]: g for g in gt_list}\n",
    "        ndcg_score = 0.0\n",
    "\n",
    "        for rec in rec_list:\n",
    "            gt = gt_dict[rec[\"id\"]]\n",
    "            ndcg_score += self._ndcg(gt[\"items\"], rec[\"items\"])\n",
    "\n",
    "\n",
    "        ndcg_score = ndcg_score / len(rec_list)\n",
    "        ent = self._entropy_diversity(rec_list)\n",
    "        \n",
    "        return ndcg_score, ent\n",
    "\n",
    "    def evaluate(self, gt_list, rec_list):\n",
    "        try:\n",
    "            ndcg_score, ent_score = self._eval(gt_list, rec_list)\n",
    "            print(f\"NDCG: {ndcg_score:.6}\")\n",
    "            print(f\"Entropy Diversity: {ent_score:.6} \")\n",
    "        except Exception as e:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7486873f",
   "metadata": {},
   "source": [
    "# ALS NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "7ea61210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.0493442\n",
      "Entropy Diversity: 3.70561 \n"
     ]
    }
   ],
   "source": [
    "# ALS \n",
    "evaluator = CustomEvaluator()\n",
    "evaluator.evaluate(ground_trues, als_predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "27e54eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(744, 744)"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(als_predict_list),len(ground_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "6cbc6795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아이템 맞춘 개수\n",
    "cnt = 0\n",
    "for gt, pred_list in zip(ground_trues, als_predict_list):\n",
    "    for pred in pred_list['items']:\n",
    "        if pred in gt['items']:\n",
    "            cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f58a979",
   "metadata": {},
   "source": [
    "# LMF NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "2138e1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.0539183\n",
      "Entropy Diversity: 3.49748 \n"
     ]
    }
   ],
   "source": [
    "# ALS \n",
    "evaluator = CustomEvaluator()\n",
    "evaluator.evaluate(ground_trues, lmf_predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "d087bb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(744, 744)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lmf_predict_list),len(ground_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "7d61e38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아이템 맞춘 개수\n",
    "cnt = 0\n",
    "for gt, pred_list in zip(ground_trues, lmf_predict_list):\n",
    "    for pred in pred_list['items']:\n",
    "        if pred in gt['items']:\n",
    "            cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad479c",
   "metadata": {},
   "source": [
    "# most popular NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "3c0a471b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.0538018\n",
      "Entropy Diversity: 2.74294 \n"
     ]
    }
   ],
   "source": [
    "# most popular\n",
    "evaluator = CustomEvaluator()\n",
    "evaluator.evaluate(ground_trues, predict_popular_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "4e693715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(744, 744)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict_popular_list),len(ground_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "b1436bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아이템 맞춘 개수\n",
    "cnt = 0\n",
    "for gt, pred_list in zip(ground_trues, predict_popular_list):\n",
    "    for pred in pred_list['items']:\n",
    "        if pred in gt['items']:\n",
    "            cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fbb56c",
   "metadata": {},
   "source": [
    "## medistream prediction NDCG & Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "42cb74cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def medistream_prediction(ground_trues:list, predict_list:list):\n",
    "    evaluator = CustomEvaluator()\n",
    "    ndcg, entropy = evaluator._eval(ground_trues, predict_list)\n",
    "    \n",
    "    assert len(predict_list) == len(ground_trues)\n",
    "    \n",
    "    cnt = 0\n",
    "    for gt, pred_list in zip(ground_trues, predict_list):\n",
    "        for pred in pred_list['items']:\n",
    "            if pred in gt['items']:\n",
    "                cnt += 1\n",
    "    return ndcg, entropy, cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "69aed061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medistream_predict</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>entropy</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medi_popular</td>\n",
       "      <td>0.061266</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>latest</td>\n",
       "      <td>0.016588</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oldest</td>\n",
       "      <td>0.015806</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high_price</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>low_price</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>name_sort</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  medistream_predict      ndcg  entropy  cnt\n",
       "0       medi_popular  0.061266  2.70805  151\n",
       "1             latest  0.016588  2.70805   52\n",
       "2             oldest  0.015806  2.70805   45\n",
       "3         high_price  0.003865  2.70805   12\n",
       "4          low_price  0.001136  2.70805    7\n",
       "5          name_sort  0.007651  2.70805   22"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medistream_predict_score = {'medistream_predict':['medi_popular','latest','oldest','high_price','low_price','name_sort'], \\\n",
    "                            'ndcg':[], 'entropy':[], 'cnt':[]}\n",
    "\n",
    "medistream_predict_list = [medistream_predict_popular_list, medistream_predict_latest_list, medistream_predict_oldest_list,\\\n",
    "                          medistream_predict_high_price_list, medistream_predict_low_price_list, medistream_predict_name_sort_list]\n",
    "\n",
    "for medistream_predict in medistream_predict_list:\n",
    "    ndcg, entropy, cnt = medistream_prediction(ground_trues, medistream_predict)\n",
    "    medistream_predict_score['ndcg'].append(ndcg)\n",
    "    medistream_predict_score['entropy'].append(entropy)\n",
    "    medistream_predict_score['cnt'].append(cnt)\n",
    "pd.DataFrame(medistream_predict_score)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2163b6ce",
   "metadata": {},
   "source": [
    "- ALS MF, LMF, MP(5개월) 모두 메디 연관추천 base model 대비   \n",
    "NDCG 점수는 낮음\n",
    "- 하지만, MF, LMF는 entropy score 가 월등히 높은 수치를 보여줌   \n",
    "- 또한, LMF 가 MF 대비 높은 NDCG 점수를 보임\n",
    "- 따라서 ALS MF 와 LMF 하이퍼파라미터 튜닝 진행 후 최종 NDCG 스코어와   \n",
    "entropy 스코어 양상을 확인해보기로 함(이때 하이퍼파라미터 튜닝을 진행한 파라미터로 학습 진행)\n",
    "- LMF 와 base model 에서 가장 높은 NDCG 점수를 보인 MP와 앙상블(medi_mp_lmf_mix) 및 하이퍼파라미터 튜닝을 진행하여 최종 점수 확인 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8681a8c",
   "metadata": {},
   "source": [
    "# 7. hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67775ea",
   "metadata": {},
   "source": [
    "## 7-1. ALS MF hypter parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "8f63d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "als_mf_hyper_parameter = {'factor':[],'regularization':[],'iteration':[],'NDCG':[],'entropy':[]}\n",
    "\n",
    "factors = [5]\n",
    "regularizations = [0.01]\n",
    "iterations = [5]\n",
    "\n",
    "for factor in factors:\n",
    "    for regularization in regularizations:\n",
    "        for iteration in iterations:\n",
    "            als_model = ALS(factors=factor, regularization=regularization, iterations = iteration, random_state=42)\n",
    "            als_model.fit(purchase_sparse, show_progress=False)\n",
    "\n",
    "            # 신규 유저인 경우 mp로 넣기\n",
    "            # 전체 도서에 대한 판매 만큼 정렬 후 넣기\n",
    "            most_popular_list = most_popular.sort_values(by='customer_id',ascending=False).index\n",
    "\n",
    "            # test 예측값, 이미 구매 했을 경우 제외\n",
    "            als_predict_list = []\n",
    "            for user_id in test['customer_id'].unique():\n",
    "                try:\n",
    "                    result = als_model.recommend(userIdToIndex[user_id], purchase_sparse[userIdToIndex[user_id]], N=15)\n",
    "                    als_predict_list.append({'id':user_id ,'items':[indexToPdId[num] for num in result[0]]})\n",
    "                except:\n",
    "                    train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "                    als_predict_list.append({'id':user_id ,'items':[most_popular.product_ids.loc[num] for num in most_popular_list \\\n",
    "                                                                        if most_popular.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                                        ]})\n",
    "\n",
    "            # 15 개만 예측하기\n",
    "            for idx, pred_list in enumerate(als_predict_list):\n",
    "                als_predict_list[idx]['items'] = pred_list['items'][:15]\n",
    "\n",
    "            # ALS \n",
    "            evaluator = CustomEvaluator()\n",
    "            ndcg, entropy = evaluator._eval(ground_trues, als_predict_list)\n",
    "\n",
    "            als_mf_hyper_parameter['factor'].append(factor)\n",
    "            als_mf_hyper_parameter['regularization'].append(regularization)\n",
    "            als_mf_hyper_parameter['iteration'].append(iteration)\n",
    "            als_mf_hyper_parameter['NDCG'].append(ndcg)\n",
    "            als_mf_hyper_parameter['entropy'].append(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "123852a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>regularization</th>\n",
       "      <th>iteration</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.053031</td>\n",
       "      <td>3.335207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   factor  regularization  iteration      NDCG   entropy\n",
       "0       5            0.01          5  0.053031  3.335207"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(als_mf_hyper_parameter).sort_values(by='NDCG',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17c5f24",
   "metadata": {},
   "source": [
    "## 7-2. LMF hypter parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "6f3f8134",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmf_hyper_parameter = {'factor':[],'regularization':[],'iteration':[],'NDCG':[],'entropy':[]}\n",
    "\n",
    "factors = [15]\n",
    "regularizations = [0.005]\n",
    "iterations = [50]\n",
    "\n",
    "for factor in factors:\n",
    "    for regularization in regularizations:\n",
    "        for iteration in iterations:\n",
    "            lmf_model = LMF(factors=factor, regularization=regularization, iterations = iteration, random_state=42)\n",
    "            lmf_model.fit(purchase_sparse, show_progress=False)\n",
    "            \n",
    "            # 신규 유저 mp로 넣기\n",
    "            most_popular_list = most_popular.sort_values(by='customer_id',ascending=False).index\n",
    "\n",
    "            # test 예측값\n",
    "            lmf_predict_list = []\n",
    "            for user_id in test['customer_id'].unique():\n",
    "                try:\n",
    "                    result = lmf_model.recommend(userIdToIndex[user_id], purchase_sparse[userIdToIndex[user_id]], N=20)\n",
    "                    lmf_predict_list.append({'id':user_id ,'items':[indexToPdId[num] for num in result[0]]})\n",
    "                except:\n",
    "                    train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "                    lmf_predict_list.append({'id':user_id ,'items':[most_popular.product_ids.loc[num] for num in most_popular_list \\\n",
    "                                                                        if most_popular.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                                        ]})\n",
    "\n",
    "            # 15 개만 예측하기\n",
    "            for idx, pred_list in enumerate(lmf_predict_list):\n",
    "                lmf_predict_list[idx]['items'] = pred_list['items'][:15]\n",
    "                \n",
    "            # LMF\n",
    "            evaluator = CustomEvaluator()\n",
    "            ndcg, entropy = evaluator._eval(ground_trues, lmf_predict_list)\n",
    "            \n",
    "            lmf_hyper_parameter['factor'].append(factor)\n",
    "            lmf_hyper_parameter['regularization'].append(regularization)\n",
    "            lmf_hyper_parameter['iteration'].append(iteration)\n",
    "            lmf_hyper_parameter['NDCG'].append(ndcg)\n",
    "            lmf_hyper_parameter['entropy'].append(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "d200968a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>regularization</th>\n",
       "      <th>iteration</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0.005</td>\n",
       "      <td>50</td>\n",
       "      <td>0.054209</td>\n",
       "      <td>3.551187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   factor  regularization  iteration      NDCG   entropy\n",
       "0      15           0.005         50  0.054209  3.551187"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lmf_hyper_parameter).sort_values(by='NDCG',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f833c11f",
   "metadata": {},
   "source": [
    "# medi popular & lmf MIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "9c515ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "medipop_lmf_mix_hyper_parameter = {'factor':[],'regularization':[],'iteration':[],'top':[],'NDCG':[],'entropy':[]}\n",
    "\n",
    "factors = [40]\n",
    "regularizations = [0.005]\n",
    "iterations = [50]\n",
    "tops = [3]\n",
    "\n",
    "for factor in factors:\n",
    "    for regularization in regularizations:\n",
    "        for iteration in iterations:\n",
    "            for top in tops:\n",
    "                lmf_model = LMF(factors=factor, regularization=regularization, iterations = iteration, random_state=42)\n",
    "                lmf_model.fit(purchase_sparse, show_progress=False)\n",
    "\n",
    "                # 신규 유저 mp로 넣기\n",
    "                most_popular_list = most_popular.sort_values(by='customer_id',ascending=False).index\n",
    "\n",
    "                # test 예측값\n",
    "                lmf_predict_list = []\n",
    "                for user_id in test['customer_id'].unique():\n",
    "                    try:\n",
    "                        train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "                        medi_popular_top_three = medistream_popular_list[:top]\n",
    "                        medi_popular_top_three_list = [medistream_prediction_preprop_df.product_ids.loc[num] for num in medi_popular_top_three \\\n",
    "                                                                            if medistream_prediction_preprop_df.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                                            ]\n",
    "                        result = lmf_model.recommend(userIdToIndex[user_id], purchase_sparse[userIdToIndex[user_id]], N=20)\n",
    "                        result_list = [indexToPdId[num] for num in result[0]]\n",
    "                        medi_pop_lmf_list = list(dict.fromkeys(medi_popular_top_three_list + result_list))\n",
    "                        lmf_predict_list.append({'id':user_id ,'items':medi_pop_lmf_list})\n",
    "                    except:\n",
    "                        train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "                        lmf_predict_list.append({'id':user_id ,'items':[medistream_prediction_preprop_df.product_ids.loc[num] for num in medistream_popular_list \\\n",
    "                                                                            if medistream_prediction_preprop_df.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                                            ]})\n",
    "\n",
    "                # 15 개만 예측하기\n",
    "                for idx, pred_list in enumerate(lmf_predict_list):\n",
    "                    lmf_predict_list[idx]['items'] = pred_list['items'][:15]\n",
    "\n",
    "                # LMF\n",
    "                evaluator = CustomEvaluator()\n",
    "                ndcg, entropy = evaluator._eval(ground_trues, lmf_predict_list)\n",
    "\n",
    "                medipop_lmf_mix_hyper_parameter['factor'].append(factor)\n",
    "                medipop_lmf_mix_hyper_parameter['regularization'].append(regularization)\n",
    "                medipop_lmf_mix_hyper_parameter['iteration'].append(iteration)\n",
    "                medipop_lmf_mix_hyper_parameter['top'].append(top)\n",
    "                medipop_lmf_mix_hyper_parameter['NDCG'].append(ndcg)\n",
    "                medipop_lmf_mix_hyper_parameter['entropy'].append(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "51b8e32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>regularization</th>\n",
       "      <th>iteration</th>\n",
       "      <th>top</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>0.005</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>0.061518</td>\n",
       "      <td>3.330821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   factor  regularization  iteration  top      NDCG   entropy\n",
       "0      40           0.005         50    3  0.061518  3.330821"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(medipop_lmf_mix_hyper_parameter).sort_values(by='NDCG',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "c3352a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_list = []\n",
    "for i in lmf_predict_list:\n",
    "    for a in i['items']:\n",
    "        mix_list.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "90754216",
   "metadata": {},
   "outputs": [],
   "source": [
    "medi_pop_list = []\n",
    "for i in medistream_predict_popular_list:\n",
    "    for a in i['items']:\n",
    "        medi_pop_list.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "43144de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 15)"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(mix_list)), len(set(medi_pop_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "aada93ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(mix_list)-set(medi_pop_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "2c6e1d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "744"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lmf_predict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f716977",
   "metadata": {},
   "source": [
    "# 8. 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb332430",
   "metadata": {},
   "source": [
    "- 각 모델은 하이퍼파라미터 튜닝한 결과로 최종 evalutation 진행\n",
    "- ALS MF: factor = 3 , regularizations = 0.01 , iterations = 5\n",
    "- LMF: factor = 15 , regularizations = 0.005 , iterations = 5\n",
    "- LMF & base model MP ensemble: factor = 40 , regularizations = 0.005 , iterations = 50 , tops = 3\n",
    "- 결과, ensemble(medi_mp_lmf_mix) 모델이 NDCG 0.061518 diversity 3.330821 로 base model(0.061266, 2.70805) 대비 모두 높은 점수를 보이는 것을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e233eeac",
   "metadata": {},
   "source": [
    "# 9. 최종결과 데이터프레임 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "2b8bdd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 131 days 13:31:51.843000\n",
      "test 총 기간: 21 days 05:53:44.939000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_day</th>\n",
       "      <th>last_day</th>\n",
       "      <th>train_데이터수</th>\n",
       "      <th>train_유저수</th>\n",
       "      <th>test_데이터수</th>\n",
       "      <th>test_유저수</th>\n",
       "      <th>test_신규유저수</th>\n",
       "      <th>test_신규아이템수</th>\n",
       "      <th>원본_test수</th>\n",
       "      <th>전처리진행test수</th>\n",
       "      <th>als_mf</th>\n",
       "      <th>lmf</th>\n",
       "      <th>medi_mp_lmf_mix</th>\n",
       "      <th>mp</th>\n",
       "      <th>medi_popular</th>\n",
       "      <th>latest</th>\n",
       "      <th>oldest</th>\n",
       "      <th>high_price</th>\n",
       "      <th>low_price</th>\n",
       "      <th>name_sort</th>\n",
       "      <th>als_mf_entropy</th>\n",
       "      <th>lmf_entropy</th>\n",
       "      <th>medi_mp_lmf_mix_entropy</th>\n",
       "      <th>mp_entropy</th>\n",
       "      <th>medi_popular_entropy</th>\n",
       "      <th>latest_entropy</th>\n",
       "      <th>oldest_entropy</th>\n",
       "      <th>high_price_entropy</th>\n",
       "      <th>low_price_entropy</th>\n",
       "      <th>name_sort_entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-13 2022-08-22</td>\n",
       "      <td>2022-08-23 2022-09-13</td>\n",
       "      <td>2887</td>\n",
       "      <td>1482</td>\n",
       "      <td>974</td>\n",
       "      <td>744</td>\n",
       "      <td>514</td>\n",
       "      <td>11</td>\n",
       "      <td>974</td>\n",
       "      <td>384</td>\n",
       "      <td>0.053031</td>\n",
       "      <td>0.054209</td>\n",
       "      <td>0.061518</td>\n",
       "      <td>0.053802</td>\n",
       "      <td>0.061266</td>\n",
       "      <td>0.016588</td>\n",
       "      <td>0.015806</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>3.335207</td>\n",
       "      <td>3.551187</td>\n",
       "      <td>3.330821</td>\n",
       "      <td>2.742936</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               first_day               last_day  train_데이터수  train_유저수  \\\n",
       "0  2022-04-13 2022-08-22  2022-08-23 2022-09-13        2887       1482   \n",
       "\n",
       "   test_데이터수  test_유저수  test_신규유저수  test_신규아이템수  원본_test수  전처리진행test수  \\\n",
       "0        974       744         514           11       974         384   \n",
       "\n",
       "     als_mf       lmf  medi_mp_lmf_mix        mp  medi_popular    latest  \\\n",
       "0  0.053031  0.054209         0.061518  0.053802      0.061266  0.016588   \n",
       "\n",
       "     oldest  high_price  low_price  name_sort  als_mf_entropy  lmf_entropy  \\\n",
       "0  0.015806    0.003865   0.001136   0.007651        3.335207     3.551187   \n",
       "\n",
       "   medi_mp_lmf_mix_entropy  mp_entropy  medi_popular_entropy  latest_entropy  \\\n",
       "0                 3.330821    2.742936               2.70805         2.70805   \n",
       "\n",
       "   oldest_entropy  high_price_entropy  low_price_entropy  name_sort_entropy  \n",
       "0         2.70805             2.70805            2.70805            2.70805  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_prediction_df = {'first_day':[],'last_day':[],'train_데이터수':[],'train_유저수':[],'test_데이터수':[],\\\n",
    "    'test_유저수':[],'test_신규유저수':[],'test_신규아이템수':[],'원본_test수':[],'전처리진행test수':[],\\\n",
    "    'als_mf':[],'lmf':[],'medi_mp_lmf_mix':[],'mp':[],'medi_popular':[],'latest':[],\\\n",
    "    'oldest':[],'high_price':[],'low_price':[],'name_sort':[],\\\n",
    "     'als_mf_entropy':[],'lmf_entropy':[],'medi_mp_lmf_mix_entropy':[],'mp_entropy':[],'medi_popular_entropy':[],'latest_entropy':[],\\\n",
    "     'oldest_entropy':[],'high_price_entropy':[],'low_price_entropy':[],'name_sort_entropy':[]}\n",
    "medistream_predict_df = pd.DataFrame(medistream_predict_score)\n",
    "\n",
    "all_prediction_df['first_day'].append(str(datetime.date(train['date_paid'].min()))+' '+str(datetime.date(train['date_paid'].max())))\n",
    "all_prediction_df['last_day'].append(str(datetime.date(test['date_paid'].min()))+' '+str(datetime.date(test['date_paid'].max())))\n",
    "all_prediction_df['train_데이터수'].append(len(train))\n",
    "all_prediction_df['train_유저수'].append(len(set(train.customer_id)))\n",
    "all_prediction_df['test_데이터수'].append(len(test))\n",
    "all_prediction_df['test_유저수'].append(len(set(test.customer_id)))\n",
    "all_prediction_df['test_신규유저수'].append(len(set(test['customer_id'].unique())- set(train['customer_id'].unique())))\n",
    "all_prediction_df['test_신규아이템수'].append(len(set(test_before_preprocess.product_ids.unique())-set(train_before_preprocess.product_ids.unique())))\n",
    "all_prediction_df['원본_test수'].append(len(test))\n",
    "all_prediction_df['전처리진행test수'].append(len(if_prepro_test))\n",
    "\n",
    "# ndcg\n",
    "all_prediction_df['als_mf'].append(pd.DataFrame(als_mf_hyper_parameter).sort_values(by='NDCG',ascending=False)['NDCG'].iloc[0])\n",
    "all_prediction_df['lmf'].append(pd.DataFrame(lmf_hyper_parameter).sort_values(by='NDCG',ascending=False)['NDCG'].iloc[0])\n",
    "all_prediction_df['medi_mp_lmf_mix'].append(pd.DataFrame(medipop_lmf_mix_hyper_parameter).sort_values(by='NDCG',ascending=False)['NDCG'].iloc[0])\n",
    "all_prediction_df['mp'].append(evaluator._eval(ground_trues, predict_popular_list)[0])\n",
    "all_prediction_df['medi_popular'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='medi_popular'].iloc[0]['ndcg'])\n",
    "all_prediction_df['latest'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='latest'].iloc[0]['ndcg'])\n",
    "all_prediction_df['oldest'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='oldest'].iloc[0]['ndcg'])\n",
    "all_prediction_df['high_price'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='high_price'].iloc[0]['ndcg'])\n",
    "all_prediction_df['low_price'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='low_price'].iloc[0]['ndcg'])\n",
    "all_prediction_df['name_sort'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='name_sort'].iloc[0]['ndcg'])\n",
    "\n",
    "# entropy\n",
    "all_prediction_df['als_mf_entropy'].append(pd.DataFrame(als_mf_hyper_parameter).sort_values(by='entropy',ascending=False)['entropy'].iloc[0])\n",
    "all_prediction_df['lmf_entropy'].append(pd.DataFrame(lmf_hyper_parameter).sort_values(by='entropy',ascending=False)['entropy'].iloc[0])\n",
    "all_prediction_df['medi_mp_lmf_mix_entropy'].append(pd.DataFrame(medipop_lmf_mix_hyper_parameter).sort_values(by='entropy',ascending=False)['entropy'].iloc[0])\n",
    "all_prediction_df['mp_entropy'].append(evaluator._eval(ground_trues, predict_popular_list)[1])\n",
    "all_prediction_df['medi_popular_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='medi_popular'].iloc[0]['entropy'])\n",
    "all_prediction_df['latest_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='latest'].iloc[0]['entropy'])\n",
    "all_prediction_df['oldest_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='oldest'].iloc[0]['entropy'])\n",
    "all_prediction_df['high_price_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='high_price'].iloc[0]['entropy'])\n",
    "all_prediction_df['low_price_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='low_price'].iloc[0]['entropy'])\n",
    "all_prediction_df['name_sort_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='name_sort'].iloc[0]['entropy'])\n",
    "\n",
    "print('train 총 기간:',train['date_paid'].max()-train['date_paid'].min())\n",
    "print('test 총 기간:',test['date_paid'].max()-test['date_paid'].min())\n",
    "display(pd.DataFrame(all_prediction_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "a28b9aa23c5615677fbb5673a1ecf276ca01f87bbd89025c626bb21eb6d1bba4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
