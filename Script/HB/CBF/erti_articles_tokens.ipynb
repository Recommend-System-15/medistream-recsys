{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f1f80ab",
   "metadata": {},
   "source": [
    "etri api를 사용하여 형태소 분석 후 명사만 가져와 토큰화한다.  \n",
    "* 형태소 분석 (문어/구어) : \"morp\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc94612",
   "metadata": {},
   "source": [
    "# import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3189ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_rows', 4000)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8120ee71",
   "metadata": {},
   "source": [
    "# upload article data\n",
    "article의 title과 content를 합친 내용으로 토큰화 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c68f8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('/fastcampus-data/articles/articels_only_contents.json')\n",
    "df = df1.copy()\n",
    "\n",
    "# article의 title과 content를 합쳐 full_content라는 새로운 컬럼에 담는다.\n",
    "df[\"full_content\"] = df['title'] + ' ' + df['content_tag_removed']\n",
    "df = df[['id', 'title', 'full_content']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8e21a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_key = '8e216d4f-bfae-4cc4-ae6f-25f2dc4968c5' # 혜빈 키\n",
    "api_key = 'de384842-9f74-42c9-a0e5-036ecd76eab5' # 영수님 키"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8247a11e",
   "metadata": {},
   "source": [
    "언어 분석 기술 문어/구어 중 한가지만 선택해 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bac6efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# // 언어 분석 기술(문어)\n",
    "openApiURL = \"http://aiopen.etri.re.kr:8000/WiseNLU\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458b38f2",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ec9965",
   "metadata": {},
   "source": [
    "### 1. api로 불러온 data에서 필요한 정보 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cfcfb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETRISentenceAnalysis:\n",
    "    def __init__(self, api_key: dict, url: str):\n",
    "        self.api_key = api_key\n",
    "        self.url = url\n",
    "\n",
    "        self.http = urllib3.PoolManager()\n",
    "  \n",
    "    def _make_request_json(self, text: str, analysis_code: int) -> dict:\n",
    "        return {\n",
    "          \"access_key\": self.api_key,\n",
    "          \"argument\": {\n",
    "              \"text\": text,\n",
    "              \"analysis_code\": analysis_code\n",
    "              }\n",
    "          }\n",
    "\n",
    "    def _request(self, request_json: dict) -> object:\n",
    "        return self.http.request(\n",
    "            \"POST\",\n",
    "            openApiURL,\n",
    "            headers={\"Content-Type\": \"application/json; charset=UTF-8\"},\n",
    "            body=json.dumps(request_json)\n",
    "        )\n",
    "\n",
    "    # 형태소 분석 결과 출력\n",
    "    def get_analyzed_sentence(self, sentence: str, analysis_code: int) -> dict:\n",
    "        def _get_return_object(sentence: str) -> dict:\n",
    "            data = str(response.data, 'utf-8')\n",
    "            data = json.loads(data)\n",
    "\n",
    "\n",
    "            return data.get('return_object') \n",
    "\n",
    "        request_json = self._make_request_json(sentence, analysis_code)\n",
    "        response = self._request(request_json)\n",
    "\n",
    "        assert response.status == 200, f'Error {response.status}'\n",
    "\n",
    "        return _get_return_object(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d72a20fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "etri_sentence_analysis = ETRISentenceAnalysis(api_key, openApiURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f96be5c",
   "metadata": {},
   "source": [
    "### 2. 한글을 제외한 문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dc353e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re    \n",
    "df['full_content'] = df['full_content'].apply(lambda x: re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\", x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d7d4cf",
   "metadata": {},
   "source": [
    "### 3. 글자가 20글자 이하이거나, 내용이 NoneType인 아티클 제거\n",
    "총 31개. id로 접근함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bcf07c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(id_less_20) =  0\n",
      "id_less_20 =  []\n",
      "len(new_id) =  26\n",
      "new_id =  [15107, 15376, 18326, 17194, 22131, 27831, 27888, 24527, 29398, 29528, 28451, 28471, 30618, 29157, 27366, 27451, 29891, 33399, 32309, 33743, 33446, 34361, 34422, 35145, 35259, 36137]\n",
      "\n",
      "len(drop_id_list) =  26\n",
      "drop_id_list =  [15107, 15376, 18326, 30618, 28451, 33446, 36137, 17194, 32309, 28471, 27831, 34361, 27451, 35259, 29891, 35145, 24527, 33743, 29398, 29528, 29157, 27366, 27888, 22131, 34422, 33399]\n"
     ]
    }
   ],
   "source": [
    "# contents 글자가 20글자 이하인 아티클\n",
    "id_less_20 = []\n",
    "for i in range(len(df['full_content'])):\n",
    "    if len(df['full_content'][i]) < 20:\n",
    "#         print(i, df['full_content'][i])\n",
    "        id_less_20.append(df['id'][i])\n",
    "\n",
    "        \n",
    "print('len(id_less_20) = ',len(id_less_20))    \n",
    "print('id_less_20 = ',id_less_20)    \n",
    "\n",
    "# none type인 아티클\n",
    "type_none_idx = [1723, 1724, 1804, 1826, 2245, 2318, 2319, 2377, 2431, 2442, 2455, 2456, 2542, 2561, 2563, 2567, 2655, 2701, 2768, 2832, 2857, 2937, 2938, 2954, 3065, 3088] \n",
    "new_id = []\n",
    "# for i in range(len(df['content_tag_removed'])):\n",
    "for j in type_none_idx:\n",
    "    new_id.append(df.iloc[j].id)\n",
    "    \n",
    "print('len(new_id) = ',len(new_id))    \n",
    "print('new_id = ', new_id)    \n",
    "print()\n",
    "\n",
    "drop_id_list = list(set(id_less_20 + new_id))\n",
    "print('len(drop_id_list) = ',len(drop_id_list))\n",
    "print('drop_id_list = ', drop_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea647cc1",
   "metadata": {},
   "source": [
    "# corpus에 형태소 분석 결과 담기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7e3b9c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3438/3438 [18:59<00:00,  3.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3438"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    con = df['full_content'].iloc[i]\n",
    "    # 형태소 분석\n",
    "    data = etri_sentence_analysis.get_analyzed_sentence(con, 'morp')\n",
    "    corpus.append(data)\n",
    "       \n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14d03a7",
   "metadata": {},
   "source": [
    "# dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c4eaf1a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3438/3438 [01:56<00:00, 29.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# dataframe 초기화\n",
    "new_df = pd.DataFrame(df[['id','title','full_content']])\n",
    "new_df['tokens'] = None\n",
    "\n",
    "# dataframe 각 토큰 담기\n",
    "for i in tqdm(range(len(corpus))):\n",
    "    nouns = []\n",
    "    res3 = corpus[i]['sentence'][0]['morp'] # 형태소 결과\n",
    "    \n",
    "    for j in res3:\n",
    "        # 형태소가 명사이고 2글자 이상인 것만 담기\n",
    "        if j['type'] == 'NNG' and len(j['lemma']) > 1: \n",
    "            nouns.append(j['lemma'])\n",
    "            new_df['tokens'].iloc[i] = nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f045a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복되는 토큰제거\n",
    "new_df['tokens'] = new_df['tokens'].apply(lambda x: list(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1847e3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>full_content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>디스크탈출증 재흡수 케이스</td>\n",
       "      <td>디스크탈출증 재흡수 케이스  케이스의 종류  치료성공 케이스     환자 성별 나이...</td>\n",
       "      <td>[요추, 보존, 근력, 여자, 약화, 다리, 우측, 병력, 결론, 흡수, 운동, 계...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>여기에 질문하는거 맞나요?</td>\n",
       "      <td>여기에 질문하는거 맞나요  수고하십니다  자보환자가 한약 치료 끝나고 보험제제를 계...</td>\n",
       "      <td>[제제, 한약, 자보, 병원, 치료, 환자, 제품, 수고, 인정, 엑스, 보험, 질문]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>뒷목통증 좌측방사통을 주소로 내원한 환자</td>\n",
       "      <td>뒷목통증 좌측방사통을 주소로 내원한 환자   케이스의 종류    치료 성공 케이스 ...</td>\n",
       "      <td>[진료, 모근, 남자, 소실, 신전, 우측, 특별, 병력, 상기, 운동, 수술, 저...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46</td>\n",
       "      <td>퇴행성 관절염 환자 무릎에 물이 찬 경우.</td>\n",
       "      <td>퇴행성 관절염 환자 무릎에 물이 찬 경우  한의원에서 대응해서 할 수 있는 치료주사...</td>\n",
       "      <td>[퇴행, 경우, 대응, 무릎, 치료, 환자, 주사, 관절, 의원]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>비전형적인 Cauda equina syn.</td>\n",
       "      <td>비전형적인      케이스의 종류    함께 논의하고 싶은 케이스       환자 ...</td>\n",
       "      <td>[여자, 우측, 다리, 병력, 결론, 운동, 회음, 본인, 종류, 소변, 동반, 스...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                    title  \\\n",
       "0  43           디스크탈출증 재흡수 케이스   \n",
       "1  61           여기에 질문하는거 맞나요?   \n",
       "2  66   뒷목통증 좌측방사통을 주소로 내원한 환자   \n",
       "3  46  퇴행성 관절염 환자 무릎에 물이 찬 경우.   \n",
       "4  51  비전형적인 Cauda equina syn.   \n",
       "\n",
       "                                        full_content  \\\n",
       "0  디스크탈출증 재흡수 케이스  케이스의 종류  치료성공 케이스     환자 성별 나이...   \n",
       "1  여기에 질문하는거 맞나요  수고하십니다  자보환자가 한약 치료 끝나고 보험제제를 계...   \n",
       "2  뒷목통증 좌측방사통을 주소로 내원한 환자   케이스의 종류    치료 성공 케이스 ...   \n",
       "3  퇴행성 관절염 환자 무릎에 물이 찬 경우  한의원에서 대응해서 할 수 있는 치료주사...   \n",
       "4  비전형적인      케이스의 종류    함께 논의하고 싶은 케이스       환자 ...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [요추, 보존, 근력, 여자, 약화, 다리, 우측, 병력, 결론, 흡수, 운동, 계...  \n",
       "1   [제제, 한약, 자보, 병원, 치료, 환자, 제품, 수고, 인정, 엑스, 보험, 질문]  \n",
       "2  [진료, 모근, 남자, 소실, 신전, 우측, 특별, 병력, 상기, 운동, 수술, 저...  \n",
       "3               [퇴행, 경우, 대응, 무릎, 치료, 환자, 주사, 관절, 의원]  \n",
       "4  [여자, 우측, 다리, 병력, 결론, 운동, 회음, 본인, 종류, 소변, 동반, 스...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a4a073",
   "metadata": {},
   "source": [
    "# save to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5c37318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# new_df.to_json('/home/user_4/CBF/Token/final_tokens_article.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
