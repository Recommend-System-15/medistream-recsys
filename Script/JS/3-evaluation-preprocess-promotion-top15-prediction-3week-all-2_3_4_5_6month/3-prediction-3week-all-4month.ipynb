{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1758f1b3",
   "metadata": {},
   "source": [
    "# ALS 모델 기반 학습 및 평가 진행\n",
    "- 메디스트림의 order 데이터 기반으로 아이템 추천을 진행합니다.\n",
    "- 3개월치 데이터 중 도서 카테고리 아이템 추천을 진행합니다.\n",
    "- train test 나눈 후 prediction 과 real item의 NDCG score를 통해 평가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dbe592",
   "metadata": {},
   "source": [
    "# 추천 모델\n",
    "- ALS MF, LMF, MP (총 3개)\n",
    "- 총 3개의 추천을 진행하며 MF와 LMF 의 경우 콜드스타트 유저(신규 유저)인 경우 MP로 추천 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "053cf1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user_3/medistream-recsys/Script\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "import random\n",
    "import implicit\n",
    "from implicit.als import AlternatingLeastSquares as ALS\n",
    "\n",
    "%cd /home/user_3/medistream-recsys/Script\n",
    "from preprocessing import drop_columns,dict_to_column,dict_to_set,set_to_column,key_to_element\n",
    "\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5943a3d",
   "metadata": {},
   "source": [
    "# 1.Dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bfc0ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5141/5141 [00:00<00:00, 760167.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# products name 확인 용\n",
    "products_df = pd.read_json(\"/fastcampus-data/products/products.json\")\n",
    "products_df = key_to_element(['_id'],products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "392f7771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('/fastcampus-data/select_column_version_4.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a727bca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-05-13 08:59:21.151000+0000', tz='UTC')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "\n",
    "df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
    "# 3개월 전 날짜 확인\n",
    "df['date_paid'].max()-relativedelta(months=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b34a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_name_fill(product_name_preprocess_df):\n",
    "    # 각 마지막 product_ids, name으로 채우기\n",
    "    product_ids_to_name = {}\n",
    "    for idx, row in product_name_preprocess_df.iterrows():\n",
    "        product_ids_to_name[row.product_ids] = row.name_x\n",
    "    product_name_preprocess_df['name_x'] = product_name_preprocess_df['product_ids'].apply(lambda x: product_ids_to_name[x])\n",
    "\n",
    "    name_to_product_ids = {}\n",
    "    for idx, row in product_name_preprocess_df.iterrows():\n",
    "        name_to_product_ids[row.name_x] = row.product_ids\n",
    "    product_name_preprocess_df['product_ids'] = product_name_preprocess_df['name_x'].apply(lambda x: name_to_product_ids[x])\n",
    "    return product_name_preprocess_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92247728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# medirecommend 만들기\n",
    "df = df.dropna(subset=['product_ids','name_x'])\n",
    "\n",
    "# 나오는 개월 수 적기\n",
    "date_state = \"2022-05-13\"\n",
    "# paid orders만 가져오기\n",
    "df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
    "df_only_paid = df[~df['date_paid'].isna()]\n",
    "# 취소 안된 것만 가져오기\n",
    "complete_df = df_only_paid[(df_only_paid['paid'] == True) & (df_only_paid['cancelled']==False)]\n",
    "# 도서 카테고리만 가져오기\n",
    "only_book = complete_df[complete_df['name'] == '도서']\n",
    "\n",
    "# 유저가 중복으로 아이템 구매 삭제\n",
    "df_duplicated_book = only_book.drop_duplicates(subset=['customer_id','product_ids'])\n",
    "\n",
    "df_sort = df_duplicated_book.sort_values(by='date_paid').reset_index(drop=True)\n",
    "df_sort = product_name_fill(df_sort)\n",
    "df_sort = df_sort.drop_duplicates(subset=['customer_id','product_ids']).reset_index(drop=True)\n",
    "\n",
    "# 3개월치 데이터만 가져오기\n",
    "df_book = df_sort[df_sort['date_paid'] >= date_state].reset_index(drop=True)\n",
    "\n",
    "# 마지막 3주 제외한 medirecommend 만들기\n",
    "mediprediction_all_df = df_sort[df_sort['date_paid'] < '2022-08-23'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05871ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id                0\n",
       "date_created       0\n",
       "regular_price      0\n",
       "sale_price         0\n",
       "three_months       0\n",
       "date_paid          0\n",
       "customer_id        0\n",
       "paid               0\n",
       "name_x             0\n",
       "category_id_y      0\n",
       "product_ids        0\n",
       "quantity           0\n",
       "price              0\n",
       "price_total        0\n",
       "age_group        890\n",
       "한의사 여부             1\n",
       "사업자 여부             1\n",
       "cancelled          0\n",
       "name               0\n",
       "slug               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# none 값 확인하기\n",
    "df_book.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1485275",
   "metadata": {},
   "source": [
    "## 전체 데이터 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee8c91fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 전: 38395 중복 제거 후: 5796\n"
     ]
    }
   ],
   "source": [
    "print('중복 제거 전:',len(only_book), '중복 제거 후:',len(df_book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c882d891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 수: 5796\n"
     ]
    }
   ],
   "source": [
    "print('전체 데이터 수:',len(df_book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80095379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아이템 수: 249 유저 수: 2634\n"
     ]
    }
   ],
   "source": [
    "print('아이템 수:',len(df_book.product_ids.unique()),'유저 수:',len(df_book.customer_id.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c21921e",
   "metadata": {},
   "source": [
    "# promotion 전처리 함수\n",
    "- train 만 전처리하여 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c14a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promotion_proprof(df):\n",
    "    from datetime import datetime\n",
    "\n",
    "    preprocessed_book_df_date = df.copy()\n",
    "\n",
    "    promotion_book_df = preprocessed_book_df_date[preprocessed_book_df_date['date_paid'] >= '2022-01-01']\n",
    "    promotion_book_df['date_paid_date'] = promotion_book_df['date_paid'].dt.date\n",
    "    promotion_book_df['date_paid_week'] = promotion_book_df['date_paid_date'].apply(lambda x: x.isocalendar()[1])\n",
    "\n",
    "    promotion_dict = {\n",
    "        2:['트리거포인트 침치료'],\n",
    "        3:['藥徵, 약의 징표','파킨슨병 한의진료','침의 과학적 접근의 이해','길익동동','Medical acupuncture 침의 과학적 접근과 임상활용',\\\n",
    "          '동의보감 약선','수화론(水火論)'],\n",
    "        4:['실전한약가이드','음양승강으로 해석하는 사상의학: 생리병리'],\n",
    "        5:['음양승강으로 해석하는 사상의학: 생리병리'],\n",
    "        6:['윤상훈·권병조의 알짜 근육학','임상 한의사를 위한 기본 한약처방 강의 2판','트리거포인트 침치료','KCD 한방내과 진찰진단 가이드라인',\\\n",
    "          '실전한약가이드','음양승강으로 해석하는 사상의학: 생리병리','藥徵, 약의 징표','증보운곡본초학','통증치료를 위한 근육 초음파와 주사 테크닉'],\n",
    "        7:['오국통 온병명방'],\n",
    "        9:['병태생리 Visual map','NEO 인턴 핸드북','보험한약 브런치 the # 2판 개정판','Kendall 자세와 통증치료에 있어서 근육의 기능과 검사 5판',\\\n",
    "          '사상방 사용설명서','실전한약가이드','일차진료 한의사를 위한 보험한약입문 - 둘째 판','증보운곡본초학'],\n",
    "        10:['한눈에 보는 스트레칭 해부학'],\n",
    "        11:['임산부에게 사용할 수 있는 한방처방'],\n",
    "        12:['임산부에게 사용할 수 있는 한방처방'],\n",
    "        13:['MRI 자신감 키우기_족부편'],\n",
    "        14:['장골의 PI 변위는 없다'],\n",
    "        15:['윤상훈·권병조의 알짜 근육학','임상 한의사를 위한 기본 한약처방 강의 2판','KCD 한방내과 진찰진단 가이드라인','트리거포인트 침치료',\\\n",
    "           '음양승강으로 해석하는 사상의학: 생리병리','침의 과학적 접근의 이해','실전한약가이드','임산부에게 사용할 수 있는 한방처방','한눈에 보는 스트레칭 해부학',\\\n",
    "           'MRI 자신감 키우기_족부편'],\n",
    "        16:['환자상담의 달인','병의원 경영과 자산 관리 클리닉','우리 병원의 문제? 현장에서 답을 찾다!','근육학','스파이랄 및 키네지오 테이핑',\\\n",
    "           '요양병원 주치의 진료핵심'],\n",
    "        17:['오당 본초강론','운동기능장애 치료 매뉴얼','K. 한의학 임상총론','한방 활용 가이드','최강통증매선','암 치료에 이용되는 천연약물',\\\n",
    "           '왕문원 임상 평형침법','중국 왕문원 평형침구학'],\n",
    "        18:['초음파 가이드 근골격계 통증 치료의 정석'],\n",
    "        19:['초음파 가이드 근골격계 통증 치료의 정석','섭혜민 명의경방험안'],\n",
    "        20:['카이로프랙틱 기본테크닉론'],\n",
    "        21:['흔히보는 정형외과 외래진료 가이드북'],\n",
    "        22:['趙紹琴(조소금) 내과학','한의학 상담','숨찬 세상, 호흡기를 편하게',\\\n",
    "         '의학심오(醫學心悟)','안면마비 침구치료','중경서 독법 강해(상,하) /개정판'],\n",
    "        23:['선생님, 이제 그만 저 좀 포기해 주세요','한의학 상담','숨찬 세상, 호흡기를 편하게',\\\n",
    "        '의학심오(醫學心悟)','중경서 독법 강해(상,하) /개정판','안면마비 침구치료'],\n",
    "     24:['황황교수의 임상의를 위한 근거기반 상한금궤 처방 매뉴얼','황황교수의 개원 한의사를 위한 상한금궤 처방 강의록',\\\n",
    "        '선생님, 이제 그만 저 좀 포기해 주세요'],\\\n",
    "     25:['황황교수의 임상의를 위한 근거기반 상한금궤 처방 매뉴얼',\\\n",
    "       '황황교수의 개원 한의사를 위한 상한금궤 처방 강의록','약침의 정석 –통증편','갑상선 진료 완전정복',\\\n",
    "       '신경학 증상의 감별법','이것이 알고싶다! 당뇨병진료','어지럼질환의 진단과 치료','증례와 함께 하는 한약처방',\\\n",
    "       '뇌의학의 첫걸음','HAPPY 소아청소년 진료'],\\\n",
    "     26:['약침의 정석 –통증편','갑상선 진료 완전정복','신경학 증상의 감별법',\\\n",
    "       '증례와 함께 하는 한약처방','이것이 알고싶다! 당뇨병진료','HAPPY 소아청소년 진료','어지럼질환의 진단과 치료',\\\n",
    "       '뇌의학의 첫걸음','실전, 임상한의학 내과질환을 중심으로','실전, 임상한의학 알레르기질환','침구대성','평주온열경위'],\n",
    "     27:['침구과 진료매뉴얼','실전, 임상한의학 내과질환을 중심으로','실전, 임상한의학 알레르기질환','내과학 5권세트','한방순환 신경내과학',\\\n",
    "        '침구대성'],\n",
    "     28:['감별진단의 정석','기본통증진료학','약처방의 정석 (1, 2권 세트)','QBook: Case based Review',\\\n",
    "         'SMART 내과 1권 : 바이탈, 감염, 종양, 류마티스','일차진료아카데미 처방가이드'],\n",
    "     29:['비만문답','사암침의 해석과 임상'],\n",
    "     30:['플로차트 정형외과 진단','침구과 진료매뉴얼','내과학 5권세트','한방순환 신경내과학'],\n",
    "     31:['외래에서 꼭 알아야 할 통증증후군 137가지'],\n",
    "     32:['SMART 기본 일차진료매뉴얼 3판(세트)','SMART 소아진료매뉴얼 3판','SMART 응급진료매뉴얼(세트)'],\n",
    "     33:['SMART 기본 일차진료매뉴얼 3판(세트)','SMART 소아진료매뉴얼 3판','SMART 응급진료매뉴얼(세트)'],\n",
    "     34:['초음파 유도하 침 시술 가이드북'],\n",
    "     35:['영어 진료 가이드북','초음파 유도하 침 시술 가이드북'],\n",
    "     36:['영어 진료 가이드북','소아피부질환해설'],\n",
    "     37:['소아피부질환해설','醫學心悟(의학심오) 톺아보기'],}\n",
    "\n",
    "    promotion_item_list = []\n",
    "    for promotion_items in promotion_dict.values():\n",
    "        for item in promotion_items:\n",
    "            promotion_item_list.append(item)\n",
    "\n",
    "    # set(promotion_item_list), len(set(promotion_item_list))\n",
    "\n",
    "    preprocess_promotion_df = promotion_book_df[~((promotion_book_df['name_x'].str.contains('침의 과학적 접근과 임상활용')) & \\\n",
    "                            (promotion_book_df['date_paid_week']==3))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('의학심오')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==22))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('의학심오')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==23))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('약처방의 정석')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==28))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('초음파 유도하 침')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==34))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('초음파 유도하 침')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==34))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('영어 진료 가이드북')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==35))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('영어 진료 가이드북')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==36))]\n",
    "    all_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('의학심오')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==37))]\n",
    "\n",
    "    for key,value in promotion_dict.items():\n",
    "        all_promotion_df = all_promotion_df[~((all_promotion_df['name_x'].isin(value)) & (all_promotion_df['date_paid_week']==key))]\n",
    "    \n",
    "    return all_promotion_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbebd6a1",
   "metadata": {},
   "source": [
    "# 2.train test split\n",
    "- 마지막 3주 분량을 test로 선정합니다.\n",
    "- train 없는 test 아이템을 삭제 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "054c8f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-09-13 08:51:40+0000', tz='UTC')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "df_book['date_paid'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57fcec3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 8, 23, 0, 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime(2022,9,13)-timedelta(days=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0aad083",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2022-08-23'\n",
    "train_before = df_book[df_book['date_paid'] < date]\n",
    "train_before_preprocess = promotion_proprof(train_before)\n",
    "test_before_preprocess = df_book[df_book['date_paid'] >= date]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30999e38",
   "metadata": {},
   "source": [
    "## 전체 아이템 중복 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc90f9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249, 249)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# product_ids, name_x 수는 일치\n",
    "len(df_book.product_ids.unique()), len(df_book.name_x.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cea01f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복 제거 후 수 비교 확인\n",
    "# 252로 일치하여 문제 없음\n",
    "len(df_book.drop_duplicates(subset=['product_ids','name_x']).name_x.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae44431e",
   "metadata": {},
   "source": [
    "## train test 아이템 중복 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "137c94be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233, 131)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_before_preprocess.product_ids.unique()),len(test_before_preprocess.product_ids.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e70aeedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_before_preprocess.product_ids.unique())-set(test_before_preprocess.product_ids.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdf1afc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 아이템에 train 없는 아이템 확인\n",
    "len(set(test_before_preprocess.product_ids.unique())-set(train_before_preprocess.product_ids.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acd3352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 만 있는 item 제거\n",
    "only_test_items = set(test_before_preprocess.product_ids.unique())-set(train_before_preprocess.product_ids.unique())\n",
    "if_prepro_test = test_before_preprocess[~test_before_preprocess['product_ids'].isin(only_test_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fde2d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_before_preprocess.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2a94995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 변수 명 변경\n",
    "train = train_before_preprocess.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e35c9ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 test 수: 974\n",
      "전처리 진행했을 경우 test 수: 384\n"
     ]
    }
   ],
   "source": [
    "# test 전처리 진행했을 경우\n",
    "print('원본 test 수:', len(test))\n",
    "print('전처리 진행했을 경우 test 수:', len(if_prepro_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24a4b77",
   "metadata": {},
   "source": [
    "# train test eda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952ba9d0",
   "metadata": {},
   "source": [
    "### 전처리 전후 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25e9863f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 전처리 전: 2220 train 전처리 후: 2220\n"
     ]
    }
   ],
   "source": [
    "print('train 전처리 전:',len(train_before_preprocess), 'train 전처리 후:',len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bacd384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 전처리 전: 974 test 전처리 후: 974\n"
     ]
    }
   ],
   "source": [
    "print('test 전처리 전:',len(test_before_preprocess), 'test 전처리 후:',len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9797c9d0",
   "metadata": {},
   "source": [
    "### user 수 비교 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e702d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 유저 수: 1212\n"
     ]
    }
   ],
   "source": [
    "print('train 유저 수:',len(train.customer_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2d4c5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 유저 수: 744\n"
     ]
    }
   ],
   "source": [
    "print('test 유저 수:',len(test.customer_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18e1b5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 만 있는 신규 유저 : 544\n"
     ]
    }
   ],
   "source": [
    "# 신규 유저는 MP 같은 다른 방법으로 추천 진행해야 함\n",
    "print('test 만 있는 신규 유저 :',len(set(test['customer_id'].unique())- set(train['customer_id'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197dd8fb",
   "metadata": {},
   "source": [
    "### item 개수 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3aba7272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 아이템 수 : 233 test 아이템 수 : 131\n"
     ]
    }
   ],
   "source": [
    "print('train 아이템 수 :',len(set(train.product_ids)), 'test 아이템 수 :',len(set(test.product_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "102316b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 만 있는 아이템 수: 113\n"
     ]
    }
   ],
   "source": [
    "print('train 만 있는 아이템 수:',  len(set(train.product_ids)-set(test.product_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41589650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 만 있는 아이템 수: 11\n"
     ]
    }
   ],
   "source": [
    "print('test 만 있는 아이템 수:', len(set(test.product_ids) - set(train.product_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19564e8",
   "metadata": {},
   "source": [
    "# 3. sparse matrix 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf19f8d",
   "metadata": {},
   "source": [
    "## ALS MF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbfcb32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PdIds = train.product_ids.unique()\n",
    "\n",
    "PdIdToIndex = {}\n",
    "indexToPdId = {}\n",
    "\n",
    "colIdx = 0\n",
    "\n",
    "for PdId in PdIds:\n",
    "    PdIdToIndex[PdId] = colIdx\n",
    "    indexToPdId[colIdx] = PdId\n",
    "    colIdx += 1\n",
    "    \n",
    "userIds = train.customer_id.unique()\n",
    "\n",
    "userIdToIndex = {}\n",
    "indexToUserId = {}\n",
    "\n",
    "rowIdx = 0\n",
    "\n",
    "for userId in userIds:\n",
    "    userIdToIndex[userId] = rowIdx\n",
    "    indexToUserId[rowIdx] = userId\n",
    "    rowIdx += 1\n",
    "\n",
    "import scipy.sparse as sp\n",
    "\n",
    "rows = []\n",
    "cols = []\n",
    "vals = []\n",
    "\n",
    "for row in train.itertuples():\n",
    "    rows.append(userIdToIndex[row.customer_id])\n",
    "    cols.append(PdIdToIndex[row.product_ids])\n",
    "    vals.append(1)\n",
    "\n",
    "purchase_sparse = sp.csr_matrix((vals, (rows, cols)), shape=(rowIdx,colIdx))\n",
    "\n",
    "matrix = purchase_sparse.todense()\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f283e658",
   "metadata": {},
   "source": [
    "### Most_popular_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a75fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular = mediprediction_all_df.groupby(['product_ids']).count()['customer_id'].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88fa623",
   "metadata": {},
   "source": [
    "### Medistream_prediction_matrix\n",
    "- 메디스트림 메디마켓에서 제공하는 정렬 추천 성능 비교를 위한 df 구현\n",
    "- 인기도순, 최신순, 과거순, 높은 가격순, 낮은 가격순, 이름순 (총 6 가지)\n",
    "- 각각 구현해보고 학습 모델 대비 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70704fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-274709b685cd>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n"
     ]
    }
   ],
   "source": [
    "medistream_prediction_df = mediprediction_all_df[['date_created','regular_price','sale_price','three_months','product_ids','name_x']]\n",
    "medistream_prediction_preprop_df = medistream_prediction_df.drop_duplicates(subset=['product_ids'], ignore_index=True)\n",
    "medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
    "# sale_prices가 0이면 regular_price 값으로 채워넣어야하는데 0이 없음(전처리 필요 무)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca1abb4",
   "metadata": {},
   "source": [
    "# Sparsity 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47f55717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.21386988484257"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sparsity: 얼마나 비어있나?\n",
    "matrix_size = purchase_sparse.shape[0]* purchase_sparse.shape[1]\n",
    "num_purchases = len(purchase_sparse.nonzero()[0])\n",
    "sparsity = 100 * (1 - (num_purchases / matrix_size))\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbe9ba0",
   "metadata": {},
   "source": [
    "# 4. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641764ad",
   "metadata": {},
   "source": [
    "## Model 학습 진행\n",
    "- real test 만들기\n",
    "- implict 라이브러리 사용(MF,LMF)\n",
    "- MF 구현 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8adfc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real test \n",
    "ground_trues = []\n",
    "for user_id in test['customer_id'].unique():\n",
    "    ground_trues.append({'id': user_id,\\\n",
    "    'items':list(test[test['customer_id']==user_id].product_ids)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b4b0d1",
   "metadata": {},
   "source": [
    "## ALS fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71f6003c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5fc609dbd148c79d03bf5d811321b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "als_model = ALS(factors=20, regularization=0.01, iterations = 50, random_state=42)\n",
    "als_model.fit(purchase_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25274f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item, user vector 추출\n",
    "als_item_factors = als_model.item_factors\n",
    "als_user_factors = als_model.user_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eefa9052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((233, 20), (1212, 20))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 shape 확인\n",
    "als_item_factors.shape, als_user_factors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9085617c",
   "metadata": {},
   "source": [
    "## LMF fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "515f2663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.lmf import LogisticMatrixFactorization as LMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aea5ab56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f020e1ca92451092775eaf5963e0b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lmf_model = LMF(factors=20, regularization=0.001, iterations = 20, random_state=42)\n",
    "lmf_model.fit(purchase_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a49d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmf_item_factors = lmf_model.item_factors\n",
    "lmf_user_factors = lmf_model.user_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c983490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1212, 22), (233, 22))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmf_user_factors.shape, lmf_item_factors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd609a",
   "metadata": {},
   "source": [
    "# 5. prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814fddf3",
   "metadata": {},
   "source": [
    "# ALS mf prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c88db67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신규 유저인 경우 mp로 넣기\n",
    "# 전체 도서에 대한 판매 만큼 정렬 후 넣기\n",
    "most_popular_list = most_popular.sort_values(by='customer_id',ascending=False).index\n",
    "\n",
    "# test 예측값, 이미 구매 했을 경우 제외\n",
    "als_predict_list = []\n",
    "for user_id in test['customer_id'].unique():\n",
    "    try:\n",
    "        result = als_model.recommend(userIdToIndex[user_id], purchase_sparse[userIdToIndex[user_id]], N=15)\n",
    "        als_predict_list.append({'id':user_id ,'items':[indexToPdId[num] for num in result[0]]})\n",
    "    except:\n",
    "        train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "        als_predict_list.append({'id':user_id ,'items':[most_popular.product_ids.loc[num] for num in most_popular_list \\\n",
    "                                                            if most_popular.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                            ]})\n",
    "        \n",
    "# 15 개만 예측하기\n",
    "for idx, pred_list in enumerate(als_predict_list):\n",
    "    als_predict_list[idx]['items'] = pred_list['items'][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeb62cc",
   "metadata": {},
   "source": [
    "# ALS mf & latest prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f95d1da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신규 유저인 경우 mp로 넣기\n",
    "# 전체 도서에 대한 판매 만큼 정렬 후 넣기\n",
    "medistream_latest_list = medistream_prediction_preprop_df.sort_values(by='date_created', ascending=False).index\n",
    "\n",
    "# test 예측값, 이미 구매 했을 경우 제외\n",
    "als_latest_predict_list = []\n",
    "for user_id in test['customer_id'].unique():\n",
    "    try:\n",
    "        result = als_model.recommend(userIdToIndex[user_id], purchase_sparse[userIdToIndex[user_id]], N=15)\n",
    "        als_latest_predict_list.append({'id':user_id ,'items':[indexToPdId[num] for num in result[0]]})\n",
    "    except:\n",
    "        train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "        als_latest_predict_list.append({'id':user_id ,'items':[medistream_prediction_preprop_df.product_ids.loc[num] for num in medistream_latest_list \\\n",
    "                                                            if medistream_prediction_preprop_df.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                            ]})\n",
    "        \n",
    "# 15 개만 예측하기\n",
    "for idx, pred_list in enumerate(als_latest_predict_list):\n",
    "    als_latest_predict_list[idx]['items'] = pred_list['items'][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee59f90",
   "metadata": {},
   "source": [
    "# LMF prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7551f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신규 유저 mp로 넣기\n",
    "most_popular_list = most_popular.sort_values(by='customer_id',ascending=False).index\n",
    "\n",
    "# test 예측값\n",
    "lmf_predict_list = []\n",
    "for user_id in test['customer_id'].unique():\n",
    "    try:\n",
    "        result = lmf_model.recommend(userIdToIndex[user_id], purchase_sparse[userIdToIndex[user_id]], N=15)\n",
    "        lmf_predict_list.append({'id':user_id ,'items':[indexToPdId[num] for num in result[0]]})\n",
    "    except:\n",
    "        train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "        lmf_predict_list.append({'id':user_id ,'items':[most_popular.product_ids.loc[num] for num in most_popular_list \\\n",
    "                                                            if most_popular.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                            ]})\n",
    "        \n",
    "# 15 개만 예측하기\n",
    "for idx, pred_list in enumerate(lmf_predict_list):\n",
    "    lmf_predict_list[idx]['items'] = pred_list['items'][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65633ab7",
   "metadata": {},
   "source": [
    "# most popular prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1f592ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 도서에 대한 판매 만큼 정렬 후 넣기\n",
    "most_popular_list = most_popular.sort_values(by='customer_id',ascending=False).index\n",
    "\n",
    "# test 예측값, 이미 구매 했을 경우 제외\n",
    "predict_popular_list = []\n",
    "for user_id in test['customer_id'].unique():\n",
    "    train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "    predict_popular_list.append({'id':user_id ,'items':[most_popular.product_ids.loc[num] for num in most_popular_list \\\n",
    "                                                            if most_popular.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                            ]})\n",
    "\n",
    "# 15 개만 예측하기\n",
    "for idx, pred_list in enumerate(predict_popular_list):\n",
    "    predict_popular_list[idx]['items'] = pred_list['items'][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90829334",
   "metadata": {},
   "source": [
    "# medistream prediction\n",
    "- 메디스트림 메디마켓에서 제공하는 정렬 추천 성능 비교\n",
    "- 인기도순, 최신순, 과거순, 높은 가격순, 낮은 가격순, 이름순 (총 6 가지)\n",
    "- 각각 구현해보고 학습 모델 대비 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6284210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인기도순\n",
    "medistream_popular_list = medistream_prediction_preprop_df.sort_values(by='three_months', ascending=False).index\n",
    "# 최신순\n",
    "medistream_latest_list = medistream_prediction_preprop_df.sort_values(by='date_created', ascending=False).index\n",
    "# 오랜된 순\n",
    "medistream_oldest_list = medistream_prediction_preprop_df.sort_values(by='date_created', ascending=True).index\n",
    "# 높은 가격 순\n",
    "medistream_high_price_list = medistream_prediction_preprop_df.sort_values(by='sale_price', ascending=False).index\n",
    "# 낮은 가격 순\n",
    "medistream_low_price_list = medistream_prediction_preprop_df.sort_values(by='sale_price', ascending=True).index\n",
    "# 이름 순\n",
    "medistream_name_sort_list = medistream_prediction_preprop_df.sort_values(by='name_x',ascending=True).index\n",
    "\n",
    "def medistream_prediction_method(predict_num:int ,medi_predict_list:list)->list:\n",
    "    medistream_predict_list = []\n",
    "    for user_id in test['customer_id'].unique():\n",
    "        medistream_predict_list.append({'id':user_id ,'items':[medistream_prediction_preprop_df.product_ids.loc[num] \\\n",
    "                                                                       for num in medi_predict_list]})\n",
    "\n",
    "    # 15 개만 예측하기\n",
    "    for idx, pred_list in enumerate(medistream_predict_list):\n",
    "        medistream_predict_list[idx]['items'] = pred_list['items'][:predict_num]\n",
    "        \n",
    "    return medistream_predict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea82c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "medistream_predict_popular_list = medistream_prediction_method(15, medistream_popular_list)\n",
    "medistream_predict_latest_list = medistream_prediction_method(15, medistream_latest_list)\n",
    "medistream_predict_oldest_list = medistream_prediction_method(15, medistream_oldest_list)\n",
    "medistream_predict_high_price_list = medistream_prediction_method(15, medistream_high_price_list)\n",
    "medistream_predict_low_price_list = medistream_prediction_method(15, medistream_low_price_list)\n",
    "medistream_predict_name_sort_list = medistream_prediction_method(15, medistream_name_sort_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b5a451",
   "metadata": {},
   "source": [
    "# 6. evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0f739b",
   "metadata": {},
   "source": [
    "## NDCG & Entropy Diversity 평가지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2124a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEvaluator:\n",
    "    # relavence 모두 1로 동일하게 봄\n",
    "    def _idcg(self, l):\n",
    "        return sum((1.0 / np.log(i + 2) for i in range(l)))\n",
    "    \n",
    "\n",
    "    def __init__(self):\n",
    "        self._idcgs = [self._idcg(i) for i in range(1000)]\n",
    "    '''\n",
    "    idcgs 예시, item 3개 추천되므로 3.074281787960283 가 됩니다.\n",
    "    [0, 1.4426950408889634, 2.352934267515801, 3.074281787960283]\n",
    "    '''\n",
    "\n",
    "    def _ndcg(self, gt, rec):\n",
    "        dcg = 0.0\n",
    "        for i, r in enumerate(rec):\n",
    "            if r in gt:\n",
    "                dcg += 1.0 / np.log(i + 2)\n",
    "\n",
    "        return dcg / self._idcgs[len(gt)]\n",
    "    \n",
    "    def _entropy_diversity(self,rec_list):\n",
    "        import six\n",
    "        import math\n",
    "        \n",
    "        topn = len(rec_list[0]['items'])\n",
    "        users = [i.get('id',None) for i in rec_list]\n",
    "        sz = float(len(users)) * topn\n",
    "        freq = {}\n",
    "        for rec in rec_list:\n",
    "            for r in rec['items']:\n",
    "                freq[r] = freq.get(r, 0) + 1\n",
    "        ent = -sum([v / sz * math.log(v / sz) for v in six.itervalues(freq)])\n",
    "        return ent\n",
    "\n",
    "    def _eval(self, gt_list, rec_list):\n",
    "        gt_dict = {g[\"id\"]: g for g in gt_list}\n",
    "        ndcg_score = 0.0\n",
    "\n",
    "        for rec in rec_list:\n",
    "            gt = gt_dict[rec[\"id\"]]\n",
    "            ndcg_score += self._ndcg(gt[\"items\"], rec[\"items\"])\n",
    "\n",
    "\n",
    "        ndcg_score = ndcg_score / len(rec_list)\n",
    "        ent = self._entropy_diversity(rec_list)\n",
    "        \n",
    "        return ndcg_score, ent\n",
    "\n",
    "    def evaluate(self, gt_list, rec_list):\n",
    "        try:\n",
    "            ndcg_score, ent_score = self._eval(gt_list, rec_list)\n",
    "            print(f\"NDCG: {ndcg_score:.6}\")\n",
    "            print(f\"Entropy Diversity: {ent_score:.6} \")\n",
    "        except Exception as e:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7486873f",
   "metadata": {},
   "source": [
    "# ALS NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ea61210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.0472784\n",
      "Entropy Diversity: 3.64869 \n"
     ]
    }
   ],
   "source": [
    "# ALS \n",
    "evaluator = CustomEvaluator()\n",
    "evaluator.evaluate(ground_trues, als_predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "27e54eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(744, 744)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(als_predict_list),len(ground_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6cbc6795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아이템 맞춘 개수\n",
    "cnt = 0\n",
    "for gt, pred_list in zip(ground_trues, als_predict_list):\n",
    "    for pred in pred_list['items']:\n",
    "        if pred in gt['items']:\n",
    "            cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fec26b",
   "metadata": {},
   "source": [
    "# ALS & latest NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9bd2871e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.0145045\n",
      "Entropy Diversity: 3.71476 \n"
     ]
    }
   ],
   "source": [
    "# ALS \n",
    "evaluator = CustomEvaluator()\n",
    "evaluator.evaluate(ground_trues, als_latest_predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cd609da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(744, 744)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(als_latest_predict_list),len(ground_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e9081b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아이템 맞춘 개수\n",
    "cnt = 0\n",
    "for gt, pred_list in zip(ground_trues, als_latest_predict_list):\n",
    "    for pred in pred_list['items']:\n",
    "        if pred in gt['items']:\n",
    "            cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f58a979",
   "metadata": {},
   "source": [
    "# LMF NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2138e1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.0551962\n",
      "Entropy Diversity: 3.4347 \n"
     ]
    }
   ],
   "source": [
    "# ALS \n",
    "evaluator = CustomEvaluator()\n",
    "evaluator.evaluate(ground_trues, lmf_predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d087bb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(744, 744)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lmf_predict_list),len(ground_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7d61e38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아이템 맞춘 개수\n",
    "cnt = 0\n",
    "for gt, pred_list in zip(ground_trues, lmf_predict_list):\n",
    "    for pred in pred_list['items']:\n",
    "        if pred in gt['items']:\n",
    "            cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad479c",
   "metadata": {},
   "source": [
    "# most popular NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c0a471b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.0537963\n",
      "Entropy Diversity: 2.73685 \n"
     ]
    }
   ],
   "source": [
    "# most popular\n",
    "evaluator = CustomEvaluator()\n",
    "evaluator.evaluate(ground_trues, predict_popular_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4e693715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(744, 744)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict_popular_list),len(ground_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b1436bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아이템 맞춘 개수\n",
    "cnt = 0\n",
    "for gt, pred_list in zip(ground_trues, predict_popular_list):\n",
    "    for pred in pred_list['items']:\n",
    "        if pred in gt['items']:\n",
    "            cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fbb56c",
   "metadata": {},
   "source": [
    "## medistream prediction NDCG & Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "42cb74cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def medistream_prediction(ground_trues:list, predict_list:list):\n",
    "    evaluator = CustomEvaluator()\n",
    "    ndcg, entropy = evaluator._eval(ground_trues, predict_list)\n",
    "    \n",
    "    assert len(predict_list) == len(ground_trues)\n",
    "    \n",
    "    cnt = 0\n",
    "    for gt, pred_list in zip(ground_trues, predict_list):\n",
    "        for pred in pred_list['items']:\n",
    "            if pred in gt['items']:\n",
    "                cnt += 1\n",
    "    return ndcg, entropy, cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "69aed061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medistream_predict</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>entropy</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medi_popular</td>\n",
       "      <td>0.061266</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>latest</td>\n",
       "      <td>0.016588</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oldest</td>\n",
       "      <td>0.015806</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high_price</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>low_price</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>name_sort</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  medistream_predict      ndcg  entropy  cnt\n",
       "0       medi_popular  0.061266  2.70805  151\n",
       "1             latest  0.016588  2.70805   52\n",
       "2             oldest  0.015806  2.70805   45\n",
       "3         high_price  0.003865  2.70805   12\n",
       "4          low_price  0.001136  2.70805    7\n",
       "5          name_sort  0.007651  2.70805   22"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medistream_predict_score = {'medistream_predict':['medi_popular','latest','oldest','high_price','low_price','name_sort'], \\\n",
    "                            'ndcg':[], 'entropy':[], 'cnt':[]}\n",
    "\n",
    "medistream_predict_list = [medistream_predict_popular_list, medistream_predict_latest_list, medistream_predict_oldest_list,\\\n",
    "                          medistream_predict_high_price_list, medistream_predict_low_price_list, medistream_predict_name_sort_list]\n",
    "\n",
    "for medistream_predict in medistream_predict_list:\n",
    "    ndcg, entropy, cnt = medistream_prediction(ground_trues, medistream_predict)\n",
    "    medistream_predict_score['ndcg'].append(ndcg)\n",
    "    medistream_predict_score['entropy'].append(entropy)\n",
    "    medistream_predict_score['cnt'].append(cnt)\n",
    "pd.DataFrame(medistream_predict_score)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2163b6ce",
   "metadata": {},
   "source": [
    "- 최신순, 인기도 순으로 점수가 높게 나왔습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8681a8c",
   "metadata": {},
   "source": [
    "# 7. hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67775ea",
   "metadata": {},
   "source": [
    "## 7-1. ALS MF hypter parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8f63d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "als_mf_hyper_parameter = {'factor':[],'regularization':[],'iteration':[],'NDCG':[],'entropy':[]}\n",
    "\n",
    "factors = [5,10,15,20]\n",
    "regularizations = [0.01,0.005]\n",
    "iterations = [5,10,15,20,25,30,40,50]\n",
    "\n",
    "for factor in factors:\n",
    "    for regularization in regularizations:\n",
    "        for iteration in iterations:\n",
    "            als_model = ALS(factors=factor, regularization=regularization, iterations = iteration, random_state=42)\n",
    "            als_model.fit(purchase_sparse, show_progress=False)\n",
    "\n",
    "            # 신규 유저인 경우 mp로 넣기\n",
    "            # 전체 도서에 대한 판매 만큼 정렬 후 넣기\n",
    "            most_popular_list = most_popular.sort_values(by='customer_id',ascending=False).index\n",
    "\n",
    "            # test 예측값, 이미 구매 했을 경우 제외\n",
    "            als_predict_list = []\n",
    "            for user_id in test['customer_id'].unique():\n",
    "                try:\n",
    "                    result = als_model.recommend(userIdToIndex[user_id], purchase_sparse[userIdToIndex[user_id]], N=15)\n",
    "                    als_predict_list.append({'id':user_id ,'items':[indexToPdId[num] for num in result[0]]})\n",
    "                except:\n",
    "                    train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "                    als_predict_list.append({'id':user_id ,'items':[most_popular.product_ids.loc[num] for num in most_popular_list \\\n",
    "                                                                        if most_popular.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                                        ]})\n",
    "\n",
    "            # 15 개만 예측하기\n",
    "            for idx, pred_list in enumerate(als_predict_list):\n",
    "                als_predict_list[idx]['items'] = pred_list['items'][:15]\n",
    "\n",
    "            # ALS \n",
    "            evaluator = CustomEvaluator()\n",
    "            ndcg, entropy = evaluator._eval(ground_trues, als_predict_list)\n",
    "\n",
    "            als_mf_hyper_parameter['factor'].append(factor)\n",
    "            als_mf_hyper_parameter['regularization'].append(regularization)\n",
    "            als_mf_hyper_parameter['iteration'].append(iteration)\n",
    "            als_mf_hyper_parameter['NDCG'].append(ndcg)\n",
    "            als_mf_hyper_parameter['entropy'].append(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "123852a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>regularization</th>\n",
       "      <th>iteration</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>15</td>\n",
       "      <td>0.056851</td>\n",
       "      <td>3.328627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>20</td>\n",
       "      <td>0.056826</td>\n",
       "      <td>3.331948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10</td>\n",
       "      <td>0.056625</td>\n",
       "      <td>3.306572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>25</td>\n",
       "      <td>0.056404</td>\n",
       "      <td>3.336953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>15</td>\n",
       "      <td>0.056382</td>\n",
       "      <td>3.331313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    factor  regularization  iteration      NDCG   entropy\n",
       "2        5           0.010         15  0.056851  3.328627\n",
       "11       5           0.005         20  0.056826  3.331948\n",
       "1        5           0.010         10  0.056625  3.306572\n",
       "4        5           0.010         25  0.056404  3.336953\n",
       "10       5           0.005         15  0.056382  3.331313"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(als_mf_hyper_parameter).sort_values(by='NDCG',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17c5f24",
   "metadata": {},
   "source": [
    "## 7-2. LMF hypter parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6f3f8134",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmf_hyper_parameter = {'factor':[],'regularization':[],'iteration':[],'NDCG':[],'entropy':[]}\n",
    "\n",
    "factors = [5,10,15,20]\n",
    "regularizations = [0.01,0.005]\n",
    "iterations = [5,10,15,20,25,30,40,50]\n",
    "\n",
    "for factor in factors:\n",
    "    for regularization in regularizations:\n",
    "        for iteration in iterations:\n",
    "            lmf_model = LMF(factors=factor, regularization=regularization, iterations = iteration, random_state=42)\n",
    "            lmf_model.fit(purchase_sparse, show_progress=False)\n",
    "            \n",
    "            # 신규 유저 mp로 넣기\n",
    "            most_popular_list = most_popular.sort_values(by='customer_id',ascending=False).index\n",
    "\n",
    "            # test 예측값\n",
    "            lmf_predict_list = []\n",
    "            for user_id in test['customer_id'].unique():\n",
    "                try:\n",
    "                    result = lmf_model.recommend(userIdToIndex[user_id], purchase_sparse[userIdToIndex[user_id]], N=15)\n",
    "                    lmf_predict_list.append({'id':user_id ,'items':[indexToPdId[num] for num in result[0]]})\n",
    "                except:\n",
    "                    train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "                    lmf_predict_list.append({'id':user_id ,'items':[most_popular.product_ids.loc[num] for num in most_popular_list \\\n",
    "                                                                        if most_popular.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                                        ]})\n",
    "\n",
    "            # 15 개만 예측하기\n",
    "            for idx, pred_list in enumerate(lmf_predict_list):\n",
    "                lmf_predict_list[idx]['items'] = pred_list['items'][:15]\n",
    "                \n",
    "            # LMF\n",
    "            evaluator = CustomEvaluator()\n",
    "            ndcg, entropy = evaluator._eval(ground_trues, lmf_predict_list)\n",
    "            \n",
    "            lmf_hyper_parameter['factor'].append(factor)\n",
    "            lmf_hyper_parameter['regularization'].append(regularization)\n",
    "            lmf_hyper_parameter['iteration'].append(iteration)\n",
    "            lmf_hyper_parameter['NDCG'].append(ndcg)\n",
    "            lmf_hyper_parameter['entropy'].append(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d200968a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>regularization</th>\n",
       "      <th>iteration</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>15</td>\n",
       "      <td>0.010</td>\n",
       "      <td>50</td>\n",
       "      <td>0.058261</td>\n",
       "      <td>3.404235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>15</td>\n",
       "      <td>0.005</td>\n",
       "      <td>50</td>\n",
       "      <td>0.057760</td>\n",
       "      <td>3.407557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>25</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>3.499964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>20</td>\n",
       "      <td>0.005</td>\n",
       "      <td>50</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>3.392729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>15</td>\n",
       "      <td>0.010</td>\n",
       "      <td>40</td>\n",
       "      <td>0.057274</td>\n",
       "      <td>3.417395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    factor  regularization  iteration      NDCG   entropy\n",
       "39      15           0.010         50  0.058261  3.404235\n",
       "47      15           0.005         50  0.057760  3.407557\n",
       "4        5           0.010         25  0.057504  3.499964\n",
       "63      20           0.005         50  0.057312  3.392729\n",
       "38      15           0.010         40  0.057274  3.417395"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lmf_hyper_parameter).sort_values(by='NDCG',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f716977",
   "metadata": {},
   "source": [
    "# 8. 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb332430",
   "metadata": {},
   "source": [
    "- als mf : 0.283429 (factor: 10, regularization: 0.005, iteration: 15)\n",
    "- lmf : 0.292581    (factor: 15, regularization: 0.005, iteration: 25)\n",
    "- mp : 0.262317\n",
    "- medi_popular : 0.398149\n",
    "- latest : 0.574001\n",
    "\n",
    "최근 아이템으로 정렬해주었을 때 가장 높은 점수가 나왔음.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2b8bdd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 101 days 13:55:22.509000\n",
      "test 총 기간: 21 days 05:53:44.939000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_day</th>\n",
       "      <th>last_day</th>\n",
       "      <th>train_데이터수</th>\n",
       "      <th>train_유저수</th>\n",
       "      <th>test_데이터수</th>\n",
       "      <th>test_유저수</th>\n",
       "      <th>test_신규유저수</th>\n",
       "      <th>test_신규아이템수</th>\n",
       "      <th>원본_test수</th>\n",
       "      <th>전처리진행test수</th>\n",
       "      <th>als_mf</th>\n",
       "      <th>lmf</th>\n",
       "      <th>mp</th>\n",
       "      <th>medi_popular</th>\n",
       "      <th>latest</th>\n",
       "      <th>oldest</th>\n",
       "      <th>high_price</th>\n",
       "      <th>low_price</th>\n",
       "      <th>name_sort</th>\n",
       "      <th>als_mf_entropy</th>\n",
       "      <th>lmf_entropy</th>\n",
       "      <th>mp_entropy</th>\n",
       "      <th>medi_popular_entropy</th>\n",
       "      <th>latest_entropy</th>\n",
       "      <th>oldest_entropy</th>\n",
       "      <th>high_price_entropy</th>\n",
       "      <th>low_price_entropy</th>\n",
       "      <th>name_sort_entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-13 2022-08-22</td>\n",
       "      <td>2022-08-23 2022-09-13</td>\n",
       "      <td>2220</td>\n",
       "      <td>1212</td>\n",
       "      <td>974</td>\n",
       "      <td>744</td>\n",
       "      <td>544</td>\n",
       "      <td>11</td>\n",
       "      <td>974</td>\n",
       "      <td>384</td>\n",
       "      <td>0.056851</td>\n",
       "      <td>0.058261</td>\n",
       "      <td>0.053796</td>\n",
       "      <td>0.061266</td>\n",
       "      <td>0.016588</td>\n",
       "      <td>0.015806</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>3.65758</td>\n",
       "      <td>3.661356</td>\n",
       "      <td>2.736849</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               first_day               last_day  train_데이터수  train_유저수  \\\n",
       "0  2022-05-13 2022-08-22  2022-08-23 2022-09-13        2220       1212   \n",
       "\n",
       "   test_데이터수  test_유저수  test_신규유저수  test_신규아이템수  원본_test수  전처리진행test수  \\\n",
       "0        974       744         544           11       974         384   \n",
       "\n",
       "     als_mf       lmf        mp  medi_popular    latest    oldest  high_price  \\\n",
       "0  0.056851  0.058261  0.053796      0.061266  0.016588  0.015806    0.003865   \n",
       "\n",
       "   low_price  name_sort  als_mf_entropy  lmf_entropy  mp_entropy  \\\n",
       "0   0.001136   0.007651         3.65758     3.661356    2.736849   \n",
       "\n",
       "   medi_popular_entropy  latest_entropy  oldest_entropy  high_price_entropy  \\\n",
       "0               2.70805         2.70805         2.70805             2.70805   \n",
       "\n",
       "   low_price_entropy  name_sort_entropy  \n",
       "0            2.70805            2.70805  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_prediction_df = {'first_day':[],'last_day':[],'train_데이터수':[],'train_유저수':[],'test_데이터수':[],\\\n",
    "    'test_유저수':[],'test_신규유저수':[],'test_신규아이템수':[],'원본_test수':[],'전처리진행test수':[],\\\n",
    "    'als_mf':[],'lmf':[],'mp':[],'medi_popular':[],'latest':[],\\\n",
    "    'oldest':[],'high_price':[],'low_price':[],'name_sort':[],\\\n",
    "     'als_mf_entropy':[],'lmf_entropy':[],'mp_entropy':[],'medi_popular_entropy':[],'latest_entropy':[],\\\n",
    "     'oldest_entropy':[],'high_price_entropy':[],'low_price_entropy':[],'name_sort_entropy':[]}\n",
    "medistream_predict_df = pd.DataFrame(medistream_predict_score)\n",
    "\n",
    "all_prediction_df['first_day'].append(str(datetime.date(train['date_paid'].min()))+' '+str(datetime.date(train['date_paid'].max())))\n",
    "all_prediction_df['last_day'].append(str(datetime.date(test['date_paid'].min()))+' '+str(datetime.date(test['date_paid'].max())))\n",
    "all_prediction_df['train_데이터수'].append(len(train))\n",
    "all_prediction_df['train_유저수'].append(len(set(train.customer_id)))\n",
    "all_prediction_df['test_데이터수'].append(len(test))\n",
    "all_prediction_df['test_유저수'].append(len(set(test.customer_id)))\n",
    "all_prediction_df['test_신규유저수'].append(len(set(test['customer_id'].unique())- set(train['customer_id'].unique())))\n",
    "all_prediction_df['test_신규아이템수'].append(len(set(test_before_preprocess.product_ids.unique())-set(train_before_preprocess.product_ids.unique())))\n",
    "all_prediction_df['원본_test수'].append(len(test))\n",
    "all_prediction_df['전처리진행test수'].append(len(if_prepro_test))\n",
    "\n",
    "# ndcg\n",
    "all_prediction_df['als_mf'].append(pd.DataFrame(als_mf_hyper_parameter).sort_values(by='NDCG',ascending=False)['NDCG'].iloc[0])\n",
    "all_prediction_df['lmf'].append(pd.DataFrame(lmf_hyper_parameter).sort_values(by='NDCG',ascending=False)['NDCG'].iloc[0])\n",
    "all_prediction_df['mp'].append(evaluator._eval(ground_trues, predict_popular_list)[0])\n",
    "all_prediction_df['medi_popular'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='medi_popular'].iloc[0]['ndcg'])\n",
    "all_prediction_df['latest'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='latest'].iloc[0]['ndcg'])\n",
    "all_prediction_df['oldest'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='oldest'].iloc[0]['ndcg'])\n",
    "all_prediction_df['high_price'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='high_price'].iloc[0]['ndcg'])\n",
    "all_prediction_df['low_price'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='low_price'].iloc[0]['ndcg'])\n",
    "all_prediction_df['name_sort'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='name_sort'].iloc[0]['ndcg'])\n",
    "\n",
    "# entropy\n",
    "all_prediction_df['als_mf_entropy'].append(pd.DataFrame(als_mf_hyper_parameter).sort_values(by='entropy',ascending=False)['entropy'].iloc[0])\n",
    "all_prediction_df['lmf_entropy'].append(pd.DataFrame(lmf_hyper_parameter).sort_values(by='entropy',ascending=False)['entropy'].iloc[0])\n",
    "all_prediction_df['mp_entropy'].append(evaluator._eval(ground_trues, predict_popular_list)[1])\n",
    "all_prediction_df['medi_popular_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='medi_popular'].iloc[0]['entropy'])\n",
    "all_prediction_df['latest_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='latest'].iloc[0]['entropy'])\n",
    "all_prediction_df['oldest_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='oldest'].iloc[0]['entropy'])\n",
    "all_prediction_df['high_price_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='high_price'].iloc[0]['entropy'])\n",
    "all_prediction_df['low_price_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='low_price'].iloc[0]['entropy'])\n",
    "all_prediction_df['name_sort_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='name_sort'].iloc[0]['entropy'])\n",
    "\n",
    "print('train 총 기간:',train['date_paid'].max()-train['date_paid'].min())\n",
    "print('test 총 기간:',test['date_paid'].max()-test['date_paid'].min())\n",
    "display(pd.DataFrame(all_prediction_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4f841d",
   "metadata": {},
   "source": [
    "# 9. 추천된 items 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2378d08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5141/5141 [00:00<00:00, 719147.44it/s]\n"
     ]
    }
   ],
   "source": [
    "products_df = pd.read_json(\"/fastcampus-data/products/products.json\")\n",
    "products_df = key_to_element(['_id'],products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7444667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_item, rea_item 비교\n",
    "def pred_real_dataframe(user_num):\n",
    "    pred_items_names = []\n",
    "    predict_dict = als_predict_list[user_num]['items']\n",
    "    for item in predict_dict:\n",
    "        pred_items_names.append(products_df[products_df['_id'] == item].meta_title.unique())\n",
    "\n",
    "    real_items_names = []\n",
    "    trues_dict = ground_trues[user_num]['items']\n",
    "    for item in trues_dict:\n",
    "        real_items_names.append(products_df[products_df['_id'] == item].meta_title.unique())\n",
    "    return pd.DataFrame({'pred_item':pred_items_names,'real_item':real_items_names})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7e10cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_item, pred_item, real_item 비교\n",
    "def train_pred_items(user_nums):\n",
    "    train_pred_items_df = pd.DataFrame(columns=['train_item','pred_item'])\n",
    "    for user_num in range(1,user_nums):\n",
    "        train_item_names = []\n",
    "        for idx in grouped_purchased[grouped_purchased['customer_id']==ground_trues[user_num]['id']].product_ids:\n",
    "            train_item_names.append(products_df[products_df['_id'] == idx].meta_title.unique()[0])\n",
    "\n",
    "        pred_items_names = []\n",
    "        predict_dict = als_predict_list[user_num]['items']\n",
    "        for item in predict_dict:\n",
    "            pred_items_names.append(products_df[products_df['_id'] == item].meta_title.unique())\n",
    "\n",
    "\n",
    "        \n",
    "        train_pred_items_df.loc[user_num,'train_item'] = train_item_names\n",
    "        train_pred_items_df.loc[user_num,'pred_item'] = pred_items_names\n",
    "    return train_pred_items_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d1bf3699",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grouped_purchased' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-853987a114dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_pred_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-72-54e069c39814>\u001b[0m in \u001b[0;36mtrain_pred_items\u001b[0;34m(user_nums)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0muser_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser_nums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtrain_item_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped_purchased\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrouped_purchased\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mground_trues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mtrain_item_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproducts_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproducts_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_title\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grouped_purchased' is not defined"
     ]
    }
   ],
   "source": [
    "train_pred_items(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14de4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 유저 구매 횟수 확인\n",
    "pd.DataFrame(purchase_sparse[1].todense()).T.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e1096b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
