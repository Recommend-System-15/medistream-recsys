{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1758f1b3",
   "metadata": {},
   "source": [
    "# Test Evaluation\n",
    "- train(약 5개월), test(마지막 3주) evaluation 최종 평가를 진행합니다.\n",
    "- 결과적으로, 앙상블 결과가 가장 높은 NDCG 점수와 entropy 점수를 보였으며 base model MP 넘는 성능을 보임(8.결론 참조)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5943a3d",
   "metadata": {},
   "source": [
    "# 1.Dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "053cf1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "import random\n",
    "import implicit\n",
    "from implicit.als import AlternatingLeastSquares as ALS\n",
    "\n",
    "%cd ../../util\n",
    "from utils import *\n",
    "\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "1bfc0ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5141/5141 [00:00<00:00, 573085.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# products name 확인 용\n",
    "products_df = pd.read_json(\"/fastcampus-data/products/products.json\")\n",
    "products_df = key_to_element(['_id'],products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "392f7771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('/fastcampus-data/select_column_version_4.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "a727bca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-04-13 08:59:21.151000+0000', tz='UTC')"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "\n",
    "df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
    "# 5개월 전 날짜 확인\n",
    "df['date_paid'].max()-relativedelta(months=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "29b34a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_name_fill(product_name_preprocess_df):\n",
    "    # 각 마지막 product_ids, name으로 채우기\n",
    "    product_ids_to_name = {}\n",
    "    for idx, row in product_name_preprocess_df.iterrows():\n",
    "        product_ids_to_name[row.product_ids] = row.name_x\n",
    "    product_name_preprocess_df['name_x'] = product_name_preprocess_df['product_ids'].apply(lambda x: product_ids_to_name[x])\n",
    "\n",
    "    name_to_product_ids = {}\n",
    "    for idx, row in product_name_preprocess_df.iterrows():\n",
    "        name_to_product_ids[row.name_x] = row.product_ids\n",
    "    product_name_preprocess_df['product_ids'] = product_name_preprocess_df['name_x'].apply(lambda x: name_to_product_ids[x])\n",
    "    return product_name_preprocess_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "92247728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# medirecommend 만들기\n",
    "df = df.dropna(subset=['product_ids','name_x'])\n",
    "\n",
    "# 나오는 개월 수 적기\n",
    "date_state = \"2022-04-13\"\n",
    "# paid orders만 가져오기\n",
    "df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
    "df_only_paid = df[~df['date_paid'].isna()]\n",
    "# 취소 안된 것만 가져오기\n",
    "complete_df = df_only_paid[(df_only_paid['paid'] == True) & (df_only_paid['cancelled']==False)]\n",
    "# 도서 카테고리만 가져오기\n",
    "only_book = complete_df[complete_df['name'] == '도서']\n",
    "\n",
    "# 유저가 중복으로 아이템 구매 삭제\n",
    "df_duplicated_book = only_book.drop_duplicates(subset=['customer_id','product_ids'])\n",
    "\n",
    "df_sort = df_duplicated_book.sort_values(by='date_paid').reset_index(drop=True)\n",
    "df_sort = product_name_fill(df_sort)\n",
    "df_sort = df_sort.drop_duplicates(subset=['customer_id','product_ids']).reset_index(drop=True)\n",
    "\n",
    "# 5개월치 데이터만 가져오기\n",
    "df_book = df_sort[df_sort['date_paid'] >= date_state].reset_index(drop=True)\n",
    "\n",
    "# 마지막 3주 제외한 medirecommend 만들기\n",
    "mediprediction_all_df = df_sort[df_sort['date_paid'] < '2022-08-23'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "05871ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id                 0\n",
       "date_created        0\n",
       "regular_price       0\n",
       "sale_price          0\n",
       "three_months        0\n",
       "date_paid           0\n",
       "customer_id         0\n",
       "paid                0\n",
       "name_x              0\n",
       "category_id_y       0\n",
       "product_ids         0\n",
       "quantity            0\n",
       "price               0\n",
       "price_total         0\n",
       "age_group        1078\n",
       "한의사 여부              2\n",
       "사업자 여부              2\n",
       "cancelled           0\n",
       "name                0\n",
       "slug                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# none 값 확인하기\n",
    "df_book.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1485275",
   "metadata": {},
   "source": [
    "## 전체 데이터 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "ee8c91fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 전: 38395 중복 제거 후: 6957\n"
     ]
    }
   ],
   "source": [
    "print('중복 제거 전:',len(only_book), '중복 제거 후:',len(df_book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "c882d891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 수: 6957\n"
     ]
    }
   ],
   "source": [
    "print('전체 데이터 수:',len(df_book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "80095379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아이템 수: 267 유저 수: 2902\n"
     ]
    }
   ],
   "source": [
    "print('아이템 수:',len(df_book.product_ids.unique()),'유저 수:',len(df_book.customer_id.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c21921e",
   "metadata": {},
   "source": [
    "# promotion 전처리 함수\n",
    "- train 만 전처리하여 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "0c14a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promotion_proprof(df):\n",
    "    from datetime import datetime\n",
    "\n",
    "    preprocessed_book_df_date = df.copy()\n",
    "\n",
    "    promotion_book_df = preprocessed_book_df_date[preprocessed_book_df_date['date_paid'] >= '2022-01-01']\n",
    "    promotion_book_df['date_paid_date'] = promotion_book_df['date_paid'].dt.date\n",
    "    promotion_book_df['date_paid_week'] = promotion_book_df['date_paid_date'].apply(lambda x: x.isocalendar()[1])\n",
    "\n",
    "    promotion_dict = {\n",
    "        2:['트리거포인트 침치료'],\n",
    "        3:['藥徵, 약의 징표','파킨슨병 한의진료','침의 과학적 접근의 이해','길익동동','Medical acupuncture 침의 과학적 접근과 임상활용',\\\n",
    "          '동의보감 약선','수화론(水火論)'],\n",
    "        4:['실전한약가이드','음양승강으로 해석하는 사상의학: 생리병리'],\n",
    "        5:['음양승강으로 해석하는 사상의학: 생리병리'],\n",
    "        6:['윤상훈·권병조의 알짜 근육학','임상 한의사를 위한 기본 한약처방 강의 2판','트리거포인트 침치료','KCD 한방내과 진찰진단 가이드라인',\\\n",
    "          '실전한약가이드','음양승강으로 해석하는 사상의학: 생리병리','藥徵, 약의 징표','증보운곡본초학','통증치료를 위한 근육 초음파와 주사 테크닉'],\n",
    "        7:['오국통 온병명방'],\n",
    "        9:['병태생리 Visual map','NEO 인턴 핸드북','보험한약 브런치 the # 2판 개정판','Kendall 자세와 통증치료에 있어서 근육의 기능과 검사 5판',\\\n",
    "          '사상방 사용설명서','실전한약가이드','일차진료 한의사를 위한 보험한약입문 - 둘째 판','증보운곡본초학'],\n",
    "        10:['한눈에 보는 스트레칭 해부학'],\n",
    "        11:['임산부에게 사용할 수 있는 한방처방'],\n",
    "        12:['임산부에게 사용할 수 있는 한방처방'],\n",
    "        13:['MRI 자신감 키우기_족부편'],\n",
    "        14:['장골의 PI 변위는 없다'],\n",
    "        15:['윤상훈·권병조의 알짜 근육학','임상 한의사를 위한 기본 한약처방 강의 2판','KCD 한방내과 진찰진단 가이드라인','트리거포인트 침치료',\\\n",
    "           '음양승강으로 해석하는 사상의학: 생리병리','침의 과학적 접근의 이해','실전한약가이드','임산부에게 사용할 수 있는 한방처방','한눈에 보는 스트레칭 해부학',\\\n",
    "           'MRI 자신감 키우기_족부편'],\n",
    "        16:['환자상담의 달인','병의원 경영과 자산 관리 클리닉','우리 병원의 문제? 현장에서 답을 찾다!','근육학','스파이랄 및 키네지오 테이핑',\\\n",
    "           '요양병원 주치의 진료핵심'],\n",
    "        17:['오당 본초강론','운동기능장애 치료 매뉴얼','K. 한의학 임상총론','한방 활용 가이드','최강통증매선','암 치료에 이용되는 천연약물',\\\n",
    "           '왕문원 임상 평형침법','중국 왕문원 평형침구학'],\n",
    "        18:['초음파 가이드 근골격계 통증 치료의 정석'],\n",
    "        19:['초음파 가이드 근골격계 통증 치료의 정석','섭혜민 명의경방험안'],\n",
    "        20:['카이로프랙틱 기본테크닉론'],\n",
    "        21:['흔히보는 정형외과 외래진료 가이드북'],\n",
    "        22:['趙紹琴(조소금) 내과학','한의학 상담','숨찬 세상, 호흡기를 편하게',\\\n",
    "         '의학심오(醫學心悟)','안면마비 침구치료','중경서 독법 강해(상,하) /개정판'],\n",
    "        23:['선생님, 이제 그만 저 좀 포기해 주세요','한의학 상담','숨찬 세상, 호흡기를 편하게',\\\n",
    "        '의학심오(醫學心悟)','중경서 독법 강해(상,하) /개정판','안면마비 침구치료'],\n",
    "     24:['황황교수의 임상의를 위한 근거기반 상한금궤 처방 매뉴얼','황황교수의 개원 한의사를 위한 상한금궤 처방 강의록',\\\n",
    "        '선생님, 이제 그만 저 좀 포기해 주세요'],\\\n",
    "     25:['황황교수의 임상의를 위한 근거기반 상한금궤 처방 매뉴얼',\\\n",
    "       '황황교수의 개원 한의사를 위한 상한금궤 처방 강의록','약침의 정석 –통증편','갑상선 진료 완전정복',\\\n",
    "       '신경학 증상의 감별법','이것이 알고싶다! 당뇨병진료','어지럼질환의 진단과 치료','증례와 함께 하는 한약처방',\\\n",
    "       '뇌의학의 첫걸음','HAPPY 소아청소년 진료'],\\\n",
    "     26:['약침의 정석 –통증편','갑상선 진료 완전정복','신경학 증상의 감별법',\\\n",
    "       '증례와 함께 하는 한약처방','이것이 알고싶다! 당뇨병진료','HAPPY 소아청소년 진료','어지럼질환의 진단과 치료',\\\n",
    "       '뇌의학의 첫걸음','실전, 임상한의학 내과질환을 중심으로','실전, 임상한의학 알레르기질환','침구대성','평주온열경위'],\n",
    "     27:['침구과 진료매뉴얼','실전, 임상한의학 내과질환을 중심으로','실전, 임상한의학 알레르기질환','내과학 5권세트','한방순환 신경내과학',\\\n",
    "        '침구대성'],\n",
    "     28:['감별진단의 정석','기본통증진료학','약처방의 정석 (1, 2권 세트)','QBook: Case based Review',\\\n",
    "         'SMART 내과 1권 : 바이탈, 감염, 종양, 류마티스','일차진료아카데미 처방가이드'],\n",
    "     29:['비만문답','사암침의 해석과 임상'],\n",
    "     30:['플로차트 정형외과 진단','침구과 진료매뉴얼','내과학 5권세트','한방순환 신경내과학'],\n",
    "     31:['외래에서 꼭 알아야 할 통증증후군 137가지'],\n",
    "     32:['SMART 기본 일차진료매뉴얼 3판(세트)','SMART 소아진료매뉴얼 3판','SMART 응급진료매뉴얼(세트)'],\n",
    "     33:['SMART 기본 일차진료매뉴얼 3판(세트)','SMART 소아진료매뉴얼 3판','SMART 응급진료매뉴얼(세트)'],\n",
    "     34:['초음파 유도하 침 시술 가이드북'],\n",
    "     35:['영어 진료 가이드북','초음파 유도하 침 시술 가이드북'],\n",
    "     36:['영어 진료 가이드북','소아피부질환해설'],\n",
    "     37:['소아피부질환해설','醫學心悟(의학심오) 톺아보기'],}\n",
    "\n",
    "    promotion_item_list = []\n",
    "    for promotion_items in promotion_dict.values():\n",
    "        for item in promotion_items:\n",
    "            promotion_item_list.append(item)\n",
    "\n",
    "    # set(promotion_item_list), len(set(promotion_item_list))\n",
    "\n",
    "    preprocess_promotion_df = promotion_book_df[~((promotion_book_df['name_x'].str.contains('침의 과학적 접근과 임상활용')) & \\\n",
    "                            (promotion_book_df['date_paid_week']==3))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('의학심오')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==22))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('의학심오')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==23))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('약처방의 정석')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==28))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('초음파 유도하 침')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==34))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('초음파 유도하 침')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==34))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('영어 진료 가이드북')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==35))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('영어 진료 가이드북')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==36))]\n",
    "    all_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('의학심오')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==37))]\n",
    "\n",
    "    for key,value in promotion_dict.items():\n",
    "        all_promotion_df = all_promotion_df[~((all_promotion_df['name_x'].isin(value)) & (all_promotion_df['date_paid_week']==key))]\n",
    "    \n",
    "    return all_promotion_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbebd6a1",
   "metadata": {},
   "source": [
    "# 2.train test split\n",
    "- 마지막 3주 분량을 test로 선정합니다.\n",
    "- train 없는 test 아이템을 삭제 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "054c8f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-09-13 08:51:40+0000', tz='UTC')"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "df_book['date_paid'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "57fcec3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 8, 23, 0, 0)"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime(2022,9,13)-timedelta(days=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "a0aad083",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2022-08-23'\n",
    "train_before = df_book[df_book['date_paid'] < date]\n",
    "train_before_preprocess = promotion_proprof(train_before)\n",
    "test_before_preprocess = df_book[df_book['date_paid'] >= date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "598fe6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5983"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "3931742d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2555, 256)"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_before.customer_id)), len(set(train_before.product_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "49bc928c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2887"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_before_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "b4e77b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482, 251)"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_before_preprocess.customer_id)), len(set(train_before_preprocess.product_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30999e38",
   "metadata": {},
   "source": [
    "## 전체 아이템 중복 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "cc90f9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(267, 267)"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# product_ids, name_x 수는 일치\n",
    "len(df_book.product_ids.unique()), len(df_book.name_x.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "cea01f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복 제거 후 수 비교 확인\n",
    "# 252로 일치하여 문제 없음\n",
    "len(df_book.drop_duplicates(subset=['product_ids','name_x']).name_x.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae44431e",
   "metadata": {},
   "source": [
    "## train test 아이템 중복 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "137c94be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251, 131)"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_before_preprocess.product_ids.unique()),len(test_before_preprocess.product_ids.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "e70aeedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_before_preprocess.product_ids.unique())-set(test_before_preprocess.product_ids.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "cdf1afc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 아이템에 train 없는 아이템 확인\n",
    "len(set(test_before_preprocess.product_ids.unique())-set(train_before_preprocess.product_ids.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "acd3352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 만 있는 item 제거\n",
    "only_test_items = set(test_before_preprocess.product_ids.unique())-set(train_before_preprocess.product_ids.unique())\n",
    "if_prepro_test = test_before_preprocess[~test_before_preprocess['product_ids'].isin(only_test_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "fde2d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_before_preprocess.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "e2a94995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 변수 명 변경\n",
    "train = train_before_preprocess.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "e35c9ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 test 수: 974\n",
      "전처리 진행했을 경우 test 수: 384\n"
     ]
    }
   ],
   "source": [
    "# test 전처리 진행했을 경우\n",
    "print('원본 test 수:', len(test))\n",
    "print('전처리 진행했을 경우 test 수:', len(if_prepro_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24a4b77",
   "metadata": {},
   "source": [
    "# train test eda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952ba9d0",
   "metadata": {},
   "source": [
    "### 전처리 전후 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "25e9863f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 전처리 전: 5983 train 전처리 후: 2887\n"
     ]
    }
   ],
   "source": [
    "print('train 전처리 전:',len(train_before), 'train 전처리 후:',len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "8bacd384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 전처리 전: 974 test 전처리 후: 974\n"
     ]
    }
   ],
   "source": [
    "print('test 전처리 전:',len(test_before_preprocess), 'test 전처리 후:',len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9797c9d0",
   "metadata": {},
   "source": [
    "### user 수 비교 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "2e702d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 전 train 유저수 :  2555 전처리 후 train 유저 수: 1482\n"
     ]
    }
   ],
   "source": [
    "print('전처리 전 train 유저수 : ',len(train_before.customer_id.unique()), '전처리 후 train 유저 수:',len(train.customer_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "b2d4c5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 유저 수: 744\n"
     ]
    }
   ],
   "source": [
    "print('test 유저 수:',len(test.customer_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "18e1b5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 만 있는 신규 유저 : 514\n"
     ]
    }
   ],
   "source": [
    "# 신규 유저는 MP 같은 다른 방법으로 추천 진행해야 함\n",
    "print('test 만 있는 신규 유저 :',len(set(test['customer_id'].unique())- set(train['customer_id'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197dd8fb",
   "metadata": {},
   "source": [
    "### item 개수 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "3aba7272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 전 train 아이템 수: 256 전처리 후 train 아이템 수 : 251\n"
     ]
    }
   ],
   "source": [
    "print('전처리 전 train 아이템 수:',len(set(train_before.product_ids)), '전처리 후 train 아이템 수 :',len(set(train.product_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "3812f139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 아이템 수 : 131\n"
     ]
    }
   ],
   "source": [
    "print('test 아이템 수 :',len(set(test.product_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "102316b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 만 있는 아이템 수: 131\n"
     ]
    }
   ],
   "source": [
    "print('train 만 있는 아이템 수:',  len(set(train.product_ids)-set(test.product_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "41589650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 만 있는 아이템 수: 11\n"
     ]
    }
   ],
   "source": [
    "print('test 만 있는 아이템 수:', len(set(test.product_ids) - set(train.product_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19564e8",
   "metadata": {},
   "source": [
    "# 3. sparse matrix 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf19f8d",
   "metadata": {},
   "source": [
    "## ALS MF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "dbfcb32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PdIds = train.product_ids.unique()\n",
    "\n",
    "PdIdToIndex = {}\n",
    "indexToPdId = {}\n",
    "\n",
    "colIdx = 0\n",
    "\n",
    "for PdId in PdIds:\n",
    "    PdIdToIndex[PdId] = colIdx\n",
    "    indexToPdId[colIdx] = PdId\n",
    "    colIdx += 1\n",
    "    \n",
    "userIds = train.customer_id.unique()\n",
    "\n",
    "userIdToIndex = {}\n",
    "indexToUserId = {}\n",
    "\n",
    "rowIdx = 0\n",
    "\n",
    "for userId in userIds:\n",
    "    userIdToIndex[userId] = rowIdx\n",
    "    indexToUserId[rowIdx] = userId\n",
    "    rowIdx += 1\n",
    "\n",
    "import scipy.sparse as sp\n",
    "\n",
    "rows = []\n",
    "cols = []\n",
    "vals = []\n",
    "\n",
    "for row in train.itertuples():\n",
    "    rows.append(userIdToIndex[row.customer_id])\n",
    "    cols.append(PdIdToIndex[row.product_ids])\n",
    "    vals.append(1)\n",
    "\n",
    "purchase_sparse = sp.csr_matrix((vals, (rows, cols)), shape=(rowIdx,colIdx))\n",
    "\n",
    "matrix = purchase_sparse.todense()\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f283e658",
   "metadata": {},
   "source": [
    "### Most_popular_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "8a75fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular = mediprediction_all_df.groupby(['product_ids']).count()['customer_id'].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88fa623",
   "metadata": {},
   "source": [
    "### Medistream_prediction_matrix\n",
    "- 메디스트림 메디마켓에서 제공하는 정렬 추천 성능 비교를 위한 df 구현\n",
    "- 인기도순, 최신순, 과거순, 높은 가격순, 낮은 가격순, 이름순 (총 6 가지)\n",
    "- 각각 구현해보고 학습 모델 대비 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "70704fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-541-274709b685cd>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n"
     ]
    }
   ],
   "source": [
    "medistream_prediction_df = mediprediction_all_df[['date_created','regular_price','sale_price','three_months','product_ids','name_x']]\n",
    "medistream_prediction_preprop_df = medistream_prediction_df.drop_duplicates(subset=['product_ids'], ignore_index=True)\n",
    "medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
    "# sale_prices가 0이면 regular_price 값으로 채워넣어야하는데 0이 없음(전처리 필요 무)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca1abb4",
   "metadata": {},
   "source": [
    "# Sparsity 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "47f55717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.22388717733654"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sparsity: 얼마나 비어있나?\n",
    "matrix_size = purchase_sparse.shape[0]* purchase_sparse.shape[1]\n",
    "num_purchases = len(purchase_sparse.nonzero()[0])\n",
    "sparsity = 100 * (1 - (num_purchases / matrix_size))\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbe9ba0",
   "metadata": {},
   "source": [
    "# 4. MP & Base Model & prediction\n",
    "- Model 학습 진행 및 predict 진행\n",
    "- MP 모델과 base model prediction 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "b8adfc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real test \n",
    "ground_trues = []\n",
    "for user_id in test['customer_id'].unique():\n",
    "    ground_trues.append({'id': user_id,\\\n",
    "    'items':list(test[test['customer_id']==user_id].product_ids)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65633ab7",
   "metadata": {},
   "source": [
    "# most popular prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "c1f592ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 도서에 대한 판매 만큼 정렬 후 넣기\n",
    "most_popular_list = most_popular.sort_values(by='customer_id',ascending=False).index\n",
    "\n",
    "# test 예측값, 이미 구매 했을 경우 제외\n",
    "predict_popular_list = []\n",
    "for user_id in test['customer_id'].unique():\n",
    "    train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "    predict_popular_list.append({'id':user_id ,'items':[most_popular.product_ids.loc[num] for num in most_popular_list \\\n",
    "                                                            if most_popular.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                            ]})\n",
    "\n",
    "# 15 개만 예측하기\n",
    "for idx, pred_list in enumerate(predict_popular_list):\n",
    "    predict_popular_list[idx]['items'] = pred_list['items'][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90829334",
   "metadata": {},
   "source": [
    "# medistream prediction\n",
    "- 메디스트림 메디마켓에서 제공하는 정렬 추천 성능 비교\n",
    "- 인기도순, 최신순, 과거순, 높은 가격순, 낮은 가격순, 이름순 (총 6 가지)\n",
    "- 각각 구현해보고 학습 모델 대비 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "6284210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인기도순\n",
    "medistream_popular_list = medistream_prediction_preprop_df.sort_values(by='three_months', ascending=False).index\n",
    "# 최신순\n",
    "medistream_latest_list = medistream_prediction_preprop_df.sort_values(by='date_created', ascending=False).index\n",
    "# 오랜된 순\n",
    "medistream_oldest_list = medistream_prediction_preprop_df.sort_values(by='date_created', ascending=True).index\n",
    "# 높은 가격 순\n",
    "medistream_high_price_list = medistream_prediction_preprop_df.sort_values(by='sale_price', ascending=False).index\n",
    "# 낮은 가격 순\n",
    "medistream_low_price_list = medistream_prediction_preprop_df.sort_values(by='sale_price', ascending=True).index\n",
    "# 이름 순\n",
    "medistream_name_sort_list = medistream_prediction_preprop_df.sort_values(by='name_x',ascending=True).index\n",
    "\n",
    "def medistream_prediction_method(predict_num:int ,medi_predict_list:list)->list:\n",
    "    medistream_predict_list = []\n",
    "    for user_id in test['customer_id'].unique():\n",
    "        medistream_predict_list.append({'id':user_id ,'items':[medistream_prediction_preprop_df.product_ids.loc[num] \\\n",
    "                                                                       for num in medi_predict_list]})\n",
    "\n",
    "    # 15 개만 예측하기\n",
    "    for idx, pred_list in enumerate(medistream_predict_list):\n",
    "        medistream_predict_list[idx]['items'] = pred_list['items'][:predict_num]\n",
    "        \n",
    "    return medistream_predict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "ea82c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "medistream_predict_popular_list = medistream_prediction_method(15, medistream_popular_list)\n",
    "medistream_predict_latest_list = medistream_prediction_method(15, medistream_latest_list)\n",
    "medistream_predict_oldest_list = medistream_prediction_method(15, medistream_oldest_list)\n",
    "medistream_predict_high_price_list = medistream_prediction_method(15, medistream_high_price_list)\n",
    "medistream_predict_low_price_list = medistream_prediction_method(15, medistream_low_price_list)\n",
    "medistream_predict_name_sort_list = medistream_prediction_method(15, medistream_name_sort_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b5a451",
   "metadata": {},
   "source": [
    "# 5. evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0f739b",
   "metadata": {},
   "source": [
    "## NDCG & Entropy Diversity 평가지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "2124a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEvaluator:\n",
    "    # relavence 모두 1로 동일하게 봄\n",
    "    def _idcg(self, l):\n",
    "        return sum((1.0 / np.log(i + 2) for i in range(l)))\n",
    "    \n",
    "\n",
    "    def __init__(self):\n",
    "        self._idcgs = [self._idcg(i) for i in range(1000)]\n",
    "\n",
    "    def _ndcg(self, gt, rec):\n",
    "        dcg = 0.0\n",
    "        for i, r in enumerate(rec):\n",
    "            if r in gt:\n",
    "                dcg += 1.0 / np.log(i + 2)\n",
    "\n",
    "        return dcg / self._idcgs[len(gt)]\n",
    "    \n",
    "    def _entropy_diversity(self,rec_list):\n",
    "        import six\n",
    "        import math\n",
    "        \n",
    "        topn = len(rec_list[0]['items'])\n",
    "        users = [i.get('id',None) for i in rec_list]\n",
    "        sz = float(len(users)) * topn\n",
    "        freq = {}\n",
    "        for rec in rec_list:\n",
    "            for r in rec['items']:\n",
    "                freq[r] = freq.get(r, 0) + 1\n",
    "        ent = -sum([v / sz * math.log(v / sz) for v in six.itervalues(freq)])\n",
    "        return ent\n",
    "\n",
    "    def _eval(self, gt_list, rec_list):\n",
    "        gt_dict = {g[\"id\"]: g for g in gt_list}\n",
    "        ndcg_score = 0.0\n",
    "\n",
    "        for rec in rec_list:\n",
    "            gt = gt_dict[rec[\"id\"]]\n",
    "            ndcg_score += self._ndcg(gt[\"items\"], rec[\"items\"])\n",
    "\n",
    "\n",
    "        ndcg_score = ndcg_score / len(rec_list)\n",
    "        ent = self._entropy_diversity(rec_list)\n",
    "        \n",
    "        return ndcg_score, ent\n",
    "\n",
    "    def evaluate(self, gt_list, rec_list):\n",
    "        try:\n",
    "            ndcg_score, ent_score = self._eval(gt_list, rec_list)\n",
    "            print(f\"NDCG: {ndcg_score:.6}\")\n",
    "            print(f\"Entropy Diversity: {ent_score:.6} \")\n",
    "        except Exception as e:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad479c",
   "metadata": {},
   "source": [
    "# most popular NDCG & Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "3c0a471b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.0538018\n",
      "Entropy Diversity: 2.74294 \n"
     ]
    }
   ],
   "source": [
    "# most popular\n",
    "evaluator = CustomEvaluator()\n",
    "evaluator.evaluate(ground_trues, predict_popular_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fbb56c",
   "metadata": {},
   "source": [
    "## medistream prediction NDCG & Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "42cb74cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def medistream_prediction(ground_trues:list, predict_list:list):\n",
    "    evaluator = CustomEvaluator()\n",
    "    ndcg, entropy = evaluator._eval(ground_trues, predict_list)\n",
    "    \n",
    "    assert len(predict_list) == len(ground_trues)\n",
    "    \n",
    "    cnt = 0\n",
    "    for gt, pred_list in zip(ground_trues, predict_list):\n",
    "        for pred in pred_list['items']:\n",
    "            if pred in gt['items']:\n",
    "                cnt += 1\n",
    "    return ndcg, entropy, cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "69aed061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medistream_predict</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>entropy</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medi_popular</td>\n",
       "      <td>0.061266</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>latest</td>\n",
       "      <td>0.016588</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oldest</td>\n",
       "      <td>0.015806</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high_price</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>low_price</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>name_sort</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  medistream_predict      ndcg  entropy  cnt\n",
       "0       medi_popular  0.061266  2.70805  151\n",
       "1             latest  0.016588  2.70805   52\n",
       "2             oldest  0.015806  2.70805   45\n",
       "3         high_price  0.003865  2.70805   12\n",
       "4          low_price  0.001136  2.70805    7\n",
       "5          name_sort  0.007651  2.70805   22"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medistream_predict_score = {'medistream_predict':['medi_popular','latest','oldest','high_price','low_price','name_sort'], \\\n",
    "                            'ndcg':[], 'entropy':[], 'cnt':[]}\n",
    "\n",
    "medistream_predict_list = [medistream_predict_popular_list, medistream_predict_latest_list, medistream_predict_oldest_list,\\\n",
    "                          medistream_predict_high_price_list, medistream_predict_low_price_list, medistream_predict_name_sort_list]\n",
    "\n",
    "for medistream_predict in medistream_predict_list:\n",
    "    ndcg, entropy, cnt = medistream_prediction(ground_trues, medistream_predict)\n",
    "    medistream_predict_score['ndcg'].append(ndcg)\n",
    "    medistream_predict_score['entropy'].append(entropy)\n",
    "    medistream_predict_score['cnt'].append(cnt)\n",
    "pd.DataFrame(medistream_predict_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8681a8c",
   "metadata": {},
   "source": [
    "# 6. hyper parameter tuned model train & evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67775ea",
   "metadata": {},
   "source": [
    "## 6-1. ALS MF hypter parameter tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "8f63d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "als_mf_hyper_parameter = {'factor':[],'regularization':[],'iteration':[],'NDCG':[],'entropy':[]}\n",
    "\n",
    "factors = [5]\n",
    "regularizations = [0.01]\n",
    "iterations = [5]\n",
    "\n",
    "for factor in factors:\n",
    "    for regularization in regularizations:\n",
    "        for iteration in iterations:\n",
    "            als_model = ALS(factors=factor, regularization=regularization, iterations = iteration, random_state=42)\n",
    "            als_model.fit(purchase_sparse, show_progress=False)\n",
    "\n",
    "            # 신규 유저인 경우 mp로 넣기\n",
    "            # 전체 도서에 대한 판매 만큼 정렬 후 넣기\n",
    "            most_popular_list = most_popular.sort_values(by='customer_id',ascending=False).index\n",
    "\n",
    "            # test 예측값, 이미 구매 했을 경우 제외\n",
    "            als_predict_list = []\n",
    "            for user_id in test['customer_id'].unique():\n",
    "                try:\n",
    "                    result = als_model.recommend(userIdToIndex[user_id], purchase_sparse[userIdToIndex[user_id]], N=15)\n",
    "                    als_predict_list.append({'id':user_id ,'items':[indexToPdId[num] for num in result[0]]})\n",
    "                except:\n",
    "                    train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "                    als_predict_list.append({'id':user_id ,'items':[most_popular.product_ids.loc[num] for num in most_popular_list \\\n",
    "                                                                        if most_popular.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                                        ]})\n",
    "\n",
    "            # 15 개만 예측하기\n",
    "            for idx, pred_list in enumerate(als_predict_list):\n",
    "                als_predict_list[idx]['items'] = pred_list['items'][:15]\n",
    "\n",
    "            # ALS \n",
    "            evaluator = CustomEvaluator()\n",
    "            ndcg, entropy = evaluator._eval(ground_trues, als_predict_list)\n",
    "\n",
    "            als_mf_hyper_parameter['factor'].append(factor)\n",
    "            als_mf_hyper_parameter['regularization'].append(regularization)\n",
    "            als_mf_hyper_parameter['iteration'].append(iteration)\n",
    "            als_mf_hyper_parameter['NDCG'].append(ndcg)\n",
    "            als_mf_hyper_parameter['entropy'].append(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "123852a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>regularization</th>\n",
       "      <th>iteration</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.053031</td>\n",
       "      <td>3.335207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   factor  regularization  iteration      NDCG   entropy\n",
       "0       5            0.01          5  0.053031  3.335207"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(als_mf_hyper_parameter).sort_values(by='NDCG',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17c5f24",
   "metadata": {},
   "source": [
    "## 6-2. LMF hypter parameter tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "6f3f8134",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmf_hyper_parameter = {'factor':[],'regularization':[],'iteration':[],'NDCG':[],'entropy':[]}\n",
    "\n",
    "factors = [15]\n",
    "regularizations = [0.005]\n",
    "iterations = [50]\n",
    "\n",
    "for factor in factors:\n",
    "    for regularization in regularizations:\n",
    "        for iteration in iterations:\n",
    "            lmf_model = LMF(factors=factor, regularization=regularization, iterations = iteration, random_state=42)\n",
    "            lmf_model.fit(purchase_sparse, show_progress=False)\n",
    "            \n",
    "            # 신규 유저 mp로 넣기\n",
    "            most_popular_list = most_popular.sort_values(by='customer_id',ascending=False).index\n",
    "\n",
    "            # test 예측값\n",
    "            lmf_predict_list = []\n",
    "            for user_id in test['customer_id'].unique():\n",
    "                try:\n",
    "                    result = lmf_model.recommend(userIdToIndex[user_id], purchase_sparse[userIdToIndex[user_id]], N=20)\n",
    "                    lmf_predict_list.append({'id':user_id ,'items':[indexToPdId[num] for num in result[0]]})\n",
    "                except:\n",
    "                    train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "                    lmf_predict_list.append({'id':user_id ,'items':[most_popular.product_ids.loc[num] for num in most_popular_list \\\n",
    "                                                                        if most_popular.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                                        ]})\n",
    "\n",
    "            # 15 개만 예측하기\n",
    "            for idx, pred_list in enumerate(lmf_predict_list):\n",
    "                lmf_predict_list[idx]['items'] = pred_list['items'][:15]\n",
    "                \n",
    "            # LMF\n",
    "            evaluator = CustomEvaluator()\n",
    "            ndcg, entropy = evaluator._eval(ground_trues, lmf_predict_list)\n",
    "            \n",
    "            lmf_hyper_parameter['factor'].append(factor)\n",
    "            lmf_hyper_parameter['regularization'].append(regularization)\n",
    "            lmf_hyper_parameter['iteration'].append(iteration)\n",
    "            lmf_hyper_parameter['NDCG'].append(ndcg)\n",
    "            lmf_hyper_parameter['entropy'].append(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "d200968a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>regularization</th>\n",
       "      <th>iteration</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0.005</td>\n",
       "      <td>50</td>\n",
       "      <td>0.054209</td>\n",
       "      <td>3.551187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   factor  regularization  iteration      NDCG   entropy\n",
       "0      15           0.005         50  0.054209  3.551187"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lmf_hyper_parameter).sort_values(by='NDCG',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f833c11f",
   "metadata": {},
   "source": [
    "# 6-3 ensemble (medi popular & lmf MIX) hypter parameter tuned\n",
    "- top5,3 모두 평가하여 결과 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30866533",
   "metadata": {},
   "source": [
    "### 1) ensemble top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "8425fa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_medipop_lmf_mix_hyper_parameter = {'factor':[],'regularization':[],'iteration':[],'top':[],'NDCG':[],'entropy':[]}\n",
    "\n",
    "factors = [40]\n",
    "regularizations = [0.005]\n",
    "iterations = [50]\n",
    "tops = [5]\n",
    "\n",
    "for factor in factors:\n",
    "    for regularization in regularizations:\n",
    "        for iteration in iterations:\n",
    "            for top in tops:\n",
    "                lmf_model = LMF(factors=factor, regularization=regularization, iterations = iteration, random_state=42)\n",
    "                lmf_model.fit(purchase_sparse, show_progress=False)\n",
    "\n",
    "                # test 예측값\n",
    "                lmf_predict_list = []\n",
    "                for user_id in test['customer_id'].unique():\n",
    "                    try:\n",
    "                        train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "                        medi_popular_top_three = medistream_popular_list[:top]\n",
    "                        medi_popular_top_three_list = [medistream_prediction_preprop_df.product_ids.loc[num] for num in medi_popular_top_three \\\n",
    "                                                                            if medistream_prediction_preprop_df.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                                            ]\n",
    "                        result = lmf_model.recommend(userIdToIndex[user_id], purchase_sparse[userIdToIndex[user_id]], N=20)\n",
    "                        result_list = [indexToPdId[num] for num in result[0]]\n",
    "                        medi_pop_lmf_list = list(dict.fromkeys(medi_popular_top_three_list + result_list))\n",
    "                        lmf_predict_list.append({'id':user_id ,'items':medi_pop_lmf_list})\n",
    "                    except:\n",
    "                        train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "                        lmf_predict_list.append({'id':user_id ,'items':[medistream_prediction_preprop_df.product_ids.loc[num] for num in medistream_popular_list \\\n",
    "                                                                            if medistream_prediction_preprop_df.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                                            ]})\n",
    "\n",
    "                # 15 개만 예측하기\n",
    "                for idx, pred_list in enumerate(lmf_predict_list):\n",
    "                    lmf_predict_list[idx]['items'] = pred_list['items'][:15]\n",
    "\n",
    "                # LMF\n",
    "                evaluator = CustomEvaluator()\n",
    "                ndcg, entropy = evaluator._eval(ground_trues, lmf_predict_list)\n",
    "\n",
    "                top5_medipop_lmf_mix_hyper_parameter['factor'].append(factor)\n",
    "                top5_medipop_lmf_mix_hyper_parameter['regularization'].append(regularization)\n",
    "                top5_medipop_lmf_mix_hyper_parameter['iteration'].append(iteration)\n",
    "                top5_medipop_lmf_mix_hyper_parameter['top'].append(top)\n",
    "                top5_medipop_lmf_mix_hyper_parameter['NDCG'].append(ndcg)\n",
    "                top5_medipop_lmf_mix_hyper_parameter['entropy'].append(entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacc8ea8",
   "metadata": {},
   "source": [
    "### 2) ensemble top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "9c515ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_medipop_lmf_mix_hyper_parameter = {'factor':[],'regularization':[],'iteration':[],'top':[],'NDCG':[],'entropy':[]}\n",
    "\n",
    "factors = [40]\n",
    "regularizations = [0.005]\n",
    "iterations = [50]\n",
    "tops = [3]\n",
    "\n",
    "for factor in factors:\n",
    "    for regularization in regularizations:\n",
    "        for iteration in iterations:\n",
    "            for top in tops:\n",
    "                lmf_model = LMF(factors=factor, regularization=regularization, iterations = iteration, random_state=42)\n",
    "                lmf_model.fit(purchase_sparse, show_progress=False)\n",
    "\n",
    "                # test 예측값\n",
    "                lmf_predict_list = []\n",
    "                for user_id in test['customer_id'].unique():\n",
    "                    try:\n",
    "                        train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "                        medi_popular_top_three = medistream_popular_list[:top]\n",
    "                        medi_popular_top_three_list = [medistream_prediction_preprop_df.product_ids.loc[num] for num in medi_popular_top_three \\\n",
    "                                                                            if medistream_prediction_preprop_df.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                                            ]\n",
    "                        result = lmf_model.recommend(userIdToIndex[user_id], purchase_sparse[userIdToIndex[user_id]], N=20)\n",
    "                        result_list = [indexToPdId[num] for num in result[0]]\n",
    "                        medi_pop_lmf_list = list(dict.fromkeys(medi_popular_top_three_list + result_list))\n",
    "                        lmf_predict_list.append({'id':user_id ,'items':medi_pop_lmf_list})\n",
    "                    except:\n",
    "                        train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "                        lmf_predict_list.append({'id':user_id ,'items':[medistream_prediction_preprop_df.product_ids.loc[num] for num in medistream_popular_list \\\n",
    "                                                                            if medistream_prediction_preprop_df.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                                            ]})\n",
    "\n",
    "                # 15 개만 예측하기\n",
    "                for idx, pred_list in enumerate(lmf_predict_list):\n",
    "                    lmf_predict_list[idx]['items'] = pred_list['items'][:15]\n",
    "\n",
    "                # LMF\n",
    "                evaluator = CustomEvaluator()\n",
    "                ndcg, entropy = evaluator._eval(ground_trues, lmf_predict_list)\n",
    "\n",
    "                top3_medipop_lmf_mix_hyper_parameter['factor'].append(factor)\n",
    "                top3_medipop_lmf_mix_hyper_parameter['regularization'].append(regularization)\n",
    "                top3_medipop_lmf_mix_hyper_parameter['iteration'].append(iteration)\n",
    "                top3_medipop_lmf_mix_hyper_parameter['top'].append(top)\n",
    "                top3_medipop_lmf_mix_hyper_parameter['NDCG'].append(ndcg)\n",
    "                top3_medipop_lmf_mix_hyper_parameter['entropy'].append(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "71d9c6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>regularization</th>\n",
       "      <th>iteration</th>\n",
       "      <th>top</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>0.005</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.060843</td>\n",
       "      <td>3.242231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   factor  regularization  iteration  top      NDCG   entropy\n",
       "0      40           0.005         50    5  0.060843  3.242231"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(top5_medipop_lmf_mix_hyper_parameter).sort_values(by='NDCG',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "51b8e32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>regularization</th>\n",
       "      <th>iteration</th>\n",
       "      <th>top</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>0.005</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>0.061518</td>\n",
       "      <td>3.330821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   factor  regularization  iteration  top      NDCG   entropy\n",
       "0      40           0.005         50    3  0.061518  3.330821"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(top3_medipop_lmf_mix_hyper_parameter).sort_values(by='NDCG',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f716977",
   "metadata": {},
   "source": [
    "# 7. 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb332430",
   "metadata": {},
   "source": [
    "- 각 모델은 하이퍼파라미터 튜닝한 결과로 최종 evalutation 진행\n",
    "- ALS MF: factor = 3 , regularizations = 0.01 , iterations = 5\n",
    "- LMF: factor = 15 , regularizations = 0.005 , iterations = 5\n",
    "- ensemble(medi_mp_lmf_mix): factor = 40 , regularizations = 0.005 , iterations = 50 , tops = 3\n",
    "- ensembel은 top3가 top5 보다 높은 점수인 것을 확인\n",
    "- 결과, ensemble(medi_mp_lmf_mix) 모델이 NDCG 0.061518 diversity 3.330821 로 base model(0.061266, 2.70805) 대비 모두 높은 점수를 보이는 것을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "2b8bdd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 131 days 13:31:51.843000\n",
      "test 총 기간: 21 days 05:53:44.939000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_day</th>\n",
       "      <th>last_day</th>\n",
       "      <th>train_데이터수</th>\n",
       "      <th>train_유저수</th>\n",
       "      <th>test_데이터수</th>\n",
       "      <th>test_유저수</th>\n",
       "      <th>test_신규유저수</th>\n",
       "      <th>test_신규아이템수</th>\n",
       "      <th>원본_test수</th>\n",
       "      <th>전처리진행test수</th>\n",
       "      <th>als_mf</th>\n",
       "      <th>lmf</th>\n",
       "      <th>top5_medi_mp_lmf_mix</th>\n",
       "      <th>top3_medi_mp_lmf_mix</th>\n",
       "      <th>mp</th>\n",
       "      <th>medi_popular</th>\n",
       "      <th>latest</th>\n",
       "      <th>oldest</th>\n",
       "      <th>high_price</th>\n",
       "      <th>low_price</th>\n",
       "      <th>name_sort</th>\n",
       "      <th>als_mf_entropy</th>\n",
       "      <th>lmf_entropy</th>\n",
       "      <th>top5_medi_mp_lmf_mix_entropy</th>\n",
       "      <th>top3_medi_mp_lmf_mix_entropy</th>\n",
       "      <th>mp_entropy</th>\n",
       "      <th>medi_popular_entropy</th>\n",
       "      <th>latest_entropy</th>\n",
       "      <th>oldest_entropy</th>\n",
       "      <th>high_price_entropy</th>\n",
       "      <th>low_price_entropy</th>\n",
       "      <th>name_sort_entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-13 2022-08-22</td>\n",
       "      <td>2022-08-23 2022-09-13</td>\n",
       "      <td>2887</td>\n",
       "      <td>1482</td>\n",
       "      <td>974</td>\n",
       "      <td>744</td>\n",
       "      <td>514</td>\n",
       "      <td>11</td>\n",
       "      <td>974</td>\n",
       "      <td>384</td>\n",
       "      <td>0.053031</td>\n",
       "      <td>0.054209</td>\n",
       "      <td>0.060843</td>\n",
       "      <td>0.061518</td>\n",
       "      <td>0.053802</td>\n",
       "      <td>0.061266</td>\n",
       "      <td>0.016588</td>\n",
       "      <td>0.015806</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>3.335207</td>\n",
       "      <td>3.551187</td>\n",
       "      <td>3.242231</td>\n",
       "      <td>3.330821</td>\n",
       "      <td>2.742936</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               first_day               last_day  train_데이터수  train_유저수  \\\n",
       "0  2022-04-13 2022-08-22  2022-08-23 2022-09-13        2887       1482   \n",
       "\n",
       "   test_데이터수  test_유저수  test_신규유저수  test_신규아이템수  원본_test수  전처리진행test수  \\\n",
       "0        974       744         514           11       974         384   \n",
       "\n",
       "     als_mf       lmf  top5_medi_mp_lmf_mix  top3_medi_mp_lmf_mix        mp  \\\n",
       "0  0.053031  0.054209              0.060843              0.061518  0.053802   \n",
       "\n",
       "   medi_popular    latest    oldest  high_price  low_price  name_sort  \\\n",
       "0      0.061266  0.016588  0.015806    0.003865   0.001136   0.007651   \n",
       "\n",
       "   als_mf_entropy  lmf_entropy  top5_medi_mp_lmf_mix_entropy  \\\n",
       "0        3.335207     3.551187                      3.242231   \n",
       "\n",
       "   top3_medi_mp_lmf_mix_entropy  mp_entropy  medi_popular_entropy  \\\n",
       "0                      3.330821    2.742936               2.70805   \n",
       "\n",
       "   latest_entropy  oldest_entropy  high_price_entropy  low_price_entropy  \\\n",
       "0         2.70805         2.70805             2.70805            2.70805   \n",
       "\n",
       "   name_sort_entropy  \n",
       "0            2.70805  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_prediction_df = {'first_day':[],'last_day':[],'train_데이터수':[],'train_유저수':[],'test_데이터수':[],\\\n",
    "    'test_유저수':[],'test_신규유저수':[],'test_신규아이템수':[],'원본_test수':[],'전처리진행test수':[],\\\n",
    "    'als_mf':[],'lmf':[],'top5_medi_mp_lmf_mix':[],'top3_medi_mp_lmf_mix':[],'mp':[],'medi_popular':[],'latest':[],\\\n",
    "    'oldest':[],'high_price':[],'low_price':[],'name_sort':[],\\\n",
    "     'als_mf_entropy':[],'lmf_entropy':[],'top5_medi_mp_lmf_mix_entropy':[],'top3_medi_mp_lmf_mix_entropy':[],'mp_entropy':[],'medi_popular_entropy':[],'latest_entropy':[],\\\n",
    "     'oldest_entropy':[],'high_price_entropy':[],'low_price_entropy':[],'name_sort_entropy':[]}\n",
    "medistream_predict_df = pd.DataFrame(medistream_predict_score)\n",
    "\n",
    "all_prediction_df['first_day'].append(str(datetime.date(train['date_paid'].min()))+' '+str(datetime.date(train['date_paid'].max())))\n",
    "all_prediction_df['last_day'].append(str(datetime.date(test['date_paid'].min()))+' '+str(datetime.date(test['date_paid'].max())))\n",
    "all_prediction_df['train_데이터수'].append(len(train))\n",
    "all_prediction_df['train_유저수'].append(len(set(train.customer_id)))\n",
    "all_prediction_df['test_데이터수'].append(len(test))\n",
    "all_prediction_df['test_유저수'].append(len(set(test.customer_id)))\n",
    "all_prediction_df['test_신규유저수'].append(len(set(test['customer_id'].unique())- set(train['customer_id'].unique())))\n",
    "all_prediction_df['test_신규아이템수'].append(len(set(test.product_ids.unique())-set(train.product_ids.unique())))\n",
    "all_prediction_df['원본_test수'].append(len(test))\n",
    "all_prediction_df['전처리진행test수'].append(len(if_prepro_test))\n",
    "\n",
    "# ndcg\n",
    "all_prediction_df['als_mf'].append(pd.DataFrame(als_mf_hyper_parameter).sort_values(by='NDCG',ascending=False)['NDCG'].iloc[0])\n",
    "all_prediction_df['lmf'].append(pd.DataFrame(lmf_hyper_parameter).sort_values(by='NDCG',ascending=False)['NDCG'].iloc[0])\n",
    "all_prediction_df['top5_medi_mp_lmf_mix'].append(pd.DataFrame(top5_medipop_lmf_mix_hyper_parameter).sort_values(by='NDCG',ascending=False)['NDCG'].iloc[0])\n",
    "all_prediction_df['top3_medi_mp_lmf_mix'].append(pd.DataFrame(top3_medipop_lmf_mix_hyper_parameter).sort_values(by='NDCG',ascending=False)['NDCG'].iloc[0])\n",
    "all_prediction_df['mp'].append(evaluator._eval(ground_trues, predict_popular_list)[0])\n",
    "all_prediction_df['medi_popular'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='medi_popular'].iloc[0]['ndcg'])\n",
    "all_prediction_df['latest'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='latest'].iloc[0]['ndcg'])\n",
    "all_prediction_df['oldest'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='oldest'].iloc[0]['ndcg'])\n",
    "all_prediction_df['high_price'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='high_price'].iloc[0]['ndcg'])\n",
    "all_prediction_df['low_price'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='low_price'].iloc[0]['ndcg'])\n",
    "all_prediction_df['name_sort'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='name_sort'].iloc[0]['ndcg'])\n",
    "\n",
    "# entropy\n",
    "all_prediction_df['als_mf_entropy'].append(pd.DataFrame(als_mf_hyper_parameter).sort_values(by='entropy',ascending=False)['entropy'].iloc[0])\n",
    "all_prediction_df['lmf_entropy'].append(pd.DataFrame(lmf_hyper_parameter).sort_values(by='entropy',ascending=False)['entropy'].iloc[0])\n",
    "all_prediction_df['top5_medi_mp_lmf_mix_entropy'].append(pd.DataFrame(top5_medipop_lmf_mix_hyper_parameter).sort_values(by='entropy',ascending=False)['entropy'].iloc[0])\n",
    "all_prediction_df['top3_medi_mp_lmf_mix_entropy'].append(pd.DataFrame(top3_medipop_lmf_mix_hyper_parameter).sort_values(by='entropy',ascending=False)['entropy'].iloc[0])\n",
    "all_prediction_df['mp_entropy'].append(evaluator._eval(ground_trues, predict_popular_list)[1])\n",
    "all_prediction_df['medi_popular_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='medi_popular'].iloc[0]['entropy'])\n",
    "all_prediction_df['latest_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='latest'].iloc[0]['entropy'])\n",
    "all_prediction_df['oldest_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='oldest'].iloc[0]['entropy'])\n",
    "all_prediction_df['high_price_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='high_price'].iloc[0]['entropy'])\n",
    "all_prediction_df['low_price_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='low_price'].iloc[0]['entropy'])\n",
    "all_prediction_df['name_sort_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='name_sort'].iloc[0]['entropy'])\n",
    "\n",
    "print('train 총 기간:',train['date_paid'].max()-train['date_paid'].min())\n",
    "print('test 총 기간:',test['date_paid'].max()-test['date_paid'].min())\n",
    "display(pd.DataFrame(all_prediction_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
