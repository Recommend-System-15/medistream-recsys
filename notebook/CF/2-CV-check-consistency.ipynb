{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c02ca1c",
   "metadata": {},
   "source": [
    "# Cross Validation 3week\n",
    "- Time-Series 데이터이기 때문에 Time-Series-CV 방법 중 blocking 방법을 이용하여 평가 진행\n",
    "- valid data 3주 기간 중 1day를 predict하고 나머지는 학습을 진행하며 순차적으로 1day를 평가하게 됨\n",
    "- 학습 데이터의 기간은 동일하게 학습을 진행\n",
    "- 아래 그림과 같이 학습이 진행되며 전체 21day를 평가하여 평균을 내서 평가를 진행하게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bced4a90",
   "metadata": {},
   "source": [
    "![Walk-Forward](https://user-images.githubusercontent.com/86936634/199648078-2fcafd47-75bc-45e8-9626-36648efa0bb0.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dbe592",
   "metadata": {},
   "source": [
    "- 수치상으로 보았을 때 과적합되는 경향도 확인되지만\n",
    "- 데이터 수가 전체 1만건 가량으로 적으며 15개 아이템을 prediction 하기 때문에 적합도를 확인하기 쉽지 않음\n",
    "- 하지만, MF 와 LMF, ensemble(medi_mp_lmf_mix) 모두 일정하게 약 0.2 정도 NDCG score 내는 것으로 보아 적합하다고 판단\n",
    "- 모델 CV 결과는 아래 링크로 확인 할 수 있습니다.\n",
    "- https://docs.google.com/spreadsheets/d/1Y_YDjP-QcCq7Qfgk2Cr0epKyX_6Fk4Eel1oklIJLLfE/edit#gid=1936801230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "053cf1d2",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user_3/medistream-recsys/Script\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "import random\n",
    "import implicit\n",
    "from implicit.als import AlternatingLeastSquares as ALS\n",
    "\n",
    "%cd ../../util\n",
    "from utils import *\n",
    "\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime, timedelta\n",
    "import scipy.sparse as sp\n",
    "from implicit.lmf import LogisticMatrixFactorization as LMF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5943a3d",
   "metadata": {},
   "source": [
    "# 1.Dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1bfc0ddc",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5141/5141 [00:00<00:00, 667437.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# products name 확인 용\n",
    "products_df = pd.read_json(\"/fastcampus-data/products/products.json\")\n",
    "products_df = key_to_element(['_id'],products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "392f7771",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_json('/fastcampus-data/select_column_version_4.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a9b3f4b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
    "all_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "13e15e5c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def product_name_fill(product_name_preprocess_df):\n",
    "    # 각 마지막 product_ids, name으로 채우기\n",
    "    product_ids_to_name = {}\n",
    "    for idx, row in product_name_preprocess_df.iterrows():\n",
    "        product_ids_to_name[row.product_ids] = row.name_x\n",
    "    product_name_preprocess_df['name_x'] = product_name_preprocess_df['product_ids'].apply(lambda x: product_ids_to_name[x])\n",
    "\n",
    "    name_to_product_ids = {}\n",
    "    for idx, row in product_name_preprocess_df.iterrows():\n",
    "        name_to_product_ids[row.name_x] = row.product_ids\n",
    "    product_name_preprocess_df['product_ids'] = product_name_preprocess_df['name_x'].apply(lambda x: name_to_product_ids[x])\n",
    "    return product_name_preprocess_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c49f14df",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def promotion_proprof(df):\n",
    "    from datetime import datetime\n",
    "\n",
    "    preprocessed_book_df_date = df.copy()\n",
    "\n",
    "    promotion_book_df = preprocessed_book_df_date[preprocessed_book_df_date['date_paid'] >= '2022-01-01']\n",
    "    promotion_book_df['date_paid_date'] = promotion_book_df['date_paid'].dt.date\n",
    "    promotion_book_df['date_paid_week'] = promotion_book_df['date_paid_date'].apply(lambda x: x.isocalendar()[1])\n",
    "\n",
    "    promotion_dict = {\n",
    "        2:['트리거포인트 침치료'],\n",
    "        3:['藥徵, 약의 징표','파킨슨병 한의진료','침의 과학적 접근의 이해','길익동동','Medical acupuncture 침의 과학적 접근과 임상활용',\\\n",
    "          '동의보감 약선','수화론(水火論)'],\n",
    "        4:['실전한약가이드','음양승강으로 해석하는 사상의학: 생리병리'],\n",
    "        5:['음양승강으로 해석하는 사상의학: 생리병리'],\n",
    "        6:['윤상훈·권병조의 알짜 근육학','임상 한의사를 위한 기본 한약처방 강의 2판','트리거포인트 침치료','KCD 한방내과 진찰진단 가이드라인',\\\n",
    "          '실전한약가이드','음양승강으로 해석하는 사상의학: 생리병리','藥徵, 약의 징표','증보운곡본초학','통증치료를 위한 근육 초음파와 주사 테크닉'],\n",
    "        7:['오국통 온병명방'],\n",
    "        9:['병태생리 Visual map','NEO 인턴 핸드북','보험한약 브런치 the # 2판 개정판','Kendall 자세와 통증치료에 있어서 근육의 기능과 검사 5판',\\\n",
    "          '사상방 사용설명서','실전한약가이드','일차진료 한의사를 위한 보험한약입문 - 둘째 판','증보운곡본초학'],\n",
    "        10:['한눈에 보는 스트레칭 해부학'],\n",
    "        11:['임산부에게 사용할 수 있는 한방처방'],\n",
    "        12:['임산부에게 사용할 수 있는 한방처방'],\n",
    "        13:['MRI 자신감 키우기_족부편'],\n",
    "        14:['장골의 PI 변위는 없다'],\n",
    "        15:['윤상훈·권병조의 알짜 근육학','임상 한의사를 위한 기본 한약처방 강의 2판','KCD 한방내과 진찰진단 가이드라인','트리거포인트 침치료',\\\n",
    "           '음양승강으로 해석하는 사상의학: 생리병리','침의 과학적 접근의 이해','실전한약가이드','임산부에게 사용할 수 있는 한방처방','한눈에 보는 스트레칭 해부학',\\\n",
    "           'MRI 자신감 키우기_족부편'],\n",
    "        16:['환자상담의 달인','병의원 경영과 자산 관리 클리닉','우리 병원의 문제? 현장에서 답을 찾다!','근육학','스파이랄 및 키네지오 테이핑',\\\n",
    "           '요양병원 주치의 진료핵심'],\n",
    "        17:['오당 본초강론','운동기능장애 치료 매뉴얼','K. 한의학 임상총론','한방 활용 가이드','최강통증매선','암 치료에 이용되는 천연약물',\\\n",
    "           '왕문원 임상 평형침법','중국 왕문원 평형침구학'],\n",
    "        18:['초음파 가이드 근골격계 통증 치료의 정석'],\n",
    "        19:['초음파 가이드 근골격계 통증 치료의 정석','섭혜민 명의경방험안'],\n",
    "        20:['카이로프랙틱 기본테크닉론'],\n",
    "        21:['흔히보는 정형외과 외래진료 가이드북'],\n",
    "        22:['趙紹琴(조소금) 내과학','한의학 상담','숨찬 세상, 호흡기를 편하게',\\\n",
    "         '의학심오(醫學心悟)','안면마비 침구치료','중경서 독법 강해(상,하) /개정판'],\n",
    "        23:['선생님, 이제 그만 저 좀 포기해 주세요','한의학 상담','숨찬 세상, 호흡기를 편하게',\\\n",
    "        '의학심오(醫學心悟)','중경서 독법 강해(상,하) /개정판','안면마비 침구치료'],\n",
    "     24:['황황교수의 임상의를 위한 근거기반 상한금궤 처방 매뉴얼','황황교수의 개원 한의사를 위한 상한금궤 처방 강의록',\\\n",
    "        '선생님, 이제 그만 저 좀 포기해 주세요'],\\\n",
    "     25:['황황교수의 임상의를 위한 근거기반 상한금궤 처방 매뉴얼',\\\n",
    "       '황황교수의 개원 한의사를 위한 상한금궤 처방 강의록','약침의 정석 –통증편','갑상선 진료 완전정복',\\\n",
    "       '신경학 증상의 감별법','이것이 알고싶다! 당뇨병진료','어지럼질환의 진단과 치료','증례와 함께 하는 한약처방',\\\n",
    "       '뇌의학의 첫걸음','HAPPY 소아청소년 진료'],\\\n",
    "     26:['약침의 정석 –통증편','갑상선 진료 완전정복','신경학 증상의 감별법',\\\n",
    "       '증례와 함께 하는 한약처방','이것이 알고싶다! 당뇨병진료','HAPPY 소아청소년 진료','어지럼질환의 진단과 치료',\\\n",
    "       '뇌의학의 첫걸음','실전, 임상한의학 내과질환을 중심으로','실전, 임상한의학 알레르기질환','침구대성','평주온열경위'],\n",
    "     27:['침구과 진료매뉴얼','실전, 임상한의학 내과질환을 중심으로','실전, 임상한의학 알레르기질환','내과학 5권세트','한방순환 신경내과학',\\\n",
    "        '침구대성'],\n",
    "     28:['감별진단의 정석','기본통증진료학','약처방의 정석 (1, 2권 세트)','QBook: Case based Review',\\\n",
    "         'SMART 내과 1권 : 바이탈, 감염, 종양, 류마티스','일차진료아카데미 처방가이드'],\n",
    "     29:['비만문답','사암침의 해석과 임상'],\n",
    "     30:['플로차트 정형외과 진단','침구과 진료매뉴얼','내과학 5권세트','한방순환 신경내과학'],\n",
    "     31:['외래에서 꼭 알아야 할 통증증후군 137가지'],\n",
    "     32:['SMART 기본 일차진료매뉴얼 3판(세트)','SMART 소아진료매뉴얼 3판','SMART 응급진료매뉴얼(세트)'],\n",
    "     33:['SMART 기본 일차진료매뉴얼 3판(세트)','SMART 소아진료매뉴얼 3판','SMART 응급진료매뉴얼(세트)'],\n",
    "     34:['초음파 유도하 침 시술 가이드북'],\n",
    "     35:['영어 진료 가이드북','초음파 유도하 침 시술 가이드북'],\n",
    "     36:['영어 진료 가이드북','소아피부질환해설'],\n",
    "     37:['소아피부질환해설','醫學心悟(의학심오) 톺아보기'],}\n",
    "\n",
    "    promotion_item_list = []\n",
    "    for promotion_items in promotion_dict.values():\n",
    "        for item in promotion_items:\n",
    "            promotion_item_list.append(item)\n",
    "\n",
    "    # set(promotion_item_list), len(set(promotion_item_list))\n",
    "    \n",
    "    preprocess_promotion_df = promotion_book_df[~((promotion_book_df['name_x'].str.contains('침의 과학적 접근과 임상활용')) & \\\n",
    "                            (promotion_book_df['date_paid_week']==3))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('의학심오')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==22))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('의학심오')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==23))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('약처방의 정석')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==28))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('초음파 유도하 침')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==34))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('초음파 유도하 침')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==34))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('영어 진료 가이드북')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==35))]\n",
    "    preprocess_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('영어 진료 가이드북')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==36))]\n",
    "    all_promotion_df = preprocess_promotion_df[~((preprocess_promotion_df['name_x'].str.contains('의학심오')) & \\\n",
    "                                (preprocess_promotion_df['date_paid_week']==37))]\n",
    "\n",
    "    for key,value in promotion_dict.items():\n",
    "        all_promotion_df = all_promotion_df[~((all_promotion_df['name_x'].isin(value)) & (all_promotion_df['date_paid_week']==key))]\n",
    "    \n",
    "    return all_promotion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7e42cf73",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-09-13 08:59:21.151000+0000', tz='UTC')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date_paid'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "912c29ad",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "split_day_list =  []\n",
    "test_day_list = []\n",
    "\n",
    "# 1일 test 날짜 확인\n",
    "last_date_state = '2022-09-13'\n",
    "split_day = pd.to_datetime(last_date_state)-relativedelta(months=4)\n",
    "test_day = pd.to_datetime(last_date_state)\n",
    "'''\n",
    "마지막 날짜에서 개월 수를 자름 -> split_day\n",
    "months 만 바꾸면 21번 분량이 나옴\n",
    "'''\n",
    "'''\n",
    "train validation test\n",
    "5month 3week     3week\n",
    "42day 전부터 자르면 됨\n",
    "'''\n",
    "for i in range(21,42):\n",
    "    sp_day = str((split_day-timedelta(days=i+1)).to_pydatetime().date())\n",
    "    tt_day  = str((test_day-timedelta(days=i+1)).to_pydatetime().date())\n",
    "    split_day_list.append(sp_day)\n",
    "    test_day_list.append(tt_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c51fdb8d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class CustomEvaluator:\n",
    "    # relavence 모두 1로 동일하게 봄\n",
    "    def _idcg(self, l):\n",
    "        return sum((1.0 / np.log(i + 2) for i in range(l)))\n",
    "    \n",
    "\n",
    "    def __init__(self):\n",
    "        self._idcgs = [self._idcg(i) for i in range(1000)]\n",
    "\n",
    "    def _ndcg(self, gt, rec):\n",
    "        dcg = 0.0\n",
    "        for i, r in enumerate(rec):\n",
    "            if r in gt:\n",
    "                dcg += 1.0 / np.log(i + 2)\n",
    "\n",
    "        return dcg / self._idcgs[len(gt)]\n",
    "    \n",
    "    def _entropy_diversity(self,rec_list):\n",
    "        import six\n",
    "        import math\n",
    "        \n",
    "        topn = len(rec_list[0]['items'])\n",
    "        users = [i.get('id',None) for i in rec_list]\n",
    "        sz = float(len(users)) * topn\n",
    "        freq = {}\n",
    "        for rec in rec_list:\n",
    "            for r in rec['items']:\n",
    "                freq[r] = freq.get(r, 0) + 1\n",
    "        ent = -sum([v / sz * math.log(v / sz) for v in six.itervalues(freq)])\n",
    "        return ent\n",
    "\n",
    "    def _eval(self, gt_list, rec_list):\n",
    "        gt_dict = {g[\"id\"]: g for g in gt_list}\n",
    "        ndcg_score = 0.0\n",
    "\n",
    "        for rec in rec_list:\n",
    "            gt = gt_dict[rec[\"id\"]]\n",
    "            ndcg_score += self._ndcg(gt[\"items\"], rec[\"items\"])\n",
    "\n",
    "\n",
    "        ndcg_score = ndcg_score / len(rec_list)\n",
    "        ent = self._entropy_diversity(rec_list)\n",
    "        \n",
    "        return ndcg_score, ent\n",
    "\n",
    "    def evaluate(self, gt_list, rec_list):\n",
    "        try:\n",
    "            ndcg_score, ent_score = self._eval(gt_list, rec_list)\n",
    "            print(f\"NDCG: {ndcg_score:.6}\")\n",
    "            print(f\"Entropy Diversity: {ent_score:.6} \")\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "53019274",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def module(df:pd.DataFrame(), split_date, test_date, all_df)->pd.DataFrame():\n",
    "    \n",
    "    # paid orders만 가져오기\n",
    "    df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
    "    df_only_paid = df[~df['date_paid'].isna()]\n",
    "    # 5개월치 데이터만 가져오기\n",
    "    df_date = df_only_paid[df_only_paid['date_paid'] >= split_date]\n",
    "    # 취소 안된 것만 가져오기\n",
    "    complete_df = df_date[(df_date['paid'] == True) & (df_date['cancelled']==False)]\n",
    "    # 도서 카테고리만 가져오기\n",
    "    only_book = complete_df[complete_df['name'] == '도서']\n",
    "\n",
    "    # 유저가 중복으로 아이템 구매 삭제\n",
    "    df_duplicated_book = only_book.drop_duplicates(subset=['customer_id','product_ids'])\n",
    "    df_book = df_duplicated_book.sort_values(by='date_paid').reset_index(drop=True)\n",
    "    \n",
    "    # medirecommend 만들기\n",
    "    df = df.dropna(subset=['product_ids','name_x'])\n",
    "\n",
    "    # paid orders만 가져오기\n",
    "    df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
    "    df_only_paid = df[~df['date_paid'].isna()]\n",
    "    # 취소 안된 것만 가져오기\n",
    "    complete_df = df_only_paid[(df_only_paid['paid'] == True) & (df_only_paid['cancelled']==False)]\n",
    "    # 도서 카테고리만 가져오기\n",
    "    only_book = complete_df[complete_df['name'] == '도서']\n",
    "\n",
    "    # 유저가 중복으로 아이템 구매 삭제\n",
    "    df_duplicated_book = only_book.drop_duplicates(subset=['customer_id','product_ids'])\n",
    "    df_sort = df_duplicated_book.sort_values(by='date_paid').reset_index(drop=True)\n",
    "    df_sort = product_name_fill(df_sort)\n",
    "    df_sort = df_sort.drop_duplicates(subset=['customer_id','product_ids']).reset_index(drop=True)\n",
    "    \n",
    "    # 변수 처리한 기간 데이터만 가져오기\n",
    "    df_book = df_sort[df_sort['date_paid'] >= split_date].reset_index(drop=True)\n",
    "\n",
    "    # 마지막 cross validation 6주 제외한 medirecommend 만들기\n",
    "    mediprediction_all_df = df_sort[df_sort['date_paid'] < test_date].reset_index(drop=True)\n",
    "    \n",
    "    train_before = df_book[df_book['date_paid'] < test_date]\n",
    "    train = promotion_proprof(train_before)\n",
    "    test = df_book[df_book['date_paid'].dt.date == pd.to_datetime(test_date)]\n",
    "    \n",
    "    \n",
    "    # test 만 있는 item 제거\n",
    "    only_test_items = set(test.product_ids.unique())-set(train.product_ids.unique())\n",
    "    if_prepro_test = test[~test['product_ids'].isin(only_test_items)]\n",
    "    \n",
    "    \n",
    "    PdIds = train.product_ids.unique()\n",
    "\n",
    "    PdIdToIndex = {}\n",
    "    indexToPdId = {}\n",
    "\n",
    "    colIdx = 0\n",
    "\n",
    "    for PdId in PdIds:\n",
    "        PdIdToIndex[PdId] = colIdx\n",
    "        indexToPdId[colIdx] = PdId\n",
    "        colIdx += 1\n",
    "\n",
    "    userIds = train.customer_id.unique()\n",
    "\n",
    "    userIdToIndex = {}\n",
    "    indexToUserId = {}\n",
    "\n",
    "    rowIdx = 0\n",
    "\n",
    "    for userId in userIds:\n",
    "        userIdToIndex[userId] = rowIdx\n",
    "        indexToUserId[rowIdx] = userId\n",
    "        rowIdx += 1\n",
    "    rows = []\n",
    "    cols = []\n",
    "    vals = []\n",
    "\n",
    "    for row in train.itertuples():\n",
    "        rows.append(userIdToIndex[row.customer_id])\n",
    "        cols.append(PdIdToIndex[row.product_ids])\n",
    "        vals.append(1)\n",
    "\n",
    "    purchase_sparse = sp.csr_matrix((vals, (rows, cols)), shape=(rowIdx,colIdx))\n",
    "\n",
    "    matrix = purchase_sparse.todense()\n",
    "\n",
    "    medistream_prediction_df = mediprediction_all_df[['date_created','regular_price','sale_price','three_months','product_ids','name_x']]\n",
    "    medistream_prediction_preprop_df = medistream_prediction_df.drop_duplicates(subset=['product_ids'], ignore_index=True)\n",
    "    medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])    \n",
    "    \n",
    "    most_popular = mediprediction_all_df.groupby(['product_ids']).count()['customer_id'].reset_index()\n",
    "    most_popular_list = most_popular.sort_values(by='customer_id',ascending=False).index\n",
    "    \n",
    "    # test 예측값, 이미 구매 했을 경우 제외\n",
    "    predict_popular_list = []\n",
    "    for user_id in test['customer_id'].unique():\n",
    "        train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "        predict_popular_list.append({'id':user_id ,'items':[most_popular.product_ids.loc[num] for num in most_popular_list \\\n",
    "                                                                if most_popular.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                                ]})\n",
    "\n",
    "    # 15 개만 예측하기\n",
    "    for idx, pred_list in enumerate(predict_popular_list):\n",
    "        predict_popular_list[idx]['items'] = pred_list['items'][:15]\n",
    "        \n",
    "    # real test \n",
    "    ground_trues = []\n",
    "    for user_id in test['customer_id'].unique():\n",
    "        ground_trues.append({'id': user_id,\\\n",
    "        'items':list(test[test['customer_id']==user_id].product_ids)\n",
    "        })\n",
    "\n",
    "    # MP\n",
    "    evaluator = CustomEvaluator()\n",
    "    mp = evaluator._eval(ground_trues, predict_popular_list)\n",
    "    \n",
    "    # 인기도순\n",
    "    medistream_popular_list = medistream_prediction_preprop_df.sort_values(by='three_months', ascending=False).index\n",
    "    # 최신순\n",
    "    medistream_latest_list = medistream_prediction_preprop_df.sort_values(by='date_created', ascending=False).index\n",
    "    # 오랜된 순\n",
    "    medistream_oldest_list = medistream_prediction_preprop_df.sort_values(by='date_created', ascending=True).index\n",
    "    # 높은 가격 순\n",
    "    medistream_high_price_list = medistream_prediction_preprop_df.sort_values(by='sale_price', ascending=False).index\n",
    "    # 낮은 가격 순\n",
    "    medistream_low_price_list = medistream_prediction_preprop_df.sort_values(by='sale_price', ascending=True).index\n",
    "    # 이름 순\n",
    "    medistream_name_sort_list = medistream_prediction_preprop_df.sort_values(by='name_x',ascending=True).index\n",
    "\n",
    "    def medistream_prediction_method(predict_num:int ,medi_predict_list:list)->list:\n",
    "        medistream_predict_list = []\n",
    "        for user_id in test['customer_id'].unique():\n",
    "            medistream_predict_list.append({'id':user_id ,'items':[medistream_prediction_preprop_df.product_ids.loc[num] \\\n",
    "                                                                           for num in medi_predict_list]})\n",
    "\n",
    "        # 15 개만 예측하기\n",
    "        for idx, pred_list in enumerate(medistream_predict_list):\n",
    "            medistream_predict_list[idx]['items'] = pred_list['items'][:predict_num]\n",
    "\n",
    "        return medistream_predict_list\n",
    "    \n",
    "    medistream_predict_popular_list = medistream_prediction_method(15, medistream_popular_list)\n",
    "    medistream_predict_latest_list = medistream_prediction_method(15, medistream_latest_list)\n",
    "    medistream_predict_oldest_list = medistream_prediction_method(15, medistream_oldest_list)\n",
    "    medistream_predict_high_price_list = medistream_prediction_method(15, medistream_high_price_list)\n",
    "    medistream_predict_low_price_list = medistream_prediction_method(15, medistream_low_price_list)\n",
    "    medistream_predict_name_sort_list = medistream_prediction_method(15, medistream_name_sort_list)\n",
    "    \n",
    "    def medistream_prediction(ground_trues:list, predict_list:list):\n",
    "        evaluator = CustomEvaluator()\n",
    "        ndcg, entropy = evaluator._eval(ground_trues, predict_list)\n",
    "\n",
    "        assert len(predict_list) == len(ground_trues)\n",
    "\n",
    "        cnt = 0\n",
    "        for gt, pred_list in zip(ground_trues, predict_list):\n",
    "            for pred in pred_list['items']:\n",
    "                if pred in gt['items']:\n",
    "                    cnt += 1\n",
    "        return ndcg, entropy, cnt\n",
    "    \n",
    "    medistream_predict_score = {'medistream_predict':['medi_popular','latest','oldest','high_price','low_price','name_sort'], \\\n",
    "                                'ndcg':[], 'entropy':[], 'cnt':[]}\n",
    "\n",
    "    medistream_predict_list = [medistream_predict_popular_list, medistream_predict_latest_list, medistream_predict_oldest_list,\\\n",
    "                              medistream_predict_high_price_list, medistream_predict_low_price_list, medistream_predict_name_sort_list]\n",
    "\n",
    "    for medistream_predict in medistream_predict_list:\n",
    "        ndcg, entropy, cnt = medistream_prediction(ground_trues, medistream_predict)\n",
    "        medistream_predict_score['ndcg'].append(ndcg)\n",
    "        medistream_predict_score['entropy'].append(entropy)\n",
    "        medistream_predict_score['cnt'].append(cnt)\n",
    "\n",
    "        \n",
    "######## hyper parameter tuned\n",
    "\n",
    "    # MF\n",
    "    als_mf_hyper_parameter = {'factor':[],'regularization':[],'iteration':[],'NDCG':[],'entropy':[]}\n",
    "\n",
    "    factors = [5]\n",
    "    regularizations = [0.01]\n",
    "    iterations = [5]\n",
    "\n",
    "    for factor in factors:\n",
    "        for regularization in regularizations:\n",
    "            for iteration in iterations:\n",
    "                als_model = ALS(factors=factor, regularization=regularization, iterations = iteration, random_state=42)\n",
    "                als_model.fit(purchase_sparse, show_progress=False)\n",
    "\n",
    "                # 신규 유저인 경우 mp로 넣기\n",
    "                # 전체 도서에 대한 판매 만큼 정렬 후 넣기\n",
    "                most_popular_list = most_popular.sort_values(by='customer_id',ascending=False).index\n",
    "\n",
    "                # test 예측값, 이미 구매 했을 경우 제외\n",
    "                als_predict_list = []\n",
    "                for user_id in test['customer_id'].unique():\n",
    "                    try:\n",
    "                        result = als_model.recommend(userIdToIndex[user_id], purchase_sparse[userIdToIndex[user_id]], N=15)\n",
    "                        als_predict_list.append({'id':user_id ,'items':[indexToPdId[num] for num in result[0]]})\n",
    "                    except:\n",
    "                        train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "                        als_predict_list.append({'id':user_id ,'items':[most_popular.product_ids.loc[num] for num in most_popular_list \\\n",
    "                                                                            if most_popular.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                                            ]})\n",
    "\n",
    "                # 15 개만 예측하기\n",
    "                for idx, pred_list in enumerate(als_predict_list):\n",
    "                    als_predict_list[idx]['items'] = pred_list['items'][:15]\n",
    "\n",
    "                # ALS \n",
    "                evaluator = CustomEvaluator()\n",
    "                ndcg, entropy = evaluator._eval(ground_trues, als_predict_list)\n",
    "\n",
    "                als_mf_hyper_parameter['factor'].append(factor)\n",
    "                als_mf_hyper_parameter['regularization'].append(regularization)\n",
    "                als_mf_hyper_parameter['iteration'].append(iteration)\n",
    "                als_mf_hyper_parameter['NDCG'].append(ndcg)\n",
    "                als_mf_hyper_parameter['entropy'].append(entropy)\n",
    "                \n",
    "    # LMF\n",
    "                \n",
    "    lmf_hyper_parameter = {'factor':[],'regularization':[],'iteration':[],'NDCG':[],'entropy':[]}\n",
    "\n",
    "    factors = [15]\n",
    "    regularizations = [0.005]\n",
    "    iterations = [50]\n",
    "\n",
    "    for factor in factors:\n",
    "        for regularization in regularizations:\n",
    "            for iteration in iterations:\n",
    "                lmf_model = LMF(factors=factor, regularization=regularization, iterations = iteration, random_state=42)\n",
    "                lmf_model.fit(purchase_sparse, show_progress=False)\n",
    "\n",
    "                # 신규 유저 mp로 넣기\n",
    "                most_popular_list = most_popular.sort_values(by='customer_id',ascending=False).index\n",
    "\n",
    "                # test 예측값\n",
    "                lmf_predict_list = []\n",
    "                for user_id in test['customer_id'].unique():\n",
    "                    try:\n",
    "                        result = lmf_model.recommend(userIdToIndex[user_id], purchase_sparse[userIdToIndex[user_id]], N=15)\n",
    "                        lmf_predict_list.append({'id':user_id ,'items':[indexToPdId[num] for num in result[0]]})\n",
    "                    except:\n",
    "                        train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "                        lmf_predict_list.append({'id':user_id ,'items':[most_popular.product_ids.loc[num] for num in most_popular_list \\\n",
    "                                                                            if most_popular.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                                            ]})\n",
    "\n",
    "                # 15 개만 예측하기\n",
    "                for idx, pred_list in enumerate(lmf_predict_list):\n",
    "                    lmf_predict_list[idx]['items'] = pred_list['items'][:15]\n",
    "\n",
    "                # LMF\n",
    "                evaluator = CustomEvaluator()\n",
    "                ndcg, entropy = evaluator._eval(ground_trues, lmf_predict_list)\n",
    "\n",
    "                lmf_hyper_parameter['factor'].append(factor)\n",
    "                lmf_hyper_parameter['regularization'].append(regularization)\n",
    "                lmf_hyper_parameter['iteration'].append(iteration)\n",
    "                lmf_hyper_parameter['NDCG'].append(ndcg)\n",
    "                lmf_hyper_parameter['entropy'].append(entropy)\n",
    "                \n",
    "    # 1) ensemble top5\n",
    "                \n",
    "    top5_medipop_lmf_mix_hyper_parameter = {'factor':[],'regularization':[],'iteration':[],'top':[],'NDCG':[],'entropy':[]}\n",
    "\n",
    "    factors = [40]\n",
    "    regularizations = [0.005]\n",
    "    iterations = [50]\n",
    "    tops = [5]\n",
    "\n",
    "    for factor in factors:\n",
    "        for regularization in regularizations:\n",
    "            for iteration in iterations:\n",
    "                for top in tops:\n",
    "                    lmf_model = LMF(factors=factor, regularization=regularization, iterations = iteration, random_state=42)\n",
    "                    lmf_model.fit(purchase_sparse, show_progress=False)\n",
    "\n",
    "                    # test 예측값\n",
    "                    lmf_predict_list = []\n",
    "                    for user_id in test['customer_id'].unique():\n",
    "                        try:\n",
    "                            train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "                            medi_popular_top_three = medistream_popular_list[:top]\n",
    "                            medi_popular_top_three_list = [medistream_prediction_preprop_df.product_ids.loc[num] for num in medi_popular_top_three \\\n",
    "                                                                                if medistream_prediction_preprop_df.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                                                ]\n",
    "                            result = lmf_model.recommend(userIdToIndex[user_id], purchase_sparse[userIdToIndex[user_id]], N=20)\n",
    "                            result_list = [indexToPdId[num] for num in result[0]]\n",
    "                            medi_pop_lmf_list = list(dict.fromkeys(medi_popular_top_three_list + result_list))\n",
    "                            lmf_predict_list.append({'id':user_id ,'items':medi_pop_lmf_list})\n",
    "                        except:\n",
    "                            train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "                            lmf_predict_list.append({'id':user_id ,'items':[medistream_prediction_preprop_df.product_ids.loc[num] for num in medistream_popular_list \\\n",
    "                                                                                if medistream_prediction_preprop_df.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                                                ]})\n",
    "\n",
    "                    # 15 개만 예측하기\n",
    "                    for idx, pred_list in enumerate(lmf_predict_list):\n",
    "                        lmf_predict_list[idx]['items'] = pred_list['items'][:15]\n",
    "\n",
    "                    # LMF\n",
    "                    evaluator = CustomEvaluator()\n",
    "                    ndcg, entropy = evaluator._eval(ground_trues, lmf_predict_list)\n",
    "\n",
    "                    top5_medipop_lmf_mix_hyper_parameter['factor'].append(factor)\n",
    "                    top5_medipop_lmf_mix_hyper_parameter['regularization'].append(regularization)\n",
    "                    top5_medipop_lmf_mix_hyper_parameter['iteration'].append(iteration)\n",
    "                    top5_medipop_lmf_mix_hyper_parameter['top'].append(top)\n",
    "                    top5_medipop_lmf_mix_hyper_parameter['NDCG'].append(ndcg)\n",
    "                    top5_medipop_lmf_mix_hyper_parameter['entropy'].append(entropy)\n",
    "                    \n",
    "    # 2) ensemble top3\n",
    "    \n",
    "    top3_medipop_lmf_mix_hyper_parameter = {'factor':[],'regularization':[],'iteration':[],'top':[],'NDCG':[],'entropy':[]}\n",
    "\n",
    "    factors = [40]\n",
    "    regularizations = [0.005]\n",
    "    iterations = [50]\n",
    "    tops = [3]\n",
    "\n",
    "    for factor in factors:\n",
    "        for regularization in regularizations:\n",
    "            for iteration in iterations:\n",
    "                for top in tops:\n",
    "                    lmf_model = LMF(factors=factor, regularization=regularization, iterations = iteration, random_state=42)\n",
    "                    lmf_model.fit(purchase_sparse, show_progress=False)\n",
    "\n",
    "                    # test 예측값\n",
    "                    lmf_predict_list = []\n",
    "                    for user_id in test['customer_id'].unique():\n",
    "                        try:\n",
    "                            train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "                            medi_popular_top_three = medistream_popular_list[:top]\n",
    "                            medi_popular_top_three_list = [medistream_prediction_preprop_df.product_ids.loc[num] for num in medi_popular_top_three \\\n",
    "                                                                                if medistream_prediction_preprop_df.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                                                ]\n",
    "                            result = lmf_model.recommend(userIdToIndex[user_id], purchase_sparse[userIdToIndex[user_id]], N=20)\n",
    "                            result_list = [indexToPdId[num] for num in result[0]]\n",
    "                            medi_pop_lmf_list = list(dict.fromkeys(medi_popular_top_three_list + result_list))\n",
    "                            lmf_predict_list.append({'id':user_id ,'items':medi_pop_lmf_list})\n",
    "                        except:\n",
    "                            train_purchase_list = list(train[train['customer_id']==user_id].product_ids)\n",
    "                            lmf_predict_list.append({'id':user_id ,'items':[medistream_prediction_preprop_df.product_ids.loc[num] for num in medistream_popular_list \\\n",
    "                                                                                if medistream_prediction_preprop_df.product_ids.loc[num] not in train_purchase_list \\\n",
    "                                                                                ]})\n",
    "\n",
    "                    # 15 개만 예측하기\n",
    "                    for idx, pred_list in enumerate(lmf_predict_list):\n",
    "                        lmf_predict_list[idx]['items'] = pred_list['items'][:15]\n",
    "\n",
    "                    # LMF\n",
    "                    evaluator = CustomEvaluator()\n",
    "                    ndcg, entropy = evaluator._eval(ground_trues, lmf_predict_list)\n",
    "\n",
    "                    top3_medipop_lmf_mix_hyper_parameter['factor'].append(factor)\n",
    "                    top3_medipop_lmf_mix_hyper_parameter['regularization'].append(regularization)\n",
    "                    top3_medipop_lmf_mix_hyper_parameter['iteration'].append(iteration)\n",
    "                    top3_medipop_lmf_mix_hyper_parameter['top'].append(top)\n",
    "                    top3_medipop_lmf_mix_hyper_parameter['NDCG'].append(ndcg)\n",
    "                    top3_medipop_lmf_mix_hyper_parameter['entropy'].append(entropy)\n",
    "                \n",
    "\n",
    "    all_prediction_df = {'first_day':[],'last_day':[],'train_데이터수':[],'train_유저수':[],'test_데이터수':[],\\\n",
    "        'test_유저수':[],'test_신규유저수':[],'test_신규아이템수':[],'원본_test수':[],'전처리진행test수':[],\\\n",
    "        'als_mf':[],'lmf':[],'top5_medi_mp_lmf_mix':[],'top3_medi_mp_lmf_mix':[],'mp':[],'medi_popular':[],'latest':[],\\\n",
    "        'oldest':[],'high_price':[],'low_price':[],'name_sort':[],\\\n",
    "         'als_mf_entropy':[],'lmf_entropy':[],'top5_medi_mp_lmf_mix_entropy':[],'top3_medi_mp_lmf_mix_entropy':[],'mp_entropy':[],'medi_popular_entropy':[],'latest_entropy':[],\\\n",
    "         'oldest_entropy':[],'high_price_entropy':[],'low_price_entropy':[],'name_sort_entropy':[]}\n",
    "    medistream_predict_df = pd.DataFrame(medistream_predict_score)\n",
    "\n",
    "    all_prediction_df['first_day'].append(str(datetime.date(train['date_paid'].min()))+' '+str(datetime.date(train['date_paid'].max())))\n",
    "    all_prediction_df['last_day'].append(str(datetime.date(test['date_paid'].min()))+' '+str(datetime.date(test['date_paid'].max())))\n",
    "    all_prediction_df['train_데이터수'].append(len(train))\n",
    "    all_prediction_df['train_유저수'].append(len(set(train.customer_id)))\n",
    "    all_prediction_df['test_데이터수'].append(len(test))\n",
    "    all_prediction_df['test_유저수'].append(len(set(test.customer_id)))\n",
    "    all_prediction_df['test_신규유저수'].append(len(set(test['customer_id'].unique())- set(train['customer_id'].unique())))\n",
    "    all_prediction_df['test_신규아이템수'].append(len(set(test.product_ids.unique())-set(train.product_ids.unique())))\n",
    "    all_prediction_df['원본_test수'].append(len(test))\n",
    "    all_prediction_df['전처리진행test수'].append(len(if_prepro_test))\n",
    "\n",
    "    # ndcg\n",
    "    all_prediction_df['als_mf'].append(pd.DataFrame(als_mf_hyper_parameter).sort_values(by='NDCG',ascending=False)['NDCG'].iloc[0])\n",
    "    all_prediction_df['lmf'].append(pd.DataFrame(lmf_hyper_parameter).sort_values(by='NDCG',ascending=False)['NDCG'].iloc[0])\n",
    "    all_prediction_df['top5_medi_mp_lmf_mix'].append(pd.DataFrame(top5_medipop_lmf_mix_hyper_parameter).sort_values(by='NDCG',ascending=False)['NDCG'].iloc[0])\n",
    "    all_prediction_df['top3_medi_mp_lmf_mix'].append(pd.DataFrame(top3_medipop_lmf_mix_hyper_parameter).sort_values(by='NDCG',ascending=False)['NDCG'].iloc[0])\n",
    "    all_prediction_df['mp'].append(evaluator._eval(ground_trues, predict_popular_list)[0])\n",
    "    all_prediction_df['medi_popular'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='medi_popular'].iloc[0]['ndcg'])\n",
    "    all_prediction_df['latest'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='latest'].iloc[0]['ndcg'])\n",
    "    all_prediction_df['oldest'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='oldest'].iloc[0]['ndcg'])\n",
    "    all_prediction_df['high_price'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='high_price'].iloc[0]['ndcg'])\n",
    "    all_prediction_df['low_price'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='low_price'].iloc[0]['ndcg'])\n",
    "    all_prediction_df['name_sort'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='name_sort'].iloc[0]['ndcg'])\n",
    "\n",
    "    # entropy\n",
    "    all_prediction_df['als_mf_entropy'].append(pd.DataFrame(als_mf_hyper_parameter).sort_values(by='entropy',ascending=False)['entropy'].iloc[0])\n",
    "    all_prediction_df['lmf_entropy'].append(pd.DataFrame(lmf_hyper_parameter).sort_values(by='entropy',ascending=False)['entropy'].iloc[0])\n",
    "    all_prediction_df['top5_medi_mp_lmf_mix_entropy'].append(pd.DataFrame(top5_medipop_lmf_mix_hyper_parameter).sort_values(by='entropy',ascending=False)['entropy'].iloc[0])\n",
    "    all_prediction_df['top3_medi_mp_lmf_mix_entropy'].append(pd.DataFrame(top3_medipop_lmf_mix_hyper_parameter).sort_values(by='entropy',ascending=False)['entropy'].iloc[0])\n",
    "    all_prediction_df['mp_entropy'].append(evaluator._eval(ground_trues, predict_popular_list)[1])\n",
    "    all_prediction_df['medi_popular_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='medi_popular'].iloc[0]['entropy'])\n",
    "    all_prediction_df['latest_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='latest'].iloc[0]['entropy'])\n",
    "    all_prediction_df['oldest_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='oldest'].iloc[0]['entropy'])\n",
    "    all_prediction_df['high_price_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='high_price'].iloc[0]['entropy'])\n",
    "    all_prediction_df['low_price_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='low_price'].iloc[0]['entropy'])\n",
    "    all_prediction_df['name_sort_entropy'].append(medistream_predict_df[medistream_predict_df['medistream_predict']=='name_sort'].iloc[0]['entropy'])\n",
    "\n",
    "    print('train 총 기간:',train['date_paid'].max()-train['date_paid'].min())\n",
    "    print('valid 총 기간:',test['date_paid'].max()-test['date_paid'].min())\n",
    "    \n",
    "    return pd.DataFrame(all_prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "02d7e20c",
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def CrossValidation():\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    twenty_df_list = []\n",
    "    for sp_day, tt_day in tqdm(zip(split_day_list,test_day_list)):\n",
    "        module_df = module(df, sp_day,tt_day, all_df)\n",
    "        twenty_df_list.append(module_df)\n",
    "    twenty_df = pd.concat(twenty_df_list, ignore_index=True)\n",
    "\n",
    "    return twenty_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "23c7dbc5",
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]<ipython-input-65-cca4300b5b5e>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
      "<ipython-input-65-cca4300b5b5e>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
      "1it [00:17, 17.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 122 days 14:59:35.538000\n",
      "test 총 기간: 0 days 10:26:56.965000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-cca4300b5b5e>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
      "<ipython-input-65-cca4300b5b5e>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
      "2it [00:38, 19.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 122 days 21:07:04.713000\n",
      "test 총 기간: 0 days 13:44:46.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-cca4300b5b5e>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
      "<ipython-input-65-cca4300b5b5e>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
      "3it [00:55, 18.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 122 days 16:35:30.710000\n",
      "test 총 기간: 0 days 21:14:26.909000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-cca4300b5b5e>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
      "<ipython-input-65-cca4300b5b5e>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
      "4it [01:13, 18.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 122 days 22:22:02.318000\n",
      "test 총 기간: 0 days 16:24:28.670000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-cca4300b5b5e>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
      "<ipython-input-65-cca4300b5b5e>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
      "5it [01:35, 19.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 122 days 21:45:05.364000\n",
      "test 총 기간: 0 days 22:08:31.172000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-cca4300b5b5e>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
      "<ipython-input-65-cca4300b5b5e>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
      "6it [01:55, 19.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 122 days 05:59:10.200000\n",
      "test 총 기간: 0 days 21:45:19.098000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-cca4300b5b5e>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
      "<ipython-input-65-cca4300b5b5e>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
      "7it [02:13, 19.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 122 days 19:10:27.839000\n",
      "test 총 기간: 0 days 14:47:56.361000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-cca4300b5b5e>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
      "<ipython-input-65-cca4300b5b5e>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
      "8it [02:31, 18.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 122 days 16:02:08\n",
      "test 총 기간: 0 days 21:12:34.296000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-cca4300b5b5e>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
      "<ipython-input-65-cca4300b5b5e>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
      "9it [02:48, 18.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 122 days 15:05:40.767000\n",
      "test 총 기간: 0 days 08:32:23.038000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-cca4300b5b5e>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
      "<ipython-input-65-cca4300b5b5e>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
      "10it [03:05, 17.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 122 days 23:29:49.118000\n",
      "test 총 기간: 0 days 13:43:21.405000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-cca4300b5b5e>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
      "<ipython-input-65-cca4300b5b5e>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
      "11it [03:23, 17.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 122 days 22:00:27.777000\n",
      "test 총 기간: 0 days 23:18:01.972000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-cca4300b5b5e>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
      "<ipython-input-65-cca4300b5b5e>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
      "12it [03:41, 17.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 122 days 14:08:06.703000\n",
      "test 총 기간: 0 days 23:47:33.414000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-cca4300b5b5e>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
      "<ipython-input-65-cca4300b5b5e>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
      "13it [04:02, 18.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 122 days 17:37:36.132000\n",
      "test 총 기간: 0 days 16:54:10.591000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-cca4300b5b5e>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
      "<ipython-input-65-cca4300b5b5e>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
      "14it [04:23, 19.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 122 days 20:38:18.546000\n",
      "test 총 기간: 0 days 23:28:54.649000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-cca4300b5b5e>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
      "<ipython-input-65-cca4300b5b5e>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
      "15it [04:40, 18.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 122 days 15:05:07.967000\n",
      "test 총 기간: 0 days 19:46:16.719000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-cca4300b5b5e>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
      "<ipython-input-65-cca4300b5b5e>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
      "16it [04:58, 18.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 122 days 14:02:30.995000\n",
      "test 총 기간: 0 days 13:24:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-cca4300b5b5e>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
      "<ipython-input-65-cca4300b5b5e>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
      "17it [05:15, 18.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 122 days 15:28:08.337000\n",
      "test 총 기간: 0 days 14:43:19.778000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-cca4300b5b5e>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
      "<ipython-input-65-cca4300b5b5e>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
      "18it [05:33, 18.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 122 days 10:34:19.664000\n",
      "test 총 기간: 0 days 14:26:25.297000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-cca4300b5b5e>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
      "<ipython-input-65-cca4300b5b5e>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
      "19it [06:01, 21.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 122 days 20:09:42.563000\n",
      "test 총 기간: 0 days 11:24:56.665000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-cca4300b5b5e>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
      "<ipython-input-65-cca4300b5b5e>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
      "20it [06:20, 20.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 122 days 16:33:08.155000\n",
      "test 총 기간: 0 days 23:49:41.735000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-cca4300b5b5e>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date_paid'] = pd.to_datetime(df['date_paid'])\n",
      "<ipython-input-65-cca4300b5b5e>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medistream_prediction_preprop_df['date_created'] = pd.to_datetime(medistream_prediction_preprop_df['date_created'])\n",
      "21it [06:41, 19.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 총 기간: 122 days 16:17:50.960000\n",
      "test 총 기간: 0 days 17:30:35.552000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_day</th>\n",
       "      <th>last_day</th>\n",
       "      <th>train_데이터수</th>\n",
       "      <th>train_유저수</th>\n",
       "      <th>test_데이터수</th>\n",
       "      <th>test_유저수</th>\n",
       "      <th>test_신규유저수</th>\n",
       "      <th>test_신규아이템수</th>\n",
       "      <th>원본_test수</th>\n",
       "      <th>전처리진행test수</th>\n",
       "      <th>als_mf</th>\n",
       "      <th>lmf</th>\n",
       "      <th>top5_medi_mp_lmf_mix</th>\n",
       "      <th>top3_medi_mp_lmf_mix</th>\n",
       "      <th>mp</th>\n",
       "      <th>medi_popular</th>\n",
       "      <th>latest</th>\n",
       "      <th>oldest</th>\n",
       "      <th>high_price</th>\n",
       "      <th>low_price</th>\n",
       "      <th>name_sort</th>\n",
       "      <th>als_mf_entropy</th>\n",
       "      <th>lmf_entropy</th>\n",
       "      <th>top5_medi_mp_lmf_mix_entropy</th>\n",
       "      <th>top3_medi_mp_lmf_mix_entropy</th>\n",
       "      <th>mp_entropy</th>\n",
       "      <th>medi_popular_entropy</th>\n",
       "      <th>latest_entropy</th>\n",
       "      <th>oldest_entropy</th>\n",
       "      <th>high_price_entropy</th>\n",
       "      <th>low_price_entropy</th>\n",
       "      <th>name_sort_entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-21 2022-08-21</td>\n",
       "      <td>2022-08-22 2022-08-22</td>\n",
       "      <td>2741</td>\n",
       "      <td>1421</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.441521</td>\n",
       "      <td>0.262526</td>\n",
       "      <td>0.434639</td>\n",
       "      <td>0.372139</td>\n",
       "      <td>0.301959</td>\n",
       "      <td>0.425974</td>\n",
       "      <td>0.142483</td>\n",
       "      <td>0.019553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.284273</td>\n",
       "      <td>3.450166</td>\n",
       "      <td>3.151517</td>\n",
       "      <td>3.271551</td>\n",
       "      <td>2.758286</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-20 2022-08-20</td>\n",
       "      <td>2022-08-21 2022-08-21</td>\n",
       "      <td>2737</td>\n",
       "      <td>1425</td>\n",
       "      <td>28</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0.333776</td>\n",
       "      <td>0.311489</td>\n",
       "      <td>0.207888</td>\n",
       "      <td>0.213219</td>\n",
       "      <td>0.282351</td>\n",
       "      <td>0.206744</td>\n",
       "      <td>0.085556</td>\n",
       "      <td>0.088352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049902</td>\n",
       "      <td>3.413769</td>\n",
       "      <td>3.642396</td>\n",
       "      <td>3.242338</td>\n",
       "      <td>3.321362</td>\n",
       "      <td>2.742388</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-19 2022-08-19</td>\n",
       "      <td>2022-08-20 2022-08-20</td>\n",
       "      <td>2738</td>\n",
       "      <td>1427</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.210899</td>\n",
       "      <td>0.270354</td>\n",
       "      <td>0.206523</td>\n",
       "      <td>0.219101</td>\n",
       "      <td>0.194802</td>\n",
       "      <td>0.197236</td>\n",
       "      <td>0.050052</td>\n",
       "      <td>0.033885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>3.456378</td>\n",
       "      <td>3.488702</td>\n",
       "      <td>3.359082</td>\n",
       "      <td>3.435062</td>\n",
       "      <td>2.758685</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-18 2022-08-18</td>\n",
       "      <td>2022-08-19 2022-08-19</td>\n",
       "      <td>2760</td>\n",
       "      <td>1439</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0.167440</td>\n",
       "      <td>0.204789</td>\n",
       "      <td>0.276922</td>\n",
       "      <td>0.286064</td>\n",
       "      <td>0.252103</td>\n",
       "      <td>0.248316</td>\n",
       "      <td>0.069940</td>\n",
       "      <td>0.043790</td>\n",
       "      <td>0.018761</td>\n",
       "      <td>0.012603</td>\n",
       "      <td>0.011503</td>\n",
       "      <td>3.489600</td>\n",
       "      <td>3.758705</td>\n",
       "      <td>3.287905</td>\n",
       "      <td>3.420011</td>\n",
       "      <td>2.802319</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-17 2022-08-17</td>\n",
       "      <td>2022-08-18 2022-08-18</td>\n",
       "      <td>2730</td>\n",
       "      <td>1422</td>\n",
       "      <td>69</td>\n",
       "      <td>53</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>0.128657</td>\n",
       "      <td>0.135959</td>\n",
       "      <td>0.165644</td>\n",
       "      <td>0.168949</td>\n",
       "      <td>0.132538</td>\n",
       "      <td>0.180751</td>\n",
       "      <td>0.217109</td>\n",
       "      <td>0.010065</td>\n",
       "      <td>0.074330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072600</td>\n",
       "      <td>3.290191</td>\n",
       "      <td>3.485916</td>\n",
       "      <td>3.188539</td>\n",
       "      <td>3.267860</td>\n",
       "      <td>2.755239</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-04-16 2022-08-16</td>\n",
       "      <td>2022-08-17 2022-08-17</td>\n",
       "      <td>2691</td>\n",
       "      <td>1409</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>0.287282</td>\n",
       "      <td>0.258927</td>\n",
       "      <td>0.259495</td>\n",
       "      <td>0.212231</td>\n",
       "      <td>0.234618</td>\n",
       "      <td>0.230214</td>\n",
       "      <td>0.059215</td>\n",
       "      <td>0.065449</td>\n",
       "      <td>0.017763</td>\n",
       "      <td>0.012524</td>\n",
       "      <td>0.019444</td>\n",
       "      <td>3.593421</td>\n",
       "      <td>3.713041</td>\n",
       "      <td>3.281175</td>\n",
       "      <td>3.416220</td>\n",
       "      <td>2.755415</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-04-15 2022-08-15</td>\n",
       "      <td>2022-08-16 2022-08-16</td>\n",
       "      <td>2679</td>\n",
       "      <td>1407</td>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>0.197017</td>\n",
       "      <td>0.254487</td>\n",
       "      <td>0.186331</td>\n",
       "      <td>0.179800</td>\n",
       "      <td>0.328102</td>\n",
       "      <td>0.194532</td>\n",
       "      <td>0.070859</td>\n",
       "      <td>0.021940</td>\n",
       "      <td>0.021439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035903</td>\n",
       "      <td>3.746213</td>\n",
       "      <td>3.836479</td>\n",
       "      <td>3.432582</td>\n",
       "      <td>3.552278</td>\n",
       "      <td>2.776645</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-04-14 2022-08-14</td>\n",
       "      <td>2022-08-15 2022-08-15</td>\n",
       "      <td>2669</td>\n",
       "      <td>1404</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0.271460</td>\n",
       "      <td>0.166050</td>\n",
       "      <td>0.248059</td>\n",
       "      <td>0.250751</td>\n",
       "      <td>0.190257</td>\n",
       "      <td>0.287150</td>\n",
       "      <td>0.128143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032421</td>\n",
       "      <td>3.303551</td>\n",
       "      <td>3.476448</td>\n",
       "      <td>3.277373</td>\n",
       "      <td>3.369497</td>\n",
       "      <td>2.784540</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-04-13 2022-08-13</td>\n",
       "      <td>2022-08-14 2022-08-14</td>\n",
       "      <td>2691</td>\n",
       "      <td>1409</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.204607</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.100129</td>\n",
       "      <td>0.100129</td>\n",
       "      <td>0.220240</td>\n",
       "      <td>0.100129</td>\n",
       "      <td>0.138919</td>\n",
       "      <td>0.039433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034868</td>\n",
       "      <td>3.120363</td>\n",
       "      <td>3.213225</td>\n",
       "      <td>3.041801</td>\n",
       "      <td>3.128332</td>\n",
       "      <td>2.733168</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-04-12 2022-08-12</td>\n",
       "      <td>2022-08-13 2022-08-13</td>\n",
       "      <td>2697</td>\n",
       "      <td>1407</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.330781</td>\n",
       "      <td>0.198122</td>\n",
       "      <td>0.162164</td>\n",
       "      <td>0.175958</td>\n",
       "      <td>0.323123</td>\n",
       "      <td>0.161561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.314365</td>\n",
       "      <td>3.504081</td>\n",
       "      <td>3.171418</td>\n",
       "      <td>3.271504</td>\n",
       "      <td>2.749530</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022-04-11 2022-08-11</td>\n",
       "      <td>2022-08-12 2022-08-12</td>\n",
       "      <td>2683</td>\n",
       "      <td>1408</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.102024</td>\n",
       "      <td>0.104018</td>\n",
       "      <td>0.141259</td>\n",
       "      <td>0.092905</td>\n",
       "      <td>0.049537</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.034574</td>\n",
       "      <td>0.039959</td>\n",
       "      <td>0.038889</td>\n",
       "      <td>3.537435</td>\n",
       "      <td>3.896470</td>\n",
       "      <td>3.478499</td>\n",
       "      <td>3.623311</td>\n",
       "      <td>2.753611</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022-04-10 2022-08-10</td>\n",
       "      <td>2022-08-11 2022-08-11</td>\n",
       "      <td>2664</td>\n",
       "      <td>1410</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>0.233957</td>\n",
       "      <td>0.226676</td>\n",
       "      <td>0.141416</td>\n",
       "      <td>0.141416</td>\n",
       "      <td>0.285041</td>\n",
       "      <td>0.169148</td>\n",
       "      <td>0.186071</td>\n",
       "      <td>0.004295</td>\n",
       "      <td>0.049874</td>\n",
       "      <td>0.008925</td>\n",
       "      <td>0.042021</td>\n",
       "      <td>3.547014</td>\n",
       "      <td>3.861086</td>\n",
       "      <td>3.418706</td>\n",
       "      <td>3.534349</td>\n",
       "      <td>2.751895</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022-04-09 2022-08-09</td>\n",
       "      <td>2022-08-10 2022-08-10</td>\n",
       "      <td>2652</td>\n",
       "      <td>1403</td>\n",
       "      <td>46</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>0.125606</td>\n",
       "      <td>0.117427</td>\n",
       "      <td>0.112712</td>\n",
       "      <td>0.125705</td>\n",
       "      <td>0.133369</td>\n",
       "      <td>0.151402</td>\n",
       "      <td>0.241776</td>\n",
       "      <td>0.039933</td>\n",
       "      <td>0.062019</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>0.070805</td>\n",
       "      <td>3.343026</td>\n",
       "      <td>3.581176</td>\n",
       "      <td>3.260097</td>\n",
       "      <td>3.357265</td>\n",
       "      <td>2.759752</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022-04-08 2022-08-08</td>\n",
       "      <td>2022-08-09 2022-08-09</td>\n",
       "      <td>2635</td>\n",
       "      <td>1401</td>\n",
       "      <td>63</td>\n",
       "      <td>41</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>0.083363</td>\n",
       "      <td>0.078481</td>\n",
       "      <td>0.172921</td>\n",
       "      <td>0.173630</td>\n",
       "      <td>0.065530</td>\n",
       "      <td>0.208627</td>\n",
       "      <td>0.301502</td>\n",
       "      <td>0.012638</td>\n",
       "      <td>0.092719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088253</td>\n",
       "      <td>3.428420</td>\n",
       "      <td>3.540503</td>\n",
       "      <td>3.241815</td>\n",
       "      <td>3.323083</td>\n",
       "      <td>2.779674</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022-04-07 2022-08-07</td>\n",
       "      <td>2022-08-08 2022-08-08</td>\n",
       "      <td>2650</td>\n",
       "      <td>1407</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>0.273237</td>\n",
       "      <td>0.242111</td>\n",
       "      <td>0.242970</td>\n",
       "      <td>0.250401</td>\n",
       "      <td>0.244709</td>\n",
       "      <td>0.181444</td>\n",
       "      <td>0.065693</td>\n",
       "      <td>0.047853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.356965</td>\n",
       "      <td>3.286739</td>\n",
       "      <td>3.155849</td>\n",
       "      <td>3.250987</td>\n",
       "      <td>2.767548</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022-04-06 2022-08-06</td>\n",
       "      <td>2022-08-07 2022-08-07</td>\n",
       "      <td>2656</td>\n",
       "      <td>1408</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0.250736</td>\n",
       "      <td>0.247829</td>\n",
       "      <td>0.287645</td>\n",
       "      <td>0.289069</td>\n",
       "      <td>0.260117</td>\n",
       "      <td>0.279074</td>\n",
       "      <td>0.085413</td>\n",
       "      <td>0.048840</td>\n",
       "      <td>0.006214</td>\n",
       "      <td>0.018193</td>\n",
       "      <td>0.015943</td>\n",
       "      <td>3.256521</td>\n",
       "      <td>3.650698</td>\n",
       "      <td>3.221192</td>\n",
       "      <td>3.307915</td>\n",
       "      <td>2.740267</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022-04-05 2022-08-05</td>\n",
       "      <td>2022-08-06 2022-08-06</td>\n",
       "      <td>2671</td>\n",
       "      <td>1420</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.183670</td>\n",
       "      <td>0.183670</td>\n",
       "      <td>0.288484</td>\n",
       "      <td>0.290576</td>\n",
       "      <td>0.276970</td>\n",
       "      <td>0.258458</td>\n",
       "      <td>0.076616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.362427</td>\n",
       "      <td>3.842399</td>\n",
       "      <td>3.428838</td>\n",
       "      <td>3.574674</td>\n",
       "      <td>2.759068</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-04-04 2022-08-04</td>\n",
       "      <td>2022-08-05 2022-08-05</td>\n",
       "      <td>2678</td>\n",
       "      <td>1424</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>0.216817</td>\n",
       "      <td>0.227550</td>\n",
       "      <td>0.202026</td>\n",
       "      <td>0.202614</td>\n",
       "      <td>0.298857</td>\n",
       "      <td>0.192553</td>\n",
       "      <td>0.144031</td>\n",
       "      <td>0.036067</td>\n",
       "      <td>0.025334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012022</td>\n",
       "      <td>3.270698</td>\n",
       "      <td>3.400319</td>\n",
       "      <td>3.178531</td>\n",
       "      <td>3.221243</td>\n",
       "      <td>2.732443</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022-04-03 2022-08-03</td>\n",
       "      <td>2022-08-04 2022-08-04</td>\n",
       "      <td>2670</td>\n",
       "      <td>1419</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>21</td>\n",
       "      <td>0.038521</td>\n",
       "      <td>0.051428</td>\n",
       "      <td>0.272525</td>\n",
       "      <td>0.272525</td>\n",
       "      <td>0.040722</td>\n",
       "      <td>0.349582</td>\n",
       "      <td>0.857159</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.257189</td>\n",
       "      <td>3.437792</td>\n",
       "      <td>3.179883</td>\n",
       "      <td>3.265622</td>\n",
       "      <td>2.750910</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022-04-02 2022-08-02</td>\n",
       "      <td>2022-08-03 2022-08-03</td>\n",
       "      <td>2648</td>\n",
       "      <td>1414</td>\n",
       "      <td>39</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>0.114493</td>\n",
       "      <td>0.090779</td>\n",
       "      <td>0.184909</td>\n",
       "      <td>0.197496</td>\n",
       "      <td>0.100391</td>\n",
       "      <td>0.266189</td>\n",
       "      <td>0.424587</td>\n",
       "      <td>0.029964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.379128</td>\n",
       "      <td>3.586581</td>\n",
       "      <td>3.342978</td>\n",
       "      <td>3.469378</td>\n",
       "      <td>2.763820</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2022-04-01 2022-08-01</td>\n",
       "      <td>2022-08-02 2022-08-02</td>\n",
       "      <td>2637</td>\n",
       "      <td>1406</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>0.129415</td>\n",
       "      <td>0.136738</td>\n",
       "      <td>0.306780</td>\n",
       "      <td>0.307303</td>\n",
       "      <td>0.149897</td>\n",
       "      <td>0.344919</td>\n",
       "      <td>0.430473</td>\n",
       "      <td>0.010746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>3.315562</td>\n",
       "      <td>3.588398</td>\n",
       "      <td>3.245391</td>\n",
       "      <td>3.335636</td>\n",
       "      <td>2.727333</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>2.70805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                first_day               last_day  train_데이터수  train_유저수  \\\n",
       "0   2022-04-21 2022-08-21  2022-08-22 2022-08-22        2741       1421   \n",
       "1   2022-04-20 2022-08-20  2022-08-21 2022-08-21        2737       1425   \n",
       "2   2022-04-19 2022-08-19  2022-08-20 2022-08-20        2738       1427   \n",
       "3   2022-04-18 2022-08-18  2022-08-19 2022-08-19        2760       1439   \n",
       "4   2022-04-17 2022-08-17  2022-08-18 2022-08-18        2730       1422   \n",
       "5   2022-04-16 2022-08-16  2022-08-17 2022-08-17        2691       1409   \n",
       "6   2022-04-15 2022-08-15  2022-08-16 2022-08-16        2679       1407   \n",
       "7   2022-04-14 2022-08-14  2022-08-15 2022-08-15        2669       1404   \n",
       "8   2022-04-13 2022-08-13  2022-08-14 2022-08-14        2691       1409   \n",
       "9   2022-04-12 2022-08-12  2022-08-13 2022-08-13        2697       1407   \n",
       "10  2022-04-11 2022-08-11  2022-08-12 2022-08-12        2683       1408   \n",
       "11  2022-04-10 2022-08-10  2022-08-11 2022-08-11        2664       1410   \n",
       "12  2022-04-09 2022-08-09  2022-08-10 2022-08-10        2652       1403   \n",
       "13  2022-04-08 2022-08-08  2022-08-09 2022-08-09        2635       1401   \n",
       "14  2022-04-07 2022-08-07  2022-08-08 2022-08-08        2650       1407   \n",
       "15  2022-04-06 2022-08-06  2022-08-07 2022-08-07        2656       1408   \n",
       "16  2022-04-05 2022-08-05  2022-08-06 2022-08-06        2671       1420   \n",
       "17  2022-04-04 2022-08-04  2022-08-05 2022-08-05        2678       1424   \n",
       "18  2022-04-03 2022-08-03  2022-08-04 2022-08-04        2670       1419   \n",
       "19  2022-04-02 2022-08-02  2022-08-03 2022-08-03        2648       1414   \n",
       "20  2022-04-01 2022-08-01  2022-08-02 2022-08-02        2637       1406   \n",
       "\n",
       "    test_데이터수  test_유저수  test_신규유저수  test_신규아이템수  원본_test수  전처리진행test수  \\\n",
       "0          10         8           5            0        10          10   \n",
       "1          28        15           9            0        28          28   \n",
       "2          12         7           3            0        12          12   \n",
       "3          19        14           6            0        19          19   \n",
       "4          69        53          37            0        69          69   \n",
       "5          42        30          15            2        42          40   \n",
       "6          32        18           6            1        32          31   \n",
       "7          18        12           7            0        18          18   \n",
       "8           8         8           6            1         8           7   \n",
       "9           8         7           4            1         8           7   \n",
       "10         32        15           6            5        32          27   \n",
       "11         36        16           5            2        36          34   \n",
       "12         46        32          21            0        46          46   \n",
       "13         63        41          27            1        63          62   \n",
       "14         19         9           6            1        19          18   \n",
       "15         22        11           6            0        22          22   \n",
       "16         13         9           3            0        13          13   \n",
       "17         22        17          12            2        22          19   \n",
       "18        100        90          66            3       100          21   \n",
       "19         39        23          11            3        39          27   \n",
       "20         43        36          24            1        43          30   \n",
       "\n",
       "      als_mf       lmf  top5_medi_mp_lmf_mix  top3_medi_mp_lmf_mix        mp  \\\n",
       "0   0.441521  0.262526              0.434639              0.372139  0.301959   \n",
       "1   0.333776  0.311489              0.207888              0.213219  0.282351   \n",
       "2   0.210899  0.270354              0.206523              0.219101  0.194802   \n",
       "3   0.167440  0.204789              0.276922              0.286064  0.252103   \n",
       "4   0.128657  0.135959              0.165644              0.168949  0.132538   \n",
       "5   0.287282  0.258927              0.259495              0.212231  0.234618   \n",
       "6   0.197017  0.254487              0.186331              0.179800  0.328102   \n",
       "7   0.271460  0.166050              0.248059              0.250751  0.190257   \n",
       "8   0.204607  0.156250              0.100129              0.100129  0.220240   \n",
       "9   0.330781  0.198122              0.162164              0.175958  0.323123   \n",
       "10  0.085938  0.100000              0.102024              0.104018  0.141259   \n",
       "11  0.233957  0.226676              0.141416              0.141416  0.285041   \n",
       "12  0.125606  0.117427              0.112712              0.125705  0.133369   \n",
       "13  0.083363  0.078481              0.172921              0.173630  0.065530   \n",
       "14  0.273237  0.242111              0.242970              0.250401  0.244709   \n",
       "15  0.250736  0.247829              0.287645              0.289069  0.260117   \n",
       "16  0.183670  0.183670              0.288484              0.290576  0.276970   \n",
       "17  0.216817  0.227550              0.202026              0.202614  0.298857   \n",
       "18  0.038521  0.051428              0.272525              0.272525  0.040722   \n",
       "19  0.114493  0.090779              0.184909              0.197496  0.100391   \n",
       "20  0.129415  0.136738              0.306780              0.307303  0.149897   \n",
       "\n",
       "    medi_popular    latest    oldest  high_price  low_price  name_sort  \\\n",
       "0       0.425974  0.142483  0.019553    0.000000   0.015852   0.000000   \n",
       "1       0.206744  0.085556  0.088352    0.000000   0.000000   0.049902   \n",
       "2       0.197236  0.050052  0.033885    0.000000   0.000000   0.023671   \n",
       "3       0.248316  0.069940  0.043790    0.018761   0.012603   0.011503   \n",
       "4       0.180751  0.217109  0.010065    0.074330   0.000000   0.072600   \n",
       "5       0.230214  0.059215  0.065449    0.017763   0.012524   0.019444   \n",
       "6       0.194532  0.070859  0.021940    0.021439   0.000000   0.035903   \n",
       "7       0.287150  0.128143  0.000000    0.021887   0.000000   0.032421   \n",
       "8       0.100129  0.138919  0.039433    0.000000   0.000000   0.034868   \n",
       "9       0.161561  0.000000  0.047619    0.000000   0.038605   0.000000   \n",
       "10      0.092905  0.049537  0.111111    0.034574   0.039959   0.038889   \n",
       "11      0.169148  0.186071  0.004295    0.049874   0.008925   0.042021   \n",
       "12      0.151402  0.241776  0.039933    0.062019   0.005178   0.070805   \n",
       "13      0.208627  0.301502  0.012638    0.092719   0.000000   0.088253   \n",
       "14      0.181444  0.065693  0.047853    0.000000   0.011102   0.000000   \n",
       "15      0.279074  0.085413  0.048840    0.006214   0.018193   0.015943   \n",
       "16      0.258458  0.076616  0.000000    0.000000   0.000000   0.000000   \n",
       "17      0.192553  0.144031  0.036067    0.025334   0.000000   0.012022   \n",
       "18      0.349582  0.857159  0.001969    0.000000   0.000000   0.000000   \n",
       "19      0.266189  0.424587  0.029964    0.000000   0.012351   0.000000   \n",
       "20      0.344919  0.430473  0.010746    0.000000   0.000000   0.010930   \n",
       "\n",
       "    als_mf_entropy  lmf_entropy  top5_medi_mp_lmf_mix_entropy  \\\n",
       "0         3.284273     3.450166                      3.151517   \n",
       "1         3.413769     3.642396                      3.242338   \n",
       "2         3.456378     3.488702                      3.359082   \n",
       "3         3.489600     3.758705                      3.287905   \n",
       "4         3.290191     3.485916                      3.188539   \n",
       "5         3.593421     3.713041                      3.281175   \n",
       "6         3.746213     3.836479                      3.432582   \n",
       "7         3.303551     3.476448                      3.277373   \n",
       "8         3.120363     3.213225                      3.041801   \n",
       "9         3.314365     3.504081                      3.171418   \n",
       "10        3.537435     3.896470                      3.478499   \n",
       "11        3.547014     3.861086                      3.418706   \n",
       "12        3.343026     3.581176                      3.260097   \n",
       "13        3.428420     3.540503                      3.241815   \n",
       "14        3.356965     3.286739                      3.155849   \n",
       "15        3.256521     3.650698                      3.221192   \n",
       "16        3.362427     3.842399                      3.428838   \n",
       "17        3.270698     3.400319                      3.178531   \n",
       "18        3.257189     3.437792                      3.179883   \n",
       "19        3.379128     3.586581                      3.342978   \n",
       "20        3.315562     3.588398                      3.245391   \n",
       "\n",
       "    top3_medi_mp_lmf_mix_entropy  mp_entropy  medi_popular_entropy  \\\n",
       "0                       3.271551    2.758286               2.70805   \n",
       "1                       3.321362    2.742388               2.70805   \n",
       "2                       3.435062    2.758685               2.70805   \n",
       "3                       3.420011    2.802319               2.70805   \n",
       "4                       3.267860    2.755239               2.70805   \n",
       "5                       3.416220    2.755415               2.70805   \n",
       "6                       3.552278    2.776645               2.70805   \n",
       "7                       3.369497    2.784540               2.70805   \n",
       "8                       3.128332    2.733168               2.70805   \n",
       "9                       3.271504    2.749530               2.70805   \n",
       "10                      3.623311    2.753611               2.70805   \n",
       "11                      3.534349    2.751895               2.70805   \n",
       "12                      3.357265    2.759752               2.70805   \n",
       "13                      3.323083    2.779674               2.70805   \n",
       "14                      3.250987    2.767548               2.70805   \n",
       "15                      3.307915    2.740267               2.70805   \n",
       "16                      3.574674    2.759068               2.70805   \n",
       "17                      3.221243    2.732443               2.70805   \n",
       "18                      3.265622    2.750910               2.70805   \n",
       "19                      3.469378    2.763820               2.70805   \n",
       "20                      3.335636    2.727333               2.70805   \n",
       "\n",
       "    latest_entropy  oldest_entropy  high_price_entropy  low_price_entropy  \\\n",
       "0          2.70805         2.70805             2.70805            2.70805   \n",
       "1          2.70805         2.70805             2.70805            2.70805   \n",
       "2          2.70805         2.70805             2.70805            2.70805   \n",
       "3          2.70805         2.70805             2.70805            2.70805   \n",
       "4          2.70805         2.70805             2.70805            2.70805   \n",
       "5          2.70805         2.70805             2.70805            2.70805   \n",
       "6          2.70805         2.70805             2.70805            2.70805   \n",
       "7          2.70805         2.70805             2.70805            2.70805   \n",
       "8          2.70805         2.70805             2.70805            2.70805   \n",
       "9          2.70805         2.70805             2.70805            2.70805   \n",
       "10         2.70805         2.70805             2.70805            2.70805   \n",
       "11         2.70805         2.70805             2.70805            2.70805   \n",
       "12         2.70805         2.70805             2.70805            2.70805   \n",
       "13         2.70805         2.70805             2.70805            2.70805   \n",
       "14         2.70805         2.70805             2.70805            2.70805   \n",
       "15         2.70805         2.70805             2.70805            2.70805   \n",
       "16         2.70805         2.70805             2.70805            2.70805   \n",
       "17         2.70805         2.70805             2.70805            2.70805   \n",
       "18         2.70805         2.70805             2.70805            2.70805   \n",
       "19         2.70805         2.70805             2.70805            2.70805   \n",
       "20         2.70805         2.70805             2.70805            2.70805   \n",
       "\n",
       "    name_sort_entropy  \n",
       "0             2.70805  \n",
       "1             2.70805  \n",
       "2             2.70805  \n",
       "3             2.70805  \n",
       "4             2.70805  \n",
       "5             2.70805  \n",
       "6             2.70805  \n",
       "7             2.70805  \n",
       "8             2.70805  \n",
       "9             2.70805  \n",
       "10            2.70805  \n",
       "11            2.70805  \n",
       "12            2.70805  \n",
       "13            2.70805  \n",
       "14            2.70805  \n",
       "15            2.70805  \n",
       "16            2.70805  \n",
       "17            2.70805  \n",
       "18            2.70805  \n",
       "19            2.70805  \n",
       "20            2.70805  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_df = CrossValidation()\n",
    "twenty_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
